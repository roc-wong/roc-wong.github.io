<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[eureka dns cluster]]></title>
      <url>%2Fblog%2F2018%2F11%2Feureka-dns-cluster.html</url>
      <content type="text"><![CDATA[Netflix Eureka集群配置Spring Cloud Netflix Eureka集群配置方式主要用两种：Static servers list config和dns，本文主要介绍基于DNS的方式搭建Eureka集群。 Static servers list configclient启动后从config中获取region和zone以及serviceUrl，进行服务注册、发现，这种静态集群模式无法动态扩容，一旦新增节点，只能挨个修改server和client端的配置文件，大致配置如下：1234567891011eureka: server: enable-self-preservation: false instance: prefer-ip-address: true instance-id: $&#123;spring.cloud.client.ip-address&#125;:$&#123;spring.application.name&#125;:$&#123;server.port&#125; client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://10.25.102.174:8082/eureka/,http://10.25.102.174:8083/eureka/ DNS configuration基于DNS的Eureka Cluster架构图如下： 简单来说就是使用DNS服务器管理Eureka Server的地址，弹性伸缩对客户端没有影响。 大致流程如下： 客户端开启DNS方式获取serviceUrl：use-dns-for-fetching-service-urls: true； 根据client.region配置的区域region，查询DNS区域配置文件中该区域下的所有可用区zone； 循环所有可用区zone，获取可用区配置的eureka-server地址； 拼接成完整的serviceUrl并加入serviceUrls列表中，serviceUrl格式为：&quot;http://&quot; + ec2Url + &quot;:&quot; + clientConfig.getEurekaServerPort() + &quot;/&quot; + clientConfig.getEurekaServerURLContext() + &quot;/&quot;;。 只要解决DNS服务器配置就可以达到动态集群的效果，关于如何搭建DNS服务器集群，请移步另一篇文章：CentOS 搭建DNS主从服务器集群，文中详细介绍了如何在区域配置文件中配置TXT记录，本文不在赘述。 1.DNS 区域文件配置TXT记录zts.local.zone区域配置文件中有关eureka的配置： 12345678910; eureka cluster配置txt.shanghai IN TXT "defaultZone.zts.local"txt.defaultZone IN TXT "10.29.181.56" "10.29.181.57" "10.29.181.58" "10.29.181.60";通过查看Eureka的源码，它的实现是通过寻找txt.beijing-a.zts.local（txt.region.eureka-server-d-n-s-name）获取"beijing-a.zts.local" "beijing-b.zts.local"的zone：beijing-a和beijing-b，;然后再去获取txt.beijing-a.zts.local和txt.beijing-b.zts.local中对应的ServiceUrls的数据，也就是IP地址: "10.29.181.61" "10.29.181.62";这样服务间就可以获取到固定端口下的不同IP的机器的注册中心服务地址，并相互注册txt.beijing IN TXT "beijing-a.zts.local" "beijing-b.zts.local"txt.beijing-a IN TXT "10.29.181.61" "10.29.181.62"txt.beijing-b IN TXT "10.29.181.63" "10.29.181.64" 2.Eureka Server/Client端配置12345678910111213141516171819202122232425262728293031---spring: application: name: eureka-serverserver: port: 8081eureka: server: enable-self-preservation: false instance: prefer-ip-address: true instance-id: $&#123;spring.cloud.client.ip-address&#125;:$&#123;spring.application.name&#125;:$&#123;server.port&#125; client: ## 是否将自己注册到eureka register-with-eureka: true ## 是否获取注册信息到本地 fetch-registry: true ## 开启DNS方式获取serviceUrl,默认为false use-dns-for-fetching-service-urls: true ## DNS域名,获取其他信息将以该域名为根域名 eureka-server-d-n-s-name: zts.local ## 当前应用所在区域,默认为us-east-1 region: beijing ## 配置中心的eureka目录 eureka-server-u-r-l-context: eureka ## 映射其他eurekaServer的端口，这里注意采用这种方式 server.port和这个端口最好一致 ## 因为dns是控制地址的变化，端口不变，所以不像前面的哪些配置方式可以自己定义url和port。 ## 所以每个IP都是用的相同的port进行注册中心服务的部署 eureka-server-port: 8081 ## 获取serviceUrl时候是否优先获取相同zone的列表(如果获取为空则获取所在region第一个zone),如果为false则优先获取不在相同zone的列表 prefer-same-zone-eureka: true 3.测试 修改客户端DNS服务器配置为10.29.181.61，DNS服务器的域名为zts.local 依次启动4台Eureka Server服务器，查看启动日志（删减版的日志），： 1234567891011121314151617181920212223242526272018-11-20 16:17:14.962 INFO 49750 --- [ main] c.n.d.s.r.aws.ConfigClusterResolver : Resolving eureka endpoints via DNS: txt.beijing.zts.local (&lt;------注意这里)2018-11-20 16:17:15.012 INFO 49750 --- [ main] com.netflix.discovery.DiscoveryClient : Disable delta property : false2018-11-20 16:17:15.262 INFO 49750 --- [ main] com.netflix.discovery.DiscoveryClient : Discovery Client initialized at timestamp 1542701835260 with initial instances count: 52018-11-20 16:17:15.326 INFO 49750 --- [ main] c.n.eureka.DefaultEurekaServerContext : Initializing ...2018-11-20 16:17:15.559 INFO 49750 --- [ main] c.n.eureka.cluster.PeerEurekaNodes : Replica node URL: http://10.29.181.62:8081/eureka/2018-11-20 16:17:15.560 INFO 49750 --- [ main] c.n.eureka.cluster.PeerEurekaNodes : Replica node URL: http://10.29.181.64:8081/eureka/2018-11-20 16:17:15.560 INFO 49750 --- [ main] c.n.eureka.cluster.PeerEurekaNodes : Replica node URL: http://10.29.181.61:8081/eureka/2018-11-20 16:17:16.052 INFO 49750 --- [ Thread-14] o.s.c.n.e.server.EurekaServerBootstrap : isAws returned false2018-11-20 16:17:16.053 INFO 49750 --- [ Thread-14] o.s.c.n.e.server.EurekaServerBootstrap : Initialized server context2018-11-20 16:17:16.056 INFO 49750 --- [ main] c.z.e.server.EurekaServerApplication : Started EurekaServerApplication in 7.112 seconds (JVM running for 7.625)2018-11-20 16:17:16.060 INFO 49750 --- [ Thread-14] c.n.e.registry.AbstractInstanceRegistry : Registered instance EUREKA-SERVER/10.29.181.61:eureka-server:8081 with status UP (replication=true)2018-11-20 16:17:16.061 INFO 49750 --- [ Thread-14] c.n.e.registry.AbstractInstanceRegistry : Registered instance EUREKA-SERVER/10.29.181.62:eureka-server:8081 with status UP (replication=true)2018-11-20 16:17:16.061 INFO 49750 --- [ Thread-14] c.n.e.registry.AbstractInstanceRegistry : Registered instance EUREKA-SERVER/10.29.181.64:eureka-server:8081 with status UP (replication=true)2018-11-20 16:17:16.062 INFO 49750 --- [ Thread-14] c.n.e.registry.AbstractInstanceRegistry : Registered instance EUREKA-SERVER/10.29.181.63:eureka-server:8081 with status UP (replication=true)2018-11-20 16:17:16.062 INFO 49750 --- [ Thread-14] c.n.e.registry.AbstractInstanceRegistry : Registered instance ACCOUNT-CENTER/10.25.102.174:account-center:8891 with status UP (replication=true)2018-11-20 16:17:16.062 INFO 49750 --- [ Thread-14] c.n.e.r.PeerAwareInstanceRegistryImpl : Got 5 instances from neighboring DS node2018-11-20 16:17:16.062 INFO 49750 --- [ Thread-14] c.n.e.r.PeerAwareInstanceRegistryImpl : Renew threshold is: 82018-11-20 16:17:16.062 INFO 49750 --- [ Thread-14] c.n.e.r.PeerAwareInstanceRegistryImpl : Changing status to UP2018-11-20 16:17:16.070 INFO 49750 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient : DiscoveryClient_EUREKA-SERVER/10.29.181.63:eureka-server:8081 - registration status: 2042018-11-20 16:17:16.070 INFO 49750 --- [ Thread-14] e.s.EurekaServerInitializerConfiguration : Started Eureka Server2018-11-20 16:17:16.310 INFO 49750 --- [nio-8081-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'2018-11-20 16:17:16.310 INFO 49750 --- [nio-8081-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started2018-11-20 16:17:16.327 INFO 49750 --- [nio-8081-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 17 ms2018-11-20 16:17:16.578 INFO 49750 --- [nio-8081-exec-1] c.n.e.registry.AbstractInstanceRegistry : Registered instance EUREKA-SERVER/10.29.181.63:eureka-server:8081 with status UP (replication=true)2018-11-20 16:17:17.457 INFO 49750 --- [nio-8081-exec-2] c.n.e.registry.AbstractInstanceRegistry : Registered instance EUREKA-SERVER/10.29.181.63:eureka-server:8081 with status UP (replication=true) Eureka Client端 Account服务配置 1234567891011121314151617181920212223242526272829303132333435363738394041logging: level: org.springframework.boot: info org.springframework.cloud: debugspring: application: name: account-centerserver: port: 8891eureka: server: enable-self-preservation: false instance: prefer-ip-address: true instance-id: $&#123;spring.cloud.client.ip-address&#125;:$&#123;spring.application.name&#125;:$&#123;server.port&#125; metadata-map: configPath: $&#123;server.servlet.context-path&#125; home-page-url-path: $&#123;server.servlet.context-path&#125; ## 服务过期时间配置,超过这个时间没有接收到心跳EurekaServer就会将这个实例剔除 lease-expiration-duration-in-seconds: 10 ## 服务刷新时间配置，每隔这个时间会主动心跳一次 lease-renewal-interval-in-seconds: 5 client: ## 是否将自己注册到eureka register-with-eureka: true ## 是否获取注册信息到本地 fetch-registry: true ## 开启DNS方式获取serviceUrl,默认为false use-dns-for-fetching-service-urls: true ## DNS域名,获取其他信息将以该域名为根域名 eureka-server-d-n-s-name: zts.local ## 当前应用所在区域,默认为us-east-1 region: beijing ## 配置中心的eureka目录 eureka-server-u-r-l-context: eureka ## 映射其他eurekaServer的端口，这里注意采用这种方式 server.port和这个端口最好一致 ## 因为dns是控制地址的变化，端口不变，所以不像前面的哪些配置方式可以自己定义url和port。 ## 所以每个IP都是用的相同的port进行注册中心服务的部署 eureka-server-port: 8081 ## 获取serviceUrl时候是否优先获取相同zone的列表(如果获取为空则获取所在region第一个zone),如果为false则优先获取不在相同zone的列表 prefer-same-zone-eureka: true Account启动日志： 1234562018-11-20 16:11:05.373 INFO 5824 --- [ restartedMain] c.n.d.s.r.aws.ConfigClusterResolver : Resolving eureka endpoints via DNS: txt.beijing.zts.local (&lt;------看这里)2018-11-20 16:11:05.529 INFO 5824 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Disable delta property : false2018-11-20 16:11:05.529 INFO 5824 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Single vip registry refresh property : null2018-11-20 16:11:05.529 INFO 5824 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Force full registry fetch : false2018-11-20 16:11:05.529 INFO 5824 --- [ restartedMain] com.netflix.discovery.DiscoveryClient : Application is null : false201 打开Eureka console，查看注册效果： 参考资料1.com.netflix.discovery.endpoint.EndpointUtils.getServiceUrlsFromDNS版本：eureka-client:1.9.3 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/** * Get the list of all eureka service urls for the eureka client to talk to. * * @param clientConfig the clientConfig to use * @param zone the zone in which the client resides * @param randomizer a randomizer to randomized returned urls, if loading from dns * * @return The list of all eureka service urls for the eureka client to talk to. */ public static List&lt;String&gt; getDiscoveryServiceUrls(EurekaClientConfig clientConfig, String zone, ServiceUrlRandomizer randomizer) &#123; boolean shouldUseDns = clientConfig.shouldUseDnsForFetchingServiceUrls(); if (shouldUseDns) &#123; return getServiceUrlsFromDNS(clientConfig, zone, clientConfig.shouldPreferSameZoneEureka(), randomizer); &#125; return getServiceUrlsFromConfig(clientConfig, zone, clientConfig.shouldPreferSameZoneEureka()); &#125; /** * Get the list of all eureka service urls from DNS for the eureka client to * talk to. The client picks up the service url from its zone and then fails over to * other zones randomly. If there are multiple servers in the same zone, the client once * again picks one randomly. This way the traffic will be distributed in the case of failures. * * @param clientConfig the clientConfig to use * @param instanceZone The zone in which the client resides. * @param preferSameZone true if we have to prefer the same zone as the client, false otherwise. * @param randomizer a randomizer to randomized returned urls * * @return The list of all eureka service urls for the eureka client to talk to. */ public static List&lt;String&gt; getServiceUrlsFromDNS(EurekaClientConfig clientConfig, String instanceZone, boolean preferSameZone, ServiceUrlRandomizer randomizer) &#123; String region = getRegion(clientConfig); // Get zone-specific DNS names for the given region so that we can get a // list of available zones Map&lt;String, List&lt;String&gt;&gt; zoneDnsNamesMap = getZoneBasedDiscoveryUrlsFromRegion(clientConfig, region); Set&lt;String&gt; availableZones = zoneDnsNamesMap.keySet(); List&lt;String&gt; zones = new ArrayList&lt;String&gt;(availableZones); if (zones.isEmpty()) &#123; throw new RuntimeException("No available zones configured for the instanceZone " + instanceZone); &#125; int zoneIndex = 0; boolean zoneFound = false; for (String zone : zones) &#123; logger.debug("Checking if the instance zone &#123;&#125; is the same as the zone from DNS &#123;&#125;", instanceZone, zone); if (preferSameZone) &#123; if (instanceZone.equalsIgnoreCase(zone)) &#123; zoneFound = true; &#125; &#125; else &#123; if (!instanceZone.equalsIgnoreCase(zone)) &#123; zoneFound = true; &#125; &#125; if (zoneFound) &#123; logger.debug("The zone index from the list &#123;&#125; that matches the instance zone &#123;&#125; is &#123;&#125;", zones, instanceZone, zoneIndex); break; &#125; zoneIndex++; &#125; if (zoneIndex &gt;= zones.size()) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("No match for the zone &#123;&#125; in the list of available zones &#123;&#125;", instanceZone, zones.toArray()); &#125; &#125; else &#123; // Rearrange the zones with the instance zone first for (int i = 0; i &lt; zoneIndex; i++) &#123; String zone = zones.remove(0); zones.add(zone); &#125; &#125; // Now get the eureka urls for all the zones in the order and return it List&lt;String&gt; serviceUrls = new ArrayList&lt;String&gt;(); for (String zone : zones) &#123; for (String zoneCname : zoneDnsNamesMap.get(zone)) &#123; List&lt;String&gt; ec2Urls = new ArrayList&lt;String&gt;(getEC2DiscoveryUrlsFromZone(zoneCname, DiscoveryUrlType.CNAME)); // Rearrange the list to distribute the load in case of multiple servers if (ec2Urls.size() &gt; 1) &#123; randomizer.randomize(ec2Urls); &#125; for (String ec2Url : ec2Urls) &#123; StringBuilder sb = new StringBuilder() .append("http://") .append(ec2Url) .append(":") .append(clientConfig.getEurekaServerPort()); if (clientConfig.getEurekaServerURLContext() != null) &#123; if (!clientConfig.getEurekaServerURLContext().startsWith("/")) &#123; sb.append("/"); &#125; sb.append(clientConfig.getEurekaServerURLContext()); if (!clientConfig.getEurekaServerURLContext().endsWith("/")) &#123; sb.append("/"); &#125; &#125; else &#123; sb.append("/"); &#125; String serviceUrl = sb.toString(); logger.debug("The EC2 url is &#123;&#125;", serviceUrl); serviceUrls.add(serviceUrl); &#125; &#125; &#125; // Rearrange the fail over server list to distribute the load String primaryServiceUrl = serviceUrls.remove(0); randomizer.randomize(serviceUrls); serviceUrls.add(0, primaryServiceUrl); if (logger.isDebugEnabled()) &#123; logger.debug("This client will talk to the following serviceUrls in order : &#123;&#125; ", (Object) serviceUrls.toArray()); &#125; return serviceUrls; &#125; 2. dns config配置参考文章 micro-service-discovery-using-netflix-eureka eureka集群基于DNS配置方式 (给予我了不少灵感) Spring Cloud Eureka 集群使用DNS方式进行服务分区(– 简单介绍了windows dns搭建)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CentOS 搭建DNS主从服务器集群]]></title>
      <url>%2Fblog%2F2018%2F11%2FCentos%E6%90%AD%E5%BB%BADNS%E4%B8%BB%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%9B%86%E7%BE%A4.html</url>
      <content type="text"><![CDATA[BIND（Berkeley internet Name Daemon)也叫做NAMED，是现今互联网上使用最为广泛的DNS 服务器程序。这篇文章将要讲述如何在 chroot 监牢中运行 BIND，这样它就无法访问文件系统中除“监牢”以外的其它部分。 在这篇文章中，我会将BIND的运行根目录改为 /var/named/chroot/。当然，对于BIND来说，这个目录就是 /（根目录）。 “jail”（监牢，下同）是一个软件机制，其功能是使得某个程序无法访问规定区域之外的资源，同样也为了增强安全性（LCTT 译注：chroot “监牢”，所谓“监牢”就是指通过chroot机制来更改某个进程所能看到的根目录，即将某进程限制在指定目录中，保证该进程只能对该目录及其子目录的文件进行操作，从而保证整个服务器的安全）。Bind Chroot DNS 服务器的默认“监牢”为 /var/named/chroot。 基本环境10.29.181.61 Master DNS服务器10.29.181.62 Slave DNS服务器 DNS服务器的合法域名：zts.local 要求 允许所有来源的主机对改域名进行解析，内网其他主机访问外网时候走ISP的DNS，只解析内网IP主机的请求进行转发，不会对外网主机的解析请求进行转发。 搭建主从DNS服务器集群1、安装Bind Chroot DNS 服务器1[root@nrozntgbd2 ~]# yum install bind-chroot bind bind-utils dig -y 2、拷贝bind相关文件,准备bind chroot 环境1[root@nrozntgbd2 ~]# cp -R /usr/share/doc/bind-*/sample/var/named/* /var/named/chroot/var/named/ 3、在bind chroot 的目录中创建相关文件123456[root@nrozntgbd2 ~]# touch /var/named/chroot/var/named/data/cache_dump.db[root@nrozntgbd2 ~]# touch /var/named/chroot/var/named/data/named_stats.txt[root@nrozntgbd2 ~]# touch /var/named/chroot/var/named/data/named_mem_stats.txt[root@nrozntgbd2 ~]# touch /var/named/chroot/var/named/data/named.run[root@nrozntgbd2 ~]# mkdir /var/named/chroot/var/named/dynamic[root@nrozntgbd2 ~]# touch /var/named/chroot/var/named/dynamic/managed-keys.bind 4、 将 Bind 锁定文件设置为可写12[root@nrozntgbd2 ~]# chmod -R 777 /var/named/chroot/var/named/data[root@nrozntgbd2 ~]# chmod -R 777 /var/named/chroot/var/named/dynamic 5、 将 /etc/named.conf 拷贝到 bind chroot目录1[root@nrozntgbd2 ~]# cp -p /etc/named.conf /var/named/chroot/etc/named.conf 6、 在/etc/named.conf中对 bind 进行配置在 named.conf 文件尾添加 zts.local 域信息， 创建转发域（Forward Zone）与反向域（Reverse Zone）（LCTT 译注：这里zts.local 并非一个真实有效的互联网域名，而是通常用于本地测试的一个域名；如果你需要做权威 DNS 解析，你可以将你拥有的域名如这里所示配置解析。）： [root@nrozntgbd2 ~]# vi /var/named/chroot/etc/named.conf a. 编辑配置文件/etc/named.conf，找到listen-on这一行，改为： 1listen-on port 53 &#123; any; &#125;; #any是匹配所有的意思 b. 找到allow-query这一行，改为： 1allow-query &#123; any; &#125;; c. 添加要解析的域 1234567891011//正向解析zone "zts.local" &#123; type master; file "zts.local.zone";&#125;;//反向解析zone "181.29.10.in-addr.arpa" IN &#123; type master; file "10.29.181.zone";&#125;; d. 对DNS配置文件进行一下语法检查：named-checkconf /var/named/chroot/etc/named.conf named.conf 完全配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364//// named.conf//// 由Red Hat提供，将 ISC BIND named(8) DNS服务器 // 配置为暂存域名服务器 (用来做本地DNS解析).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//options &#123; listen-on port 53 &#123; any; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; any; &#125;; /* - 如果你要建立一个 授权域名服务器 服务器, 那么不要开启 recursion（递归） 功能。 - 如果你要建立一个 递归 DNS 服务器, 那么需要开启recursion 功能。 - 如果你的递归DNS服务器有公网IP地址, 你必须开启访问控制功能， 只有那些合法用户才可以发询问. 如果不这么做的话，那么你的服 服务就会受到DNS 放大攻击。实现BCP38将有效抵御这类攻击。 */ recursion yes; dnssec-enable yes; dnssec-validation yes; dnssec-lookaside auto; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;logging &#123; channel default_debug &#123; file "data/named.run"; severity dynamic; &#125;;&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;zone "zts.local" &#123; type master; file "zts.local.zone";&#125;;zone "181.29.10.in-addr.arpa" IN &#123; type master; file "10.29.181.zone";&#125;;include "/etc/named.rfc1912.zones";include "/etc/named.root.key"; 7、 为 zts.local 域名创建转发域与反向域文件a)创建转发域[root@nrozntgbd2 ~]# vi /var/named/chroot/var/named/zts.local.zone 添加如下内容并保存：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071$ORIGIN zts.local.$TTL 86400;;在zone的配置文件中，它是以分号来作为批注语句标识符的。;修改这个配置文件时，要注意，名称最后面没有加句点的是主机名，最后面加了句点的是FQDN（除了$ORIGIN那里）。;$ORIGIN那里填域名。下面的@符号会引用这里填写的值。如果不填，则会引用主配置文件中zone语句后面的值。;$TTL表示timeto live值，表示当其它DNS查询到本zone的DNS记录时，这个记录能在它的DNS缓存中存在多久，单位为秒。@ IN SOA dns1.zts.local. roc.fly.qq.com. ( 2018111901 1H 5m 2D 6H );;SOA后面的两个参数分别是主DNS服务器主机名和管理者邮箱(xie@zts.local)。因为@符号有特殊含义，所以写成这样。;括号内的第一个参数是序号，代表本配置文档的新旧，序号越大，表示越新。每次修改本文档后，都要将这个值改大。;第二个参数是刷新频率，表示slave隔多久会跟master比对一次配置档案，单位为秒。;第三个参数是失败重新尝试时间，单位为秒;第四个参数是失效时间，单位为秒。;在BIND9中，第五个参数表示其它DNS服务器能缓存negative answers的时间，单位为秒。;@ IN NS dns1.zts.local. IN NS dns2.zts.local.dns1 IN A 10.29.181.61dns2 IN A 10.29.181.62;;类型NS定义指定域的DNS服务器主机名(如dns1.zts.local)，不管是主DNS还是从DNS。;类型A定义指定主机(如dns1)的IP地址。如果是使用的IPv6地址，则需使用类型AAAA。;;@ IN MX 10 mail1.zts.local.; IN MX 20 mail2.zts.local.;mail1 IN A 10.29.181.61;mail2 IN A 10.29.181.62;;类型MX定义指定域的邮件服务器主机名(如mail1.zts.local)。;MX后面的数字为优先级，越小越优先。同样的优先级值则可以在多台邮件服务器之间进行负载分担。;;www IN CNAME servs.zts.local.;ftp IN CNAME servs.zts.local.;servs IN A 10.29.181.6;;类型CNAME用于定义别名。通常用于同一台主机提供多个服务的情况。;以这里的设定为例，当要解析ftp.zts.local的IP时，它会解析成主机servs.zts.local的IP。;forum IN A 10.29.181.61;travel IN A 10.29.181.8; IN A 10.29.181.9;;如上面所示，也可以直接设定某一台主机(如forum.zts.local)的IP。;同一台主机(如travel.zts.local)也可以设定多个IP。; eureka cluster配置txt.shanghai IN TXT "defaultZone.zts.local"txt.defaultZone IN TXT "10.29.181.56" "10.29.181.57" "10.29.181.58" "10.29.181.60";通过查看Eureka的源码，它的实现是通过寻找txt.beijing-a.zts.local（txt.region.eureka-server-d-n-s-name）获取"beijing-a.zts.local" "beijing-b.zts.local"的zone：beijing-a和beijing-b，;然后再去获取txt.beijing-a.zts.local和txt.beijing-b.zts.local中对应的ServiceUrls的数据，也就是IP地址: "10.29.181.61" "10.29.181.62";这样服务间就可以获取到固定端口下的不同IP的机器的注册中心服务地址，并相互注册txt.beijing IN TXT "beijing-a.zts.local" "beijing-b.zts.local"txt.beijing-a IN TXT "10.29.181.61" "10.29.181.62"txt.beijing-b IN TXT "10.29.181.63" "10.29.181.64" 对区域文件进行有效性检查：1named-checkzone 181.29.10.in-addr.arpa 10.29.181.zone b)创建反向域[root@nrozntgbd2 ~]# vi /var/named/chroot/var/named/10.29.181.zone 12345678910111213141516171819202122232425262728$ORIGIN 181.29.10.in-addr.arpa.$TTL 86400;;在zone的配置文件中，它是以分号来作为批注语句标识符的。;修改这个配置文件时，要注意，名称最后面没有加句点的是主机名，最后面加了句点的是FQDN（除了$ORIGIN那里）。;$ORIGIN那里填域名。下面的@符号会引用这里填写的值。如果不填，则会引用主配置文件中zone语句后面的值。;$TTL表示timeto live值，表示当其它DNS查询到本zone的DNS记录时，这个记录能在它的DNS缓存中存在多久，单位为秒。@ IN SOA dns1.zts.local. roc.fly.qq.com. ( 2018111902 1H 5m 2D 6H );;SOA后面的两个参数分别是主DNS服务器主机名和管理者邮箱(xie@zts.local)。因为@符号有特殊含义，所以写成这样。;括号内的第一个参数是序号，代表本配置文档的新旧，序号越大，表示越新。每次修改本文档后，都要将这个值改大。;第二个参数是刷新频率，表示slave隔多久会跟master比对一次配置档案，单位为秒。;第三个参数是失败重新尝试时间，单位为秒;第四个参数是失效时间，单位为秒。;在BIND9中，第五个参数表示其它DNS服务器能缓存negative answers的时间，单位为秒。;;61.181.29.10.in-addr.arpa. IN PTR dns1.zts.local.;62.181.29.10.in-addr.arpa. IN PTR dns2.zts.local.@ IN NS dns1.zts.local. IN NS dns2.zts.local.61 IN PTR dns1.zts.local.62 IN PTR dns2.zts.local. 对区域文件进行有效性检查：1named-checkzone zts.local /var/named/chroot/var/named/zts.local.zone 8、启动 bind-chroot 服务启动named，日志可以在/var/log/messages下查看1234[root@nrozntgbd2 named]# service named restartStopping named: . [ OK ]Starting named: [ OK ][root@nrozntgbd2 named]# vim /var/log/messages 设置开机启动12# centos 6chkconfig named on 1234567# centos 7[root@nrozntgbd2 ~]# /usr/libexec/setup-named-chroot.sh /var/named/chroot on[root@nrozntgbd2 ~]# systemctl stop named[root@nrozntgbd2 ~]# systemctl disable named[root@nrozntgbd2 ~]# systemctl start named-chroot[root@nrozntgbd2 ~]# systemctl enable named-chrootln -s '/usr/lib/systemd/system/named-chroot.service' '/etc/systemd/system/multi-user.target.wants/named-chroot.service' 9、搭建从DNS服务器a)安装从DNS服务器 1.重复步骤1-5 2.编辑配置文件/var/named/chroot/etc/named.conf，找到listen-on这一行，改为： 1listen-on port 53 &#123; any; &#125;; #any是匹配所有的意思 3.找到allow-query这一行，改为： 1allow-query &#123; any; &#125;; 4.在/var/named/chroot/etc/named.conf中增加区域配置 1234567891011zone "zts.local" &#123; type slave; file "zts.local.zone"; ###将同步后的文件放置在哪里，这里是/var/named/ masters &#123; 10.29.181.61; &#125;; ###指定主服务器的ip地址&#125;;zone "181.29.10.in-addr.arpa" IN &#123; type slave; file "10.29.181.zone"; masters &#123; 10.29.181.61; &#125;; ###指定主服务器的ip地址&#125;; 5.修改权限(建议同时修改主、从DNS服务器) 1chown named:named /var/named/chroot/var/named b)修改主DNS服务器配置修改/var/named/chroot/etc/named.conf，并验证：named-checkconf named.conf 1234567891011121314151617zone "zts.local" &#123; type master; file "zts.local.zone"; allow-transfer &#123; 10.29.181.62; &#125;; //指定这个域的从DNS服务器的IP allow-query &#123; any; &#125;; //允许来自任意IP对这个域的解析请求 notify yes; also-notify &#123; 10.29.181.62; &#125;;&#125;;zone "181.29.10.in-addr.arpa" IN &#123; type master; file "10.29.181.zone"; allow-transfer &#123; 10.29.181.62; &#125;; //指定这个域的从DNS服务器的IP allow-query &#123; any; &#125;; //允许来自任意IP对这个域的解析请求 notify yes; also-notify &#123; 10.29.181.62; &#125;;&#125;; c)重启主、从DNS服务器 1.重启主服务器：service named restart 2.重启从服务器：service named restart 3.若报错，可检查日志文件vim /var/log/messages，这里我们检查下从服务器同步日志 1234567891011121314151617181920212223242526272829303132333435363738Nov 19 21:06:40 nrozntgbd3 named[90312]: adjusted limit on open files from 100000 to 1048576Nov 19 21:06:40 nrozntgbd3 named[90312]: found 8 CPUs, using 8 worker threadsNov 19 21:06:40 nrozntgbd3 named[90312]: using up to 4096 socketsNov 19 21:06:40 nrozntgbd3 named[90312]: loading configuration from '/etc/named.conf'Nov 19 21:06:40 nrozntgbd3 named[90312]: reading built-in trusted keys from file '/etc/named.iscdlv.key'Nov 19 21:06:40 nrozntgbd3 named[90312]: using default UDP/IPv4 port range: [1024, 65535]Nov 19 21:06:40 nrozntgbd3 named[90312]: using default UDP/IPv6 port range: [1024, 65535]Nov 19 21:06:40 nrozntgbd3 named[90312]: listening on IPv4 interface lo, 127.0.0.1#53Nov 19 21:06:40 nrozntgbd3 named[90312]: listening on IPv4 interface eth3, 10.29.181.62#53Nov 19 21:06:40 nrozntgbd3 named[90312]: listening on IPv6 interface lo, ::1#53Nov 19 21:06:40 nrozntgbd3 named[90312]: generating session key for dynamic DNSNov 19 21:06:40 nrozntgbd3 named[90312]: sizing zone task pool based on 7 zonesNov 19 21:06:40 nrozntgbd3 named[90312]: set up managed keys zone for view _default, file '/var/named/dynamic/managed-keys.bind'Nov 19 21:06:40 nrozntgbd3 named[90312]: Warning: 'empty-zones-enable/disable-empty-zone' not set: disabling RFC 1918 empty zonesNov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 127.IN-ADDR.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 254.169.IN-ADDR.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 2.0.192.IN-ADDR.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 100.51.198.IN-ADDR.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 113.0.203.IN-ADDR.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 255.255.255.255.IN-ADDR.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.IP6.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: D.F.IP6.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 8.E.F.IP6.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 9.E.F.IP6.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: A.E.F.IP6.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: B.E.F.IP6.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: automatic empty zone: 8.B.D.0.1.0.0.2.IP6.ARPANov 19 21:06:40 nrozntgbd3 named[90312]: command channel listening on 127.0.0.1#953Nov 19 21:06:40 nrozntgbd3 named[90312]: command channel listening on ::1#953Nov 19 21:06:40 nrozntgbd3 named[90312]: zone 0.in-addr.arpa/IN: loaded serial 0Nov 19 21:06:40 nrozntgbd3 named[90312]: zone 1.0.0.127.in-addr.arpa/IN: loaded serial 0Nov 19 21:06:40 nrozntgbd3 named[90312]: zone 1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa/IN: loaded serial 0Nov 19 21:06:40 nrozntgbd3 named[90312]: zone zts.local/IN: loaded serial 2018111901Nov 19 21:06:40 nrozntgbd3 named[90312]: zone localhost.localdomain/IN: loaded serial 0Nov 19 21:06:40 nrozntgbd3 named[90312]: zone localhost/IN: loaded serial 0Nov 19 21:06:40 nrozntgbd3 named[90312]: managed-keys-zone ./IN: loaded serial 2Nov 19 21:06:40 nrozntgbd3 named[90312]: runningNov 19 21:06:40 nrozntgbd3 named[90312]: zone zts.local/IN: sending notifies (serial 2018111901) 4.检查从服务器/var/named/chroot/var/named/zts.local.zone、/var/named/chroot/var/named/10.29.181.zone文件是否生成。 1234567891011121314[root@nrozntgbd3 named]# ls -alhtotal 48Kdrwxr-xr-x 5 named named 4.0K Nov 19 21:06 .drwxr-x--- 6 root named 4.0K Nov 19 20:48 ..drwxrwxrwx 2 root root 4.0K Nov 19 20:48 datadrwxrwxrwx 2 root root 4.0K Nov 19 20:58 dynamic-rw-r--r-- 1 root root 56 Nov 19 20:48 my.external.zone.db-rw-r--r-- 1 root root 56 Nov 19 20:48 my.internal.zone.db-rw-r--r-- 1 root root 3.3K Nov 19 20:48 named.ca-rw-r--r-- 1 root root 152 Nov 19 20:48 named.empty-rw-r--r-- 1 root root 152 Nov 19 20:48 named.localhost-rw-r--r-- 1 root root 168 Nov 19 20:48 named.loopbackdrwxr-xr-x 2 root root 4.0K Nov 19 20:48 slaves-rw-r--r-- 1 named named 660 Nov 19 21:12 zts.local.zone (&lt;------看，已经自动生成了) 9、测试登录10.29.181.62，修改DNS服务器地址vim /etc/resolv.conf(这种方式是临时的，重启网卡后，就刷新掉了)： [root@nrozntgbd3 roc]# vim /etc/resolv.conf 12#search xx.zts.comnameserver 10.29.181.61 建议使用修改网卡的dns的方式：vim /etc/sysconfig/network-scripts/ifcfg-eth0，这种方式会永久设定dns 使用dig测试 注意查看;; ANSWER SECTION:输出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@nrozntgbd3 roc]# dig -t A forum.zts.local @10.29.181.61; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6_10.1 &lt;&lt;&gt;&gt; -t A forum.zts.local @10.29.181.61;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 35607;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 2;; QUESTION SECTION:;forum.zts.local. IN A;; ANSWER SECTION:forum.zts.local. 86400 IN A 10.29.181.61 (&lt;-------看这个输出);; AUTHORITY SECTION:zts.local. 86400 IN NS dns1.zts.local.zts.local. 86400 IN NS dns2.zts.local.;; ADDITIONAL SECTION:dns1.zts.local. 86400 IN A 10.29.181.61dns2.zts.local. 86400 IN A 10.29.181.62;; Query time: 0 msec;; SERVER: 10.29.181.61#53(10.29.181.61);; WHEN: Mon Nov 19 20:24:11 2018;; MSG SIZE rcvd: 119[root@nrozntgbd3 roc]# dig -t TXT txt.shanghai.zts.local; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6_10.1 &lt;&lt;&gt;&gt; -t TXT txt.shanghai.zts.local;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 19185;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 2;; QUESTION SECTION:;txt.shanghai.zts.local. IN TXT;; ANSWER SECTION:txt.shanghai.zts.local. 86400 IN TXT "defaultZone.zts.local" (&lt;-------看这个输出);; AUTHORITY SECTION:zts.local. 86400 IN NS dns2.zts.local.zts.local. 86400 IN NS dns1.zts.local.;; ADDITIONAL SECTION:dns1.zts.local. 86400 IN A 10.29.181.61dns2.zts.local. 86400 IN A 10.29.181.62;; Query time: 0 msec;; SERVER: 10.29.181.61#53(10.29.181.61);; WHEN: Mon Nov 19 20:24:22 2018;; MSG SIZE rcvd: 144 使用nslookup测试 123456789101112[root@nrozntgbd3 named]# nslookup &gt; set queryType=TXT&gt; txt.shanghai.zts.localServer: 10.29.181.61Address: 10.29.181.61#53txt.shanghai.zts.local text = "defaultZone.zts.local"&gt; txt.beijing.zts.localServer: 10.29.181.61Address: 10.29.181.61#53txt.beijing.zts.local text = "beijing-a.zts.local" "beijing-b.zts.local" 测试反向代理 1234567891011121314151617181920212223242526[root@nrozntgbd3 roc]# dig -x 10.29.181.61 @10.29.181.61; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6_10.1 &lt;&lt;&gt;&gt; -x 10.29.181.61 @10.29.181.61;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 55778;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 2;; QUESTION SECTION:;61.181.29.10.in-addr.arpa. IN PTR;; ANSWER SECTION:61.181.29.10.in-addr.arpa. 86400 IN PTR dns1.zts.local.;; AUTHORITY SECTION:181.29.10.in-addr.arpa. 86400 IN NS dns1.zts.local.181.29.10.in-addr.arpa. 86400 IN NS dns2.zts.local.;; ADDITIONAL SECTION:dns1.zts.local. 86400 IN A 10.29.181.61dns2.zts.local. 86400 IN A 10.29.181.62;; Query time: 0 msec;; SERVER: 10.29.181.61#53(10.29.181.61);; WHEN: Mon Nov 19 20:27:42 2018;; MSG SIZE rcvd: 136 解析内部、外部域名 1234567891011121314151617[root@nrozntgbd3 roc]# nslookup forum.zts.local Server: 10.29.181.61Address: 10.29.181.61#53Name: forum.zts.localAddress: 10.29.181.61[root@nrozntgbd3 roc]# nslookup www.baidu.comServer: 10.29.181.61Address: 10.29.181.61#53Non-authoritative answer:www.baidu.com canonical name = www.a.shifen.com.Name: www.a.shifen.comAddress: 115.239.211.112Name: www.a.shifen.comAddress: 115.239.210.27 参考 在 CentOS7.0 上搭建DNS服务器 Centos7上搭建DNS服务 Linux命令学习之nslookup 搭建一个互联网DNS服务器架构 CentOS之DNS服务器安装-yellowcong centos7搭建主从DNS服务器 Centos7 搭建DNS服务器与原理配置详解]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[bash-support.vim-Bash-IDE]]></title>
      <url>%2Fblog%2F2018%2F02%2Fbash-support-vim-Bash-IDE.html</url>
      <content type="text"><![CDATA[IDE（集成开发环境）就是这样一个软件，它为了最大化程序员生产效率，提供了很多编程所需的设施和组件。 IDE 将所有开发工作集中到一个程序中，使得程序员可以编写、修改、编译、部署以及调试程序。 在这篇文章中，我们会介绍如何通过使用 bash-support vim 插件将 Vim 编辑器安装和配置 为一个编写 Bash 脚本的 IDE。 一键安装Bash-support脚本： https://github.com/roc-wong/shell-tools/blob/master/xpress_install/bash_support.sh 本篇博客整理自Linux中国： 如何用bash-support插件将Vim编辑器打造成编写Bash脚本的IDE 什么是 bash-support.vim 插件bash-support 是一个高度定制化的 vim 插件，它允许你插入：文件头、补全语句、注释、函数、以及代码块。它也使你可以进行语法检查、使脚本可执行、一键启动调试器；而完成所有的这些而不需要关闭编辑器。 它使用快捷键（映射），通过有组织地、一致的文件内容编写/插入，使得 bash 脚本编程变得有趣和愉快。 插件当前版本是 4.3，4.0 版本 重写了之前的 3.12.1 版本，4.0 及之后的版本基于一个全新的、更强大的、和之前版本模板语法不同的模板系统。 如何在 Linux 中安装 Bash-support 插件用下面的命令下载最新版本的 bash-support 插件： 12$ cd Downloads$ curl http://www.vim.org/scripts/download_script.php?src_id=24452 &gt;bash-support.zip 按照如下步骤安装；在你的主目录创建 .vim 目录（如果它不存在的话），进入该目录并提取 bash-support.zip 内容： 123$ mkdir ~/.vim$ cd .vim$ unzip ~/Downloads/bash-support.zip 下一步，在 .vimrc 文件中激活它： 1$ vi ~/.vimrc 并插入下面一行： 12filetype plug-in on set number # 可选，增加这行以在 vim 中显示行号 如何在 Vim 编辑器中使用 Bash-support 插件为了简化使用，通常使用的结构和特定操作可以分别通过键映射来插入/执行。 ~/.vim/doc/bashsupport.txt 和 ~/.vim/bash-support/doc/bash-hotkeys.pdf 或者 ~/.vim/bash-support/doc/bash-hotkeys.tex 文件中介绍了映射。 重要： 所有映射（+字符 组合）都是针对特定文件类型的：为了避免和其它插件的映射冲突，它们只适用于 sh 文件。 使用键映射的时候打字速度也有关系，引导符”\”和后面字符的组合要在特定短时间内才能识别出来（很可能少于 3 秒 - 基于假设）。 如何为新脚本自动生成文件头下面我们会介绍和学习使用这个插件一些显著的功能。看下面的示例文件头，为了要在你所有的新脚本中自动创建该文件头，请按照以下步骤操作。 首先设置你的个人信息（作者名称、作者参考、组织、公司等）。在一个 Bash 缓冲区（像下面这样打开一个测试脚本）中使用映射 \ntw 启动模板设置向导。 选中选项 1 设置个性化文件，然后按回车键。 1$ vi test.sh 之后，再次输入回车键。然后再一次选中选项 1 设置个性化文件的路径并输入回车。 设置向导会把目标文件 .vim/bash-support/rc/personal.templates 拷贝到 .vim/templates/personal.templates，打开并编辑它，在这里你可以输入你的信息。 按 i 键像截图那样在单引号中插入合适的值。 一旦你设置了正确的值，输入 :wq 保存并退出文件。关闭 Bash 测试脚本，打开另一个脚本来测试新的配置。现在文件头中应该有和下面截图类似的你的个人信息：1$ vi test2.sh 添加 Bash-support 插件帮助信息为此，在 Vim 命令行输入下面的命令并按回车键，它会创建 .vim/doc/tags 文件： 1:helptags $HOME/.vim/doc/ 如何在 Shell 脚本中插入注释要插入一个块注释，在普通模式下输入 \cfr： 如何在 Shell 脚本中插入语句下面是一些用于插入语句的键映射（n – 普通模式, i – 插入模式，v 可视模式）： 12345678910111213\sc – case in … esac （n, i）\sei – elif then （n, i）\sf – for in do done （n, i, v）\sfo – for ((…)) do done （n, i, v）\si – if then fi （n, i, v）\sie – if then else fi （n, i, v）\ss – select in do done （n, i, v）\su – until do done （n, i, v）\sw – while do done （n, i, v）\sfu – function （n, i, v）\se – echo -e "…" （n, i, v）\sp – printf "…" （n, i, v）\sa – 数组元素, $&#123;.[.]&#125; （n, i, v） 和其它更多的数组功能。 插入一个函数和函数头输入 \sfu 添加一个新的空函数，然后添加函数名并按回车键创建它。之后，添加你的函数代码。 为了给上面的函数创建函数头，输入 \cfu，输入函数名称，按回车键并填入合适的值（名称、介绍、参数、返回值）： 更多关于添加 Bash 语句的例子下面是一个使用 \si 插入一条 if 语句的例子： 下面的例子显示使用 \se 添加一条 echo 语句： 如何在 Vi 编辑器中使用运行操作下面是一些运行操作键映射的列表： 123456\rr – 更新文件，运行脚本（n, i）\ra – 设置脚本命令行参数 （n, i）\rc – 更新文件，检查语法 （n, i）\rco – 语法检查选项 （n, i）\rd – 启动调试器（n, i）\re – 使脚本可/不可执行(*) （n, i） 使脚本可执行编写完脚本后，保存它然后输入 \re 和回车键使它可执行。 如何在 Bash 脚本中使用预定义代码片段预定义代码片段是为了特定目的包含了已写好代码的文件。为了添加代码段，输入 \nr 和 \nw 读/写预定义代码段。输入下面的命令列出默认的代码段： $ ls ~/.vim/bash-support/codesnippets/ 为了使用代码段，例如 free-software-comment，输入 \nr 并使用自动补全功能选择它的名称，然后输入回车键： 创建自定义预定义代码段可以在 ~/.vim/bash-support/codesnippets/目录下编写你自己的代码段。另外，你还可以从你正常的脚本代码中创建你自己的代码段： 选择你想作为代码段的部分代码，然后输入 \nw 并给它一个相近的文件名。 要读入它，只需要输入 \nr 然后使用文件名就可以添加你自定义的代码段。 在当前光标处查看内建和命令帮助要显示帮助，在普通模式下输入： \hh – 内建帮助 \hm – 命令帮助 更多参考资料，可以查看文件： 12~/.vim/doc/bashsupport.txt #在线文档的副本~/.vim/doc/tags 访问 Bash-support 插件 GitHub 仓库：https://github.com/WolfgangMehner/bash-support 在 Vim 网站访问 Bash-support 插件：http://www.vim.org/scripts/script.php?script_id=365 就是这些啦，在这篇文章中，我们介绍了在 Linux 中使用 Bash-support 插件安装和配置 Vim 为一个 Bash-IDE 的步骤。快去发现这个插件其它令人兴奋的功能吧，一定要在评论中和我们分享哦。 作者简介： Aaron Kili 是一个 Linux 和 F.O.S.S 爱好者、Linux 系统管理员、网络开发人员，现在也是 TecMint 的内容创作者，她喜欢和电脑一起工作，坚信共享知识。 via: http://www.tecmint.com/use-vim-as-bash-ide-using-bash-support-in-linux/ 作者：Aaron Kili 译者：ictlyh 校对：wxy 本文由 LCTT 原创编译，Linux中国 荣誉推出]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[极光推送服务限流方案]]></title>
      <url>%2Fblog%2F2018%2F01%2F%E6%9C%8D%E5%8A%A1%E9%99%90%E6%B5%81%E6%96%B9%E6%A1%88.html</url>
      <content type="text"><![CDATA[如何让系统在汹涌澎湃的流量面前谈笑风生？我们的策略是不要让系统超负荷工作。如果现有的系统扛不住业务目标怎么办？加机器！机器不够怎么办？业务降级，服务限流！ 正所谓「他强任他强，清风拂山岗；他横任他横，明月照大江」，降级和限流是系统可用性保障中必不可少的神兵利器，丢卒保车，以暂停边缘业务为代价保障核心业务的资源，以系统不被突发流量压挂为第一要务。 现状JPush API 频率控制JPush API对访问次数，具有频率控制。即一定的时间窗口内，API允许调用的次数是有限制的。免费版：1分钟600次。 超出后：1&#123;"error":&#123;"code":2002,"message":"Request times of the app_key exceed the limit of current time window"&#125;&#125; 各业务组直接对接极光API目前各业务线都在使用极光推送服务，并且是直接调用极光API。水归一源，终汇聚一处。想实现流量管控，只有将调用出口整合到一处，方可达到限流管控的目的。 解决方案令牌桶算法令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。令牌桶属于控制速率类型的。令牌桶算法最初来源于计算机网络。在网络传输数据时，为了防止网络拥塞，需限制流出网络的流量，使流量以比较均匀的速度向外发送。令牌桶算法就实现了这个功能，可控制发送到网络上数据的数目，并允许突发数据的发送。 在 Wikipedia 上，令牌桶算法是这么描述的： 每秒会有 r 个令牌放入桶中，或者说，每过 1/r 秒桶中增加一个令牌。 桶中最多存放 b 个令牌，如果桶满了，新放入的令牌会被丢弃。 当一个 n 字节的数据包到达时，消耗 n 个令牌，然后发送该数据包。 如果桶中可用令牌小于 n，则该数据包将被缓存或丢弃。 大小固定的令牌桶可自行以恒定的速率源源不断地产生令牌。如果令牌不被消耗，或者被消耗的速度小于产生的速度，令牌就会不断地增多，直到把桶填满。后面再产生的令牌就会从桶中溢出。最后桶中可以保存的最大令牌数永远不会超过桶的大小。传送到令牌桶的数据包需要消耗令牌。不同大小的数据包，消耗的令牌数量不一样。 令牌桶这种控制机制基于令牌桶中是否存在令牌来指示什么时候可以发送流量。令牌桶中的每一个令牌都代表一个字节。如果令牌桶中存在令牌，则允许发送流量；而如果令牌桶中不存在令牌，则不允许发送流量。因此，如果突发门限被合理地配置并且令牌桶中有足够的令牌，那么流量就可以以峰值速率发送。 基于令牌桶算法改造消息中心，流程图如下： 单机限流Google Guava RateLimiter就是令牌桶算法的实现，速率限制器会在可配置的速率下分配许可证。如果必要的话，每个acquire() 会阻塞当前线程直到许可证可用后获取该许可证。一旦获取到许可证，不需要再释放许可证。RateLimiter经常用于限制对一些物理资源或者逻辑资源的访问速率。与Semaphore 相比，Semaphore 限制了并发访问的数量而不是使用速率。 123456789//每秒两个许可final RateLimiter rateLimiter = RateLimiter.create(2.0);void submitTasks(List tasks, Executor executor) &#123; for (Runnable task : tasks) &#123; rateLimiter.acquire(); // 拿不到许可就等待 executor.execute(task); &#125;&#125; 通过设置许可证的速率来定义RateLimiter。在默认配置下，许可证会在固定的速率下被分配，速率单位是每秒多少个许可证。为了确保维护配置的速率，许可会被平稳地分配，许可之间的延迟会做调整。可能存在配置一个拥有预热期的RateLimiter的情况，在这段时间内，每秒分配的许可数会稳定地增长直到达到稳定的速率。 分布式限流Remote Dictionary Server（Redis）是一个基于 key-value 键值对的持久化数据库存储系统。支持多种数据结构，包括 string (字符串)、list (链表)、set (集合)、zset (sorted set –有序集合)和 hash（哈希类型）。这些数据类型都支持 push/pop、add/remove 及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。 想实现分布式限流，非Redis莫属。Redis限流的大体思路是设置一个带有过期时间的key，每次申请令牌时，将 key 所储存的值加上增量 increment， 判断key 所存储的值是否达到上限，未达到上限，则获得许可。如有需要，亦可阻塞当前线程直到获得许可。 限流相关的命令： 事务 MULTI、EXEC、DISCARD和WATCH命令是Redis事务功能的基础，Redis事务允许在一次单独的步骤中执行一组命令，并且可以保证如下两个重要事项： Redis会将一个事务中的所有命令序列化，然后按顺序执行。 Redis不可能在一个Redis事务的执行过程中插入执行另一个客户端发出的请求。这样便能保证Redis将这些命令作为一个单独的隔离操作执行。 在一个Redis事务中，Redis要么执行其中的所有命令，要么什么都不执行。 因此，Redis事务能够保证原子性。EXEC命令会触发执行事务中的所有命令。因此，当某个客户端正在执行一次事务时，如果它在调用MULTI命令之前就从Redis服务端断开连接，那么就不会执行事务中的任何操作；相反，如果它在调用EXEC命令之后才从Redis服务端断开连接，那么就会执行事务中的所有操作。当Redis使用只增文件（AOF：Append-only File）时，Redis能够确保使用一个单独的write(2)系统调用，这样便能将事务写入磁盘。然而，如果Redis服务器宕机，或者系统管理员以某种方式停止Redis服务进程的运行，那么Redis很有可能只执行了事务中的一部分操作。Redis将会在重新启动时检查上述状态，然后退出运行，并且输出报错信息。使用redis-check-aof工具可以修复上述的只增文件，这个工具将会从上述文件中删除执行不完全的事务，这样Redis服务器才能再次启动。 从2.2版本开始，除了上述两项保证之外，Redis还能够以乐观锁(Watch)的形式提供更多的保证，这种形式非常类似于”检查再设置”（CAS：Check And Set）操作。 从2.6版本开始提供脚本（Lua scripting）能力，一种更灵活的批量命令组织方式用于取代目前的事务机制。脚本提供了更强大和灵活的编程能力，但也是一把双刃剑，由于 Redis 需要保证脚本执行的原子性和隔离性，脚本执行期间会阻塞其他命令的执行，因此建议使用高效的脚本完成业务。 SET SET key value [EX seconds] [PX milliseconds] [NX|XX] 将字符串值 value 关联到 key 。如果 key 已经持有其他值， SET 就覆写旧值，无视类型。对于某个原本带有生存时间（TTL）的键来说， 当 SET 命令成功在这个键上执行时， 这个键原有的 TTL 将被清除。 从 Redis 2.6.12 版本开始， SET 命令的行为可以通过一系列参数来修改： EX second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。PX millisecond ：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。NX ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。XX ：只在键已经存在时，才对键进行设置操作。 INCRBY 将 key 所储存的值加上增量 increment 。如果 key 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 INCRBY 命令。如果值包含错误的类型，或字符串类型的值不能表示为数字，那么返回一个错误。 Redis官方基于上述命令提供的限流代码：https://redis.io/commands/incr#pattern-rate-limiter-1 代码验证使用Jedis client进行限流方案验证： 123456789101112131415161718192021222324252627282930313233343536package hbec.app.stock.ratelimiter;/** * @author roc * @date 2018/01/24 */public interface RateLimiter &#123; /** * Acquires a permit only if one is available at the * time of invocation. * * &lt;p&gt;Acquires a permit, if one is available and returns immediately, * with the result &#123;@code LimiterResult#acquired is true&#125;, * reducing the number of available permits by one. * * &lt;p&gt;If no permit is available then this method will return * immediately with the value &#123;@code false&#125;. * * @param permits the number of permits to acquire * @return acquire result &#123;@code true&#125; if a permit was acquired, * and &#123;@code false is false&#125; otherwise */ boolean tryAcquire(int permits); /** * Acquires a permit from this method, blocking until one is * available, or the thread is &#123;@linkplain Thread#interrupt interrupted&#125;. * * &lt;p&gt;Acquires a permit, if one is available and returns immediately, * reducing the number of available permits by one. * * @param permits the number of permits to acquire */ void acquire(int permits) throws InterruptedException;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147package hbec.app.stock.ratelimiter;import com.google.common.base.Preconditions;import hbec.app.stock.commons.redis.JedisTemplate;import org.apache.commons.lang3.StringUtils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import redis.clients.jedis.Jedis;import redis.clients.jedis.Response;import redis.clients.jedis.Transaction;import java.util.Random;import java.util.concurrent.TimeUnit;/** * @author roc * @date 2018/01/23 */public class RedisRateLimiter implements RateLimiter &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RedisRateLimiter.class); private static final String ZERO = "0"; private static final String NOT_EXISTS = "NX"; private static final String P_EXPIRE = "PX"; public static final int NOT_SET = -1; private static final Random TIME_RANDOM = new Random(); /** * 限流标识，redis key */ private String rateLimiterName; /** * 存活时间 */ private int timeToLive; /** * 许可上限 */ private int upperLimitPermits; private JedisTemplate jedisTemplate; @Override public boolean tryAcquire(final int permits) &#123; Preconditions.checkArgument(permits &gt; 0, "The number of permits must be greater than 0."); return acquireSync(permits).isAcquired(); &#125; @Override public void acquire(final int permits) throws InterruptedException &#123; Preconditions.checkArgument(permits &gt; 0, "The number of permits must be greater than 0."); LimiterResult limiterResult; do &#123; limiterResult = acquireSync(permits); if (!limiterResult.isAcquired()) &#123; long sleepTime = limiterResult.getRemainderTTL() + TIME_RANDOM.nextInt(5); Thread.sleep(sleepTime); &#125; &#125; while (!limiterResult.isAcquired()); &#125; public LimiterResult acquireSync(final int permits) &#123; return jedisTemplate.execute(new JedisTemplate.JedisAction&lt;LimiterResult&gt;() &#123; @Override public LimiterResult action(Jedis jedis) &#123; Transaction transaction = jedis.multi(); transaction.set(rateLimiterName, ZERO, NOT_EXISTS, P_EXPIRE, timeToLive); Response&lt;Long&gt; currentQPS = transaction.incrBy(rateLimiterName, permits); Response&lt;Long&gt; keyTTL = transaction.pttl(rateLimiterName); transaction.exec(); Long currentPermit = currentQPS.get(); Long remainderTTL = keyTTL.get(); boolean acquired = currentPermit &lt;= upperLimitPermits; if (!acquired &amp;&amp; remainderTTL == NOT_SET) &#123; LOGGER.error("Warning! Set ttl false, key=&#123;&#125;, current ttl=&#123;&#125;", rateLimiterName, remainderTTL); jedis.expire(rateLimiterName, timeToLive); remainderTTL = (long) timeToLive; &#125; LOGGER.debug("rateLimiterName=&#123;&#125;, passed=&#123;&#125;, remainderTTL=&#123;&#125;, time=&#123;&#125;", rateLimiterName, acquired ? "true" : "false", remainderTTL, currentPermit); return LimiterResult.newInstance(acquired, remainderTTL); &#125; &#125;); &#125; public static Builder newBuilder(JedisTemplate jedisTemplate) &#123; return new Builder(jedisTemplate); &#125; public static final class Builder &#123; private JedisTemplate jedisTemplate; private String rateLimiterName; private int timeToLive; private int upperLimitPermits; private Builder(JedisTemplate jedisTemplate) &#123; Preconditions.checkNotNull(jedisTemplate, "JedisTemplate can't be null."); this.jedisTemplate = jedisTemplate; &#125; public Builder setRateLimiterName(String rateLimiterName) &#123; this.rateLimiterName = rateLimiterName; return this; &#125; public Builder setTimeToLive(int timeToLive, TimeUnit timeUnit) &#123; this.timeToLive = (int) timeUnit.toMillis(timeToLive); return this; &#125; public Builder setUpperLimitPermits(int upperLimitPermits) &#123; this.upperLimitPermits = upperLimitPermits; return this; &#125; public RedisRateLimiter build() &#123; Preconditions.checkArgument(StringUtils.isNotBlank(rateLimiterName), "RateLimiterName can't be blank."); Preconditions.checkArgument(upperLimitPermits &gt; 0, "UpperLimitPermits must be an integer greater than 0."); Preconditions.checkArgument(timeToLive &gt; 0, "TimeToLive must be an integer greater than 0."); RedisRateLimiter redisRateLimiter = new RedisRateLimiter(); redisRateLimiter.jedisTemplate = this.jedisTemplate; redisRateLimiter.upperLimitPermits = this.upperLimitPermits; redisRateLimiter.rateLimiterName = this.rateLimiterName; redisRateLimiter.timeToLive = this.timeToLive; return redisRateLimiter; &#125; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344package hbec.app.stock.ratelimiter;/** * @author roc * @date 2018/01/24 */public class LimiterResult &#123; private boolean acquired; private Long remainderTTL; public static LimiterResult newInstance(boolean acquired, Long remainderTTL) &#123; LimiterResult limiterResult = new LimiterResult(); limiterResult.setAcquired(acquired); limiterResult.setRemainderTTL(remainderTTL); return limiterResult; &#125; public boolean isAcquired() &#123; return acquired; &#125; public Long getRemainderTTL() &#123; return remainderTTL; &#125; public void setAcquired(boolean acquired) &#123; this.acquired = acquired; &#125; public void setRemainderTTL(Long remainderTTL) &#123; this.remainderTTL = remainderTTL; &#125; @Override public String toString() &#123; final StringBuilder sb = new StringBuilder("LimiterResult&#123;"); sb.append("acquired=").append(acquired); sb.append(", remainderTTL=").append(remainderTTL); sb.append('&#125;'); return sb.toString(); &#125;&#125; JedisTemplate.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855package hbec.app.stock.commons.redis;import hbec.app.stock.redis.JedisUtils;import java.util.List;import java.util.Map;import java.util.Set;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.Pipeline;import redis.clients.jedis.ScanParams;import redis.clients.jedis.ScanResult;import redis.clients.jedis.Tuple;import redis.clients.jedis.exceptions.JedisConnectionException;import redis.clients.jedis.exceptions.JedisDataException;import redis.clients.jedis.exceptions.JedisException;/** * JedisTemplate 提供了一个template方法，负责对Jedis连接的获取与归还。 * JedisAction&lt;T&gt; 和 JedisActionNoResult两种回调接口，适用于有无返回值两种情况。 * PipelineAction 与 PipelineActionResult两种接口，适合于pipeline中批量传输命令的情况。 * * 同时提供一些JedisOperation中定义的 最常用函数的封装, 如get/set/zadd等。 * * @author roc */public class JedisTemplate &#123; private static Logger logger = LoggerFactory.getLogger(JedisTemplate.class); private JedisPool jedisPool; public JedisTemplate(JedisPool jedisPool) &#123; this.jedisPool = jedisPool; &#125; /** * Callback interface for template. */ public interface JedisAction&lt;T&gt; &#123; T action(Jedis jedis); &#125; /** * Callback interface for template without result. */ public interface JedisActionNoResult &#123; void action(Jedis jedis); &#125; /** * Callback interface for template. */ public interface PipelineAction &#123; List&lt;Object&gt; action(Pipeline Pipeline); &#125; /** * Callback interface for template without result. */ public interface PipelineActionNoResult &#123; void action(Pipeline Pipeline); &#125; /** * Execute with a call back action with result. */ public &lt;T&gt; T execute(JedisAction&lt;T&gt; jedisAction) throws JedisException &#123; Jedis jedis = null; boolean broken = false; try &#123; jedis = jedisPool.getResource(); return jedisAction.action(jedis); &#125; catch (JedisException e) &#123; broken = handleJedisException(e); throw e; &#125; finally &#123; closeResource(jedis, broken); &#125; &#125; /** * Execute with a call back action without result. */ public void execute(JedisActionNoResult jedisAction) throws JedisException &#123; Jedis jedis = null; boolean broken = false; try &#123; jedis = jedisPool.getResource(); jedisAction.action(jedis); &#125; catch (JedisException e) &#123; broken = handleJedisException(e); throw e; &#125; finally &#123; closeResource(jedis, broken); &#125; &#125; /** * Execute with a call back action with result in pipeline. */ public List&lt;Object&gt; execute(PipelineAction pipelineAction) throws JedisException &#123; Jedis jedis = null; boolean broken = false; try &#123; jedis = jedisPool.getResource(); Pipeline pipeline = jedis.pipelined(); pipelineAction.action(pipeline); return pipeline.syncAndReturnAll(); &#125; catch (JedisException e) &#123; broken = handleJedisException(e); throw e; &#125; finally &#123; closeResource(jedis, broken); &#125; &#125; /** * Execute with a call back action without result in pipeline. */ public void execute(PipelineActionNoResult pipelineAction) throws JedisException &#123; Jedis jedis = null; boolean broken = false; try &#123; jedis = jedisPool.getResource(); Pipeline pipeline = jedis.pipelined(); pipelineAction.action(pipeline); pipeline.sync(); &#125; catch (JedisException e) &#123; broken = handleJedisException(e); throw e; &#125; finally &#123; closeResource(jedis, broken); &#125; &#125; /** * Handle jedisException, write log and return whether the connection is * broken. */ protected boolean handleJedisException(JedisException jedisException) &#123; if (jedisException instanceof JedisConnectionException) &#123; logger.error("Redis connection lost.", jedisException); &#125; else if (jedisException instanceof JedisDataException) &#123; if ((jedisException.getMessage() != null) &amp;&amp; (jedisException.getMessage().indexOf("READONLY") != -1)) &#123; logger.error("Redis connection are read-only slave.", jedisException); &#125; else &#123; // dataException, isBroken=false return false; &#125; &#125; else &#123; logger.error("Jedis exception happen.", jedisException); &#125; return true; &#125; /** * Return jedis connection to the pool, call different return methods * depends on the conectionBroken status. */ protected void closeResource(Jedis jedis, boolean conectionBroken) &#123; try &#123; if (conectionBroken) &#123; jedisPool.returnBrokenResource(jedis); &#125; else &#123; jedisPool.returnResource(jedis); &#125; &#125; catch (Exception e) &#123; logger.error("return back jedis failed, will fore close the jedis.", e); &#125; &#125; // / Common Actions /// /** * Remove the specified keys. If a given key does not exist no operation is * performed for this key. * * return false if one of the key is not exist. */ public Boolean del(final String... keys) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; return jedis.del(keys) == keys.length ? true : false; &#125; &#125;); &#125; // / String Actions /// /** * Get the value of the specified key. If the key does not exist null is * returned. If the value stored at key is not a string an error is returned * because GET can only handle string values. */ public String get(final String key) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; return jedis.get(key); &#125; &#125;); &#125; /** * Get the value of the specified key as Long.If the key does not exist null * is returned. */ public Long getAsLong(final String key) &#123; String result = get(key); return result != null ? Long.valueOf(result) : null; &#125; /** * Get the value of the specified key as Integer.If the key does not exist * null is returned. */ public Integer getAsInt(final String key) &#123; String result = get(key); return result != null ? Integer.valueOf(result) : null; &#125; /** * Get the value of the specified key as Boolean.If the key does not exist * null is returned. */ public Boolean getAsBoolean(final String key) &#123; String result = get(key); return result != null ? Boolean.valueOf(result) : null; &#125; /** * Get the values of all the specified keys. If one or more keys dont exist * or is not of type String, a 'nil' value is returned instead of the value * of the specified key, but the operation never fails. */ public List&lt;String&gt; mget(final String... keys) &#123; return execute(new JedisAction&lt;List&lt;String&gt;&gt;() &#123; @Override public List&lt;String&gt; action(Jedis jedis) &#123; return jedis.mget(keys); &#125; &#125;); &#125; /** * Set the string value as value of the key. The string can't be longer than * 1073741824 bytes (1 GB). */ public void set(final String key, final String value) &#123; execute(new JedisActionNoResult() &#123; @Override public void action(Jedis jedis) &#123; jedis.set(key, value); &#125; &#125;); &#125; /** * The command is exactly equivalent to the following group of commands: * &#123;@link #set(String, String) SET&#125; + &#123;@link #expire(String, int) EXPIRE&#125;. * The operation is atomic. */ public void setex(final String key, final String value, final int seconds) &#123; execute(new JedisActionNoResult() &#123; @Override public void action(Jedis jedis) &#123; jedis.setex(key, seconds, value); &#125; &#125;); &#125; /** * SETNX works exactly like &#123;@link #setNX(String, String) SET&#125; with the only * difference that if the key already exists no operation is performed. * SETNX actually means "SET if Not eXists". * * return true if the key was set. */ public Boolean setnx(final String key, final String value) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; return jedis.setnx(key, value) == 1 ? true : false; &#125; &#125;); &#125; /** * The command is exactly equivalent to the following group of commands: * &#123;@link #setex(String, String, int) SETEX&#125; + * &#123;@link #sexnx(String, String) SETNX&#125;. The operation is atomic. */ public Boolean setnxex(final String key, final String value, final int seconds) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; String result = jedis.set(key, value, "NX", "EX", seconds); return JedisUtils.isStatusOk(result); &#125; &#125;); &#125; /** * GETSET is an atomic set this value and return the old value command. Set * key to the string value and return the old value stored at key. The * string can't be longer than 1073741824 bytes (1 GB). */ public String getSet(final String key, final String value) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; return jedis.getSet(key, value); &#125; &#125;); &#125; /** * Increment the number stored at key by one. If the key does not exist or * contains a value of a wrong type, set the key to the value of "0" before * to perform the increment operation. * &lt;p&gt; * INCR commands are limited to 64 bit signed integers. * &lt;p&gt; * Note: this is actually a string operation, that is, in Redis there are * not "integer" types. Simply the string stored at the key is parsed as a * base 10 64 bit signed integer, incremented, and then converted back as a * string. * * @return Integer reply, this commands will reply with the new value of key * after the increment. */ public Long incr(final String key) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.incr(key); &#125; &#125;); &#125; public Long incrBy(final String key, final long increment) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.incrBy(key, increment); &#125; &#125;); &#125; public Double incrByFloat(final String key, final double increment) &#123; return execute(new JedisAction&lt;Double&gt;() &#123; @Override public Double action(Jedis jedis) &#123; return jedis.incrByFloat(key, increment); &#125; &#125;); &#125; /** * Decrement the number stored at key by one. If the key does not exist or * contains a value of a wrong type, set the key to the value of "0" before * to perform the decrement operation. */ public Long decr(final String key) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.decr(key); &#125; &#125;); &#125; public Long decrBy(final String key, final long decrement) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.decrBy(key, decrement); &#125; &#125;); &#125; // / Hash Actions /// /** * If key holds a hash, retrieve the value associated to the specified * field. * &lt;p&gt; * If the field is not found or the key does not exist, a special 'nil' * value is returned. */ public String hget(final String key, final String fieldName) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; return jedis.hget(key, fieldName); &#125; &#125;); &#125; public List&lt;String&gt; hmget(final String key, final String... fieldsNames) &#123; return execute(new JedisAction&lt;List&lt;String&gt;&gt;() &#123; @Override public List&lt;String&gt; action(Jedis jedis) &#123; return jedis.hmget(key, fieldsNames); &#125; &#125;); &#125; public Map&lt;String, String&gt; hgetAll(final String key) &#123; return execute(new JedisAction&lt;Map&lt;String, String&gt;&gt;() &#123; @Override public Map&lt;String, String&gt; action(Jedis jedis) &#123; return jedis.hgetAll(key); &#125; &#125;); &#125; public void hset(final String key, final String fieldName, final String value) &#123; execute(new JedisActionNoResult() &#123; @Override public void action(Jedis jedis) &#123; jedis.hset(key, fieldName, value); &#125; &#125;); &#125; public void hmset(final String key, final Map&lt;String, String&gt; map) &#123; execute(new JedisActionNoResult() &#123; @Override public void action(Jedis jedis) &#123; jedis.hmset(key, map); &#125; &#125;); &#125; public Boolean hsetnx(final String key, final String fieldName, final String value) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; return jedis.hsetnx(key, fieldName, value) == 1 ? true : false; &#125; &#125;); &#125; public Long hincrBy(final String key, final String fieldName, final long increment) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.hincrBy(key, fieldName, increment); &#125; &#125;); &#125; public Double hincrByFloat(final String key, final String fieldName, final double increment) &#123; return execute(new JedisAction&lt;Double&gt;() &#123; @Override public Double action(Jedis jedis) &#123; return jedis.hincrByFloat(key, fieldName, increment); &#125; &#125;); &#125; public Long hdel(final String key, final String... fieldsNames) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.hdel(key, fieldsNames); &#125; &#125;); &#125; public Boolean hexists(final String key, final String fieldName) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; return jedis.hexists(key, fieldName); &#125; &#125;); &#125; public Set&lt;String&gt; hkeys(final String key) &#123; return execute(new JedisAction&lt;Set&lt;String&gt;&gt;() &#123; @Override public Set&lt;String&gt; action(Jedis jedis) &#123; return jedis.hkeys(key); &#125; &#125;); &#125; public Long hlen(final String key) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.hlen(key); &#125; &#125;); &#125; // / List Actions /// public Long lpush(final String key, final String... values) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.lpush(key, values); &#125; &#125;); &#125; public String rpop(final String key) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; return jedis.rpop(key); &#125; &#125;); &#125; public String brpop(final String key) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; List&lt;String&gt; nameValuePair = jedis.brpop(key); if (nameValuePair != null) &#123; return nameValuePair.get(1); &#125; else &#123; return null; &#125; &#125; &#125;); &#125; public String brpop(final int timeout, final String key) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; List&lt;String&gt; nameValuePair = jedis.brpop(timeout, key); if (nameValuePair != null) &#123; return nameValuePair.get(1); &#125; else &#123; return null; &#125; &#125; &#125;); &#125; /** * Not support for sharding. */ public String rpoplpush(final String sourceKey, final String destinationKey) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; return jedis.rpoplpush(sourceKey, destinationKey); &#125; &#125;); &#125; /** * Not support for sharding. */ public String brpoplpush(final String source, final String destination, final int timeout) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; return jedis.brpoplpush(source, destination, timeout); &#125; &#125;); &#125; public Long llen(final String key) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.llen(key); &#125; &#125;); &#125; public String lindex(final String key, final long index) &#123; return execute(new JedisAction&lt;String&gt;() &#123; @Override public String action(Jedis jedis) &#123; return jedis.lindex(key, index); &#125; &#125;); &#125; public List&lt;String&gt; lrange(final String key, final int start, final int end) &#123; return execute(new JedisAction&lt;List&lt;String&gt;&gt;() &#123; @Override public List&lt;String&gt; action(Jedis jedis) &#123; return jedis.lrange(key, start, end); &#125; &#125;); &#125; public void ltrim(final String key, final int start, final int end) &#123; execute(new JedisActionNoResult() &#123; @Override public void action(Jedis jedis) &#123; jedis.ltrim(key, start, end); &#125; &#125;); &#125; public void ltrimFromLeft(final String key, final int size) &#123; execute(new JedisActionNoResult() &#123; @Override public void action(Jedis jedis) &#123; jedis.ltrim(key, 0, size - 1); &#125; &#125;); &#125; public Boolean lremFirst(final String key, final String value) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; Long count = jedis.lrem(key, 1, value); return (count == 1); &#125; &#125;); &#125; public Boolean lremAll(final String key, final String value) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; Long count = jedis.lrem(key, 0, value); return (count &gt; 0); &#125; &#125;); &#125; // / Set Actions /// public Boolean sadd(final String key, final String member) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; return jedis.sadd(key, member) == 1 ? true : false; &#125; &#125;); &#125; public Set&lt;String&gt; smembers(final String key) &#123; return execute(new JedisAction&lt;Set&lt;String&gt;&gt;() &#123; @Override public Set&lt;String&gt; action(Jedis jedis) &#123; return jedis.smembers(key); &#125; &#125;); &#125; // / Ordered Set Actions /// /** * return true for add new element, false for only update the score. */ public Boolean zadd(final String key, final double score, final String member) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; return jedis.zadd(key, score, member) == 1 ? true : false; &#125; &#125;); &#125; public Double zscore(final String key, final String member) &#123; return execute(new JedisAction&lt;Double&gt;() &#123; @Override public Double action(Jedis jedis) &#123; return jedis.zscore(key, member); &#125; &#125;); &#125; public Long zrank(final String key, final String member) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.zrank(key, member); &#125; &#125;); &#125; public Long zrevrank(final String key, final String member) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.zrevrank(key, member); &#125; &#125;); &#125; public Long zcount(final String key, final double min, final double max) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.zcount(key, min, max); &#125; &#125;); &#125; public Set&lt;String&gt; zrange(final String key, final int start, final int end) &#123; return execute(new JedisAction&lt;Set&lt;String&gt;&gt;() &#123; @Override public Set&lt;String&gt; action(Jedis jedis) &#123; return jedis.zrange(key, start, end); &#125; &#125;); &#125; public Set&lt;Tuple&gt; zrangeWithScores(final String key, final int start, final int end) &#123; return execute(new JedisAction&lt;Set&lt;Tuple&gt;&gt;() &#123; @Override public Set&lt;Tuple&gt; action(Jedis jedis) &#123; return jedis.zrangeWithScores(key, start, end); &#125; &#125;); &#125; public Set&lt;String&gt; zrevrange(final String key, final int start, final int end) &#123; return execute(new JedisAction&lt;Set&lt;String&gt;&gt;() &#123; @Override public Set&lt;String&gt; action(Jedis jedis) &#123; return jedis.zrevrange(key, start, end); &#125; &#125;); &#125; public Set&lt;Tuple&gt; zrevrangeWithScores(final String key, final int start, final int end) &#123; return execute(new JedisAction&lt;Set&lt;Tuple&gt;&gt;() &#123; @Override public Set&lt;Tuple&gt; action(Jedis jedis) &#123; return jedis.zrevrangeWithScores(key, start, end); &#125; &#125;); &#125; public Set&lt;String&gt; zrangeByScore(final String key, final double min, final double max) &#123; return execute(new JedisAction&lt;Set&lt;String&gt;&gt;() &#123; @Override public Set&lt;String&gt; action(Jedis jedis) &#123; return jedis.zrangeByScore(key, min, max); &#125; &#125;); &#125; public Set&lt;Tuple&gt; zrangeByScoreWithScores(final String key, final double min, final double max) &#123; return execute(new JedisAction&lt;Set&lt;Tuple&gt;&gt;() &#123; @Override public Set&lt;Tuple&gt; action(Jedis jedis) &#123; return jedis.zrangeByScoreWithScores(key, min, max); &#125; &#125;); &#125; public Set&lt;String&gt; zrevrangeByScore(final String key, final double max, final double min) &#123; return execute(new JedisAction&lt;Set&lt;String&gt;&gt;() &#123; @Override public Set&lt;String&gt; action(Jedis jedis) &#123; return jedis.zrevrangeByScore(key, max, min); &#125; &#125;); &#125; public Set&lt;Tuple&gt; zrevrangeByScoreWithScores(final String key, final double max, final double min) &#123; return execute(new JedisAction&lt;Set&lt;Tuple&gt;&gt;() &#123; @Override public Set&lt;Tuple&gt; action(Jedis jedis) &#123; return jedis.zrevrangeByScoreWithScores(key, max, min); &#125; &#125;); &#125; public Boolean zrem(final String key, final String member) &#123; return execute(new JedisAction&lt;Boolean&gt;() &#123; @Override public Boolean action(Jedis jedis) &#123; return jedis.zrem(key, member) == 1 ? true : false; &#125; &#125;); &#125; public Long zremByScore(final String key, final double start, final double end) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.zremrangeByScore(key, start, end); &#125; &#125;); &#125; public Long zremByRank(final String key, final long start, final long end) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.zremrangeByRank(key, start, end); &#125; &#125;); &#125; public Long zcard(final String key) &#123; return execute(new JedisAction&lt;Long&gt;() &#123; @Override public Long action(Jedis jedis) &#123; return jedis.zcard(key); &#125; &#125;); &#125; 验证代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package hbec.app.stock.ratelimiter;import hbec.app.stock.commons.redis.JedisTemplate;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.testng.annotations.BeforeTest;import org.testng.annotations.Test;import redis.clients.jedis.JedisPool;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;/** * @author roc * @date 2018/01/26 */public class RedisRateLimiterTest &#123; private static final Logger LOGGER = LoggerFactory.getLogger(RedisRateLimiterTest.class); private RateLimiter rateLimiter; private AtomicInteger atomicInteger = new AtomicInteger(1); @BeforeTest public void init() &#123; JedisPool jedisPool = new JedisPool("10.0.30.66", 6379); JedisTemplate jedisTemplate = new JedisTemplate(jedisPool); String rateLimiterName = "rateLimiterROC"; rateLimiter = RedisRateLimiter.newBuilder(jedisTemplate).setRateLimiterName(rateLimiterName) .setUpperLimitPermits(10).setTimeToLive(5, TimeUnit.SECONDS).build(); &#125; @Test(threadPoolSize = 10, invocationCount = 20) public void testTryAcquire() throws Exception &#123; boolean acquired = rateLimiter.tryAcquire(1); if (acquired) &#123; LOGGER.info("thread &#123;&#125; acquire the permit &#123;&#125; times.", Thread.currentThread().getId(), atomicInteger.getAndIncrement()); &#125; &#125; @Test(threadPoolSize = 10, invocationCount = 20) public void testAcquire() throws Exception &#123; rateLimiter.acquire(1); LOGGER.info("thread &#123;&#125; acquire the permit &#123;&#125; times.", Thread.currentThread().getId(), atomicInteger.getAndIncrement()); &#125;&#125; 测试用例 10个线程20次请求，限制5s内10次请求。 测试结果 10次请求在5s内正常通过，剩下10次请求等待下个时间窗口轮询。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[极光推送java-sdk-V3.2.15堵塞BUG]]></title>
      <url>%2Fblog%2F2018%2F01%2F%E6%9E%81%E5%85%89%E6%8E%A8%E9%80%81java-sdk-V3-2-15%E5%A0%B5%E5%A1%9EBUG.html</url>
      <content type="text"><![CDATA[案发现场 从RabbitMQ Server端获取消息的线程运行正常，读到数据后放到本地的BlockQueue中，等待消费者线程消费。 消费者线程堵塞，不再消费本地BlockQueue中的消息。 使用jstack进行Thread Dump分析。由于自定义消费者线程名称，所以直接筛选前缀为MessageConsumer线程，结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940"MessageConsumer-1" prio=10 tid=0x00007f39309f6000 nid=0x1047 waiting on condition [0x00007f39052d3000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000000a4b994d0&gt; (a java.util.concurrent.CountDownLatch$Sync) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186) at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:834) at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:994) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1303) at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:236) at cn.jiguang.common.connection.NettyHttpClient.sendHttpRequest(NettyHttpClient.java:193) at cn.jiguang.common.connection.NettyHttpClient.sendPost(NettyHttpClient.java:134) at cn.jpush.api.push.PushClient.sendPush(PushClient.java:194) at cn.jpush.api.JPushClient.sendPush(JPushClient.java:205) at hbec.app.platform.push.service.impl.JPushService.push(JPushService.java:66) at hbec.app.platform.push.service.impl.PushFacadeService.jpush(PushFacadeService.java:113) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at hbec.app.mc.RpcService.send(RpcService.java:38) at hbec.app.mc.NotifySendService.send(NotifySendService.java:40) at hbec.app.mc.NotifyService.notifyPerson(NotifyService.java:151) at hbec.app.mc.NotifyService.notify(NotifyService.java:83) at hbec.app.mc.rabbitmq.RealTimeConsumer.onMessage(RealTimeConsumer.java:29) at org.springframework.amqp.rabbit.listener.adapter.MessageListenerAdapter.onMessage(MessageListenerAdapter.java:273) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:848) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:771) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$001(SimpleMessageListenerContainer.java:102) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$1.invokeListener(SimpleMessageListenerContainer.java:198) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.invokeListener(SimpleMessageListenerContainer.java:1311) at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.executeListener(AbstractMessageListenerContainer.java:752) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doReceiveAndExecute(SimpleMessageListenerContainer.java:1254) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.receiveAndExecute(SimpleMessageListenerContainer.java:1224) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.access$1600(SimpleMessageListenerContainer.java:102) at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1470) at java.lang.Thread.run(Thread.java:745) Locked ownable synchronizers: - None…… 从上可以发现，消费者线程大都处于WAITING状态，线程阻塞在NettyHttpClient.sendHttpRequest的CountDownLatch.await()方法。12at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:236)at cn.jiguang.common.connection.NettyHttpClient.sendHttpRequest(NettyHttpClient.java:193) 分析推理通过对应用中各线程运行的状态情况，推测是极光推送SDK代码BUG导致。深入源码进行问题排查： 1&gt; cn.jpush.api.JPushClient.java 123public PushResult sendPush(PushPayload pushPayload) throws APIConnectionException, APIRequestException &#123; return _pushClient.sendPush(pushPayload); &#125; 2&gt; cn.jpush.api.push.PushClient.java 1234567891011121314public PushResult sendPush(PushPayload pushPayload) throws APIConnectionException, APIRequestException &#123; Preconditions.checkArgument(! (null == pushPayload), "pushPayload should not be null"); if (_apnsProduction &gt; 0) &#123; pushPayload.resetOptionsApnsProduction(true); &#125; else if(_apnsProduction == 0) &#123; pushPayload.resetOptionsApnsProduction(false); &#125; if (_timeToLive &gt;= 0) &#123; pushPayload.resetOptionsTimeToLive(_timeToLive); &#125; //该版本默认使用NettyHttpClient，进入源码 ResponseWrapper response = _httpClient.sendPost(_baseUrl + _pushPath, pushPayload.toString()); return BaseResult.fromResponse(response, PushResult.class); &#125; 3&gt; cn.jiguang.common.connection.NettyHttpClient.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455@Override public ResponseWrapper sendPost(String url, String content) throws APIConnectionException, APIRequestException &#123; ResponseWrapper wrapper = new ResponseWrapper(); try &#123; return sendHttpRequest(HttpMethod.POST, url, content); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return wrapper; &#125;private ResponseWrapper sendHttpRequest(HttpMethod method, String url, String body) throws Exception &#123; // 此处实例化CountDownLatch并传递给NettyClientInitializer, 继续跟踪 CountDownLatch latch = new CountDownLatch(1); NettyClientInitializer initializer = new NettyClientInitializer(_sslCtx, null, latch); b.handler(initializer); ResponseWrapper wrapper = new ResponseWrapper(); URI uri = new URI(url); String scheme = uri.getScheme() == null ? "http" : uri.getScheme(); String host = uri.getHost() == null ? "127.0.0.1" : uri.getHost(); int port = uri.getPort(); if (port == -1) &#123; if ("http".equalsIgnoreCase(scheme)) &#123; port = 80; &#125; else if ("https".equalsIgnoreCase(scheme)) &#123; port = 443; &#125; &#125; try &#123; ChannelFuture connect = b.connect(host, port); _channel = connect.sync().channel(); FullHttpRequest request; if (null != body) &#123; ByteBuf byteBuf = Unpooled.copiedBuffer(body.getBytes(CharsetUtil.UTF_8)); request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, method, uri.getRawPath(), byteBuf); request.headers().set(HttpHeaderNames.CONTENT_LENGTH, (long) byteBuf.readableBytes()); &#125; else &#123; request = new DefaultFullHttpRequest(HTTP_1_1, method, uri.getRawPath()); &#125; request.headers().set(HttpHeaderNames.HOST, uri.getHost()); request.headers().set(HttpHeaderNames.AUTHORIZATION, _authCode); request.headers().set("Content-Type","application/json;charset=utf-8"); connect.awaitUninterruptibly(); LOG.info("Sending request. " + request); LOG.info("Send body: " + body); _channel.writeAndFlush(request); //调用latch.await()后主线程阻塞，等待netty异步网络调用。如果异步线程执行后不调用countDown()，主线程将永远阻塞，此为问题主要原因。 latch.await(); wrapper = initializer.getResponse(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return wrapper; &#125; 4&gt; cn.jiguang.common.connection.NettyClientInitializer.java 123456@Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; //使用_latch创建HttpResponseHandler this._handler = new HttpResponseHandler(_callback, _latch); socketChannel.pipeline().addLast(_sslCtx.newHandler(socketChannel.alloc()), new HttpClientCodec(), _handler); &#125; 5&gt; cn.jiguang.common.connection.HttpResponseHandler.java1234567891011121314151617181920212223242526272829303132333435363738394041@Override protected void channelRead0(ChannelHandlerContext ctx, HttpObject msg) throws Exception &#123; if (msg instanceof HttpResponse) &#123; HttpResponse response = (HttpResponse) msg; status = response.status().code(); &#125; if (msg instanceof HttpContent) &#123; HttpContent content = (HttpContent) msg; LOG.info(content.content().toString()); if (content instanceof LastHttpContent) &#123; //断点跟踪发现，程序运行到该分支后，直接close，并未调用_latch.countDown(); 此为问题的主要爆发点 LOG.info("closing connection"); ctx.close(); &#125; else &#123; String responseContent = content.content().toString(CharsetUtil.UTF_8); _wrapper.responseCode = status; _wrapper.responseContent = responseContent; LOG.info("Got Response code: " + status + " content: " + responseContent); System.err.println("Got Response code: " + status + " content: " + responseContent); System.err.flush(); if (null != _callback) &#123; _callback.onSucceed(_wrapper); &#125; if (null != _latch) &#123; //正常情况下 _latch.countDown(); &#125; &#125; &#125; &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; LOG.error("error:", cause); try &#123; //模拟网络异常，发现此处也存在bug，未调用_latch.countDown(); 隐藏爆发点 ctx.close(); &#125;catch (Exception ex) &#123; LOG.error("close error:", ex); &#125; &#125; 翻阅源码发现HttpResponseHandler.java类内部存在两个隐患： 程序运行到if (content instanceof LastHttpContent) {……}分支后，未调用_latch.countDown(); 当出现网络异常时，exceptionCaught方法内部也未调用_latch.countDown(); 只要其中任意一个隐患爆发，主线程就会阻塞，进入WAITING状态。消费者线程就此堵塞，不再消费BlockQueue中的消息。 恢复现场 Maven pom.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;sky-framework&lt;/artifactId&gt; &lt;groupId&gt;org.sky&lt;/groupId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;jpush-test&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- jpush --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.jpush.api&lt;/groupId&gt; &lt;artifactId&gt;jpush-client&lt;/artifactId&gt; &lt;version&gt;3.2.15&lt;/version&gt; &lt;/dependency&gt; &lt;!-- utils begin --&gt; &lt;dependency&gt; &lt;groupId&gt;cn.jpush.api&lt;/groupId&gt; &lt;artifactId&gt;jiguang-common&lt;/artifactId&gt; &lt;version&gt;1.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.6.Final&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- LOGGING begin --&gt; &lt;!-- slf4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- logback --&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 代码直接调用log4j会被桥接到slf4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 代码直接调用commons-logging会被桥接到slf4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 代码直接调用java.util.logging会被桥接到slf4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- log4jdbc --&gt; &lt;dependency&gt; &lt;groupId&gt;com.googlecode.log4jdbc&lt;/groupId&gt; &lt;artifactId&gt;log4jdbc&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- LOGGING end --&gt; &lt;dependency&gt; &lt;groupId&gt;org.testng&lt;/groupId&gt; &lt;artifactId&gt;testng&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 测试代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package org.sky.jpush;import cn.jiguang.common.ClientConfig;import cn.jiguang.common.resp.APIConnectionException;import cn.jiguang.common.resp.APIRequestException;import cn.jpush.api.JPushClient;import cn.jpush.api.push.PushResult;import cn.jpush.api.push.model.Options;import cn.jpush.api.push.model.Platform;import cn.jpush.api.push.model.PushPayload;import cn.jpush.api.push.model.audience.Audience;import cn.jpush.api.push.model.audience.AudienceTarget;import cn.jpush.api.push.model.notification.IosAlert;import cn.jpush.api.push.model.notification.IosNotification;import cn.jpush.api.push.model.notification.Notification;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.testng.annotations.Test;/** * @author roc * @date 2018/01/09 */public class JPushServiceTest &#123; protected static final Logger LOG = LoggerFactory.getLogger(JPushServiceTest.class); private static final String APP_KEY = "b11314807507e2bcfdeebe2e"; private static final String MASTER_SECRET = "2c88a01e073a0fe4fc7b167c"; protected static final String GROUP_MASTER_SECRET = "b11314807507e2bcfdeebe2e"; protected static final String GROUP_PUSH_KEY = "2c88a01e073a0fe4fc7b167c"; public static final String ALERT = "JPush Test - alert"; public static final String MSG_CONTENT = "JPush Test - msgContent"; public static final String REGISTRATION_ID1 = "0900e8d85ef"; public static final String REGISTRATION_ID2 = "0a04ad7d8b4"; public static final String REGISTRATION_ID3 = "18071adc030dcba91c0"; @Test public void testNettyClient() &#123; ClientConfig clientConfig = ClientConfig.getInstance(); JPushClient jpushClient = new JPushClient(MASTER_SECRET, APP_KEY, null, clientConfig); /*String authCode = ServiceHelper.getBasicAuthorization(APP_KEY, MASTER_SECRET); ApacheHttpClient apacheHttpClient = new (authCode, null, clientConfig); jpushClient.getPushClient().setHttpClient(apacheHttpClienApacheHttpClientt); */ PushPayload payload = buildTestPayload(); try &#123; PushResult result = jpushClient.sendPush(payload); int status = result.getResponseCode(); LOG.info("Got result - " + result); &#125; catch (APIConnectionException e) &#123; LOG.error("Connection error. Should retry later. ", e); LOG.error("Sendno: " + payload.getSendno()); &#125; catch (APIRequestException e) &#123; LOG.error("Error response from JPush server. Should review and fix it. ", e); LOG.info("HTTP Status: " + e.getStatus()); LOG.info("Error Code: " + e.getErrorCode()); LOG.info("Error Message: " + e.getErrorMessage()); LOG.info("Msg ID: " + e.getMsgId()); LOG.error("Sendno: " + payload.getSendno()); &#125; &#125; public PushPayload buildTestPayload() &#123; String title = "hello world, roc"; String subTitle = "低头前行了这么久，我只是在找一个抬头的机会"; String body = "人这一生，浪费了太多的时间在毫无意义的事情上，担忧、抱怨、埋怨、比较……"; IosAlert iosAlert = IosAlert.newBuilder() .setTitleAndBody(title, subTitle, body).build(); IosNotification iosNotification = IosNotification.newBuilder() .setAlert(iosAlert).incrBadge(1) .setSound("happy").build(); Notification notification = Notification.newBuilder().addPlatformNotification(iosNotification).build(); PushPayload pushPayload = PushPayload .newBuilder() .setPlatform(Platform.android_ios()) .setAudience( Audience.newBuilder() .addAudienceTarget( AudienceTarget.alias("TEST303644")) .build()) .setNotification(notification) .setOptions(Options.newBuilder().setApnsProduction(true).build()) .build(); return pushPayload; &#125;&#125; Thread Dump Debug跟踪，发现程序进入if分支，调用close()关闭连接后，主线程阻塞进入wait状态。使用IDEA生成thread dump： 日志输出 12342018-01-09 21:12:19.064 [nioEventLoopGroup-2-1] DEBUG io.netty.handler.ssl.SslHandler - [id: 0x6f019129, L:/10.0.31.70:55848 - R:api.jpush.cn/103.40.232.116:443] HANDSHAKEN: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA2018-01-09 21:12:29.324 [nioEventLoopGroup-2-1] INFO c.j.c.connection.HttpResponseHandler - PooledSlicedByteBuf(ridx: 0, widx: 44, cap: 44/44, unwrapped: PooledUnsafeDirectByteBuf(ridx: 324, widx: 324, cap: 373))//此为HttpResponseHandler.java类log输出，与源代码吻合2018-01-09 21:12:49.010 [nioEventLoopGroup-2-1] INFO c.j.c.connection.HttpResponseHandler - closing connection 主线程处于WAIT状态，Netty异步线程已运行完毕，现场恢复成功。 解决方案 升级极光SDK版本，升级后发现最新版已解决该问题。 增加熔断处理，调用外部服务时，使用Guava SimpleTimeLimiter设置超时熔断。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Notepad++-regular-expression]]></title>
      <url>%2Fblog%2F2017%2F08%2FNotePad-regular-expression.html</url>
      <content type="text"><![CDATA[低头前行了这么久，我只是在找一个抬头的机会 Notepad++ 正则表达式用法归档 注意: 不支持多行表达式 (involving \n, \r, etc). 基本表达式 符号 解释 . 匹配任意字符，除了新一行(\n)。也就是说 “.”可以匹配 \r ，当文件中同时含有\r and \n时，会引起混乱。要匹配所有的字符，使用\s\S。 (…) 这个匹配一个标签区域. 这个标签可以被访问，通过语法 \1访问第一个标签, \2 访问第二个, 同理 \3 \4 … \9。 这些标签可以用在当前正则表达式中，或则替search和replace中的换字符串。 \1, \2, etc 在替换中代表1到9的标签区域(\1 to \9)。例如, 查找字符串 Fred([1-9])XXX 并替换为字符串 Sam\1YYY的方法，当在文件中找到Fred2XXX的字符串时，会替换为Sam2YYY。注意: 只有9个区域能使用，所以我们在使用时很安全，像\10\2 表示区域1和文本”0”以及区域2。 […] 表示一个字符集合, 例如 [abc]表示任意字符 a, b or c.我们也可以使用范围例如[a-z] 表示所以的小写字母。 [^…] 表示字符补集. 例如, [^A-Za-z] 表示任意字符除了字母表。 ^ 匹配一行的开始(除非在集合中, 如下). $ 匹配行尾. * 匹配0或多次, 例如 Sa*m 匹配 Sm, Sam, Saam, Saaam 等等. + 匹配1次或多次,例如 Sa+m 匹配 Sam, Saam, Saaam 等等. ? 匹配0或者1次, 例如 Sa?m 匹配 Sm, Sam. {n} 匹配确定的 n 次.例如, ‘Sa{2}m’ 匹配 Saam. {m,n} 匹配至少m次，至多n次(如果n缺失，则任意次数).例如, ‘Sa{2,3}m’ 匹配 Saam or Saaam. ‘Sa{2,}m’ 与 ‘Saa+m’相同 *?, +?, ??, {n,m}? 非贪心匹配，匹配第一个有效的匹配，通常 ‘&lt;.&gt;’ 会匹配整个 ‘content’字符串 –但 ‘&lt;.?&gt;’ 只匹配 ” .这个标记一个标签区域，这些区域可以用语法\1 \2 等访问多个对应1-9区域。 标记和分组 符号 解释 (…) 一组捕获. 可以通过\1 访问第一个组, \2 访问第二个. (?:…) 非捕获组. (?=…) 非捕获组 – 向前断言. 例如’(.*)(?=ton)’ 表达式，当 遇到’Appleton’字符串时，会匹配为’Apple’. (?&lt;=…) 非捕获组 – 向后断言. 例如’(?&lt;=sir) (.*)’ 表示式，当遇到’sir William’ 字符串时，匹配为’ William’. (?!…) 非捕获组 – 消极的向前断言. 例如’.(?!e)’ 表达式，当遇到’Apple’时，会找到每个字母除了 ‘l’，因为它紧跟着 ‘e’. (? 非捕获组 – 消极向后断言. 例如 ‘(? (?P…) 命名所捕获的组. 提交一个名称到组中供后续使用，例如’(?PA[^\s]+)\s(?P=first)’ 会找到 ‘Apple Apple’. 类似的 ‘(A[^\s]+)\s\1’ 使用组名而不是数字. (?=name) 匹配名为name的组. (?P…). (?#comment) 批注 –括号中的内容在匹配时将被忽略。 特殊符号 符号 解释 \s 匹配空格. 注意，会匹配标记的末尾. 使用 [[:blank:]] 来避免匹配新一行。 \S 匹配非空白 \w 匹配单词字符 \W 匹配非单词字符 \d 匹配数字字符 \D 匹配非数字字符 \b 匹配单词边界. ‘\bW\w+’ 找到W开头的单词 \B 匹配非单词边界. ‘\Be\B+’ – 找到位于单子中间的字母’e’ \&lt; This matches the start of a word using Scintilla’s definitions of words. &gt; This matches the end of a word using Scintilla’s definition of words. \x 运行用x来表达可能具有其他意思的字符。例如, [ 用来插入到文本中作为[ 而不是作为字符集的开始. 字符类 符号 解释 [[:alpha:]] 匹配字母字符: [A-Za-z] [[:digit:]] 匹配数字字符: [0-9] [[:xdigit:]] 匹配16进制字符: [0-9A-Fa-f] [[:alnum:]] 匹配字母数字字符: [0-9A-Za-z] [[:lower:]] 匹配小写字符: [a-z] [[:upper:]] 匹配大写字符: [A-Z] [[:blank:]] 匹配空白 (空格 or tab):[ \t] [[:space:]] 匹配空白字符:[ \t\r\n\v\f] [[:punct:]] 匹配标点字符: [-!”#$%&amp;’()*+,./:;&lt;=&gt;?@[]_`{ [[:graph:]] 匹配图形字符: [\x21-\x7E] [[:print:]] 匹配可打印的字符 (graphical characters and spaces) [[:cntrl:]] 匹配控制字符 替换操作使用正则表达式的标记，通过（）来包围想要用的字符，然后用\1 来替换字符串，第一个匹配文本。 例如: Text body Search string Replace string ResultHi my name is Fred my name is (.+) my name is not \1 Hi my name is not FredThe quick brown fox jumped over the fat lazy dog brown (.+) jumped over the (.+) brown \2 jumped over the \1 The quick brown fat jumped over the fox lazy dog 限制Support for regular expressions in PN2 is currently limited, the supported patterns and syntax are a very small subset of the powerful expressions supported by perl. 最大的限制是正则表达式只能匹配单行，不能用多行匹配表达。可以用Backslash Expressions代替. 准备计划是使用PCRE库 library (used elsewhere in PN2) 来支持文档搜索. 原文：http://www.pnotepad.org/docs/search/regular_expressions/ 应用举例删除空白行的方法选择替换，把查找模式设置为正则表达式，在查找框中输入 ^\s+ ,替换框留空，点“全部替换”，即可(先全选)。 删除所有行s字符开始后面的所有字符选择替换，把查找模式设置为正则表达式，在查找框中输入 ^([^:]):.$，替换框填写$1，点“全部替换”，即可(先全选)。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[svn-sqliteS10-disk-IO-error]]></title>
      <url>%2Fblog%2F2017%2F08%2Fsvn-sqliteS10-disk-IO-error.html</url>
      <content type="text"><![CDATA[低头前行，莫问前程。 在使用svn提交项目时，遇到报错：svn: E200030: sqlite[S10]: disk I/O error 在使用svn提交项目时，遇到报错： 123456789svn: E155004: Run 'svn cleanup' to remove locks (type 'svn help cleanup' for details)svn: E155004: Failed to lock working copy 'F:\workspace-new\idea-workspace\hbec-app-stock-project'.svn: E200030: sqlite[S10]: disk I/O errorsvn: E200042: Additional errors:svn: E200030: sqlite[S10]: disk I/O errorsvn: E200030: sqlite[S1]: no such savepoint: svnsvn: E200030: sqlite[S1]: no such savepoint: svnsvn: E200030: sqlite[S1]: no such savepoint: svnsvn: E200030: sqlite[S1]: no such savepoint: svn 此时可通过sqlite3工具来修复，具体步骤为： 下载sqlite3工具，下载地址为：http://www.sqlite.org/download.html 将sqlite3.exe文件解压缩到.svn目录的同级目录 打开命令行工具，切换到.svn的同级目录 执行命令： sqlite3.exe .svn/wc.db “reindex nodes” sqlite3.exe .svn/wc.db “reindex pristine”]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[deadlock-found-when-trying-to-get-lock]]></title>
      <url>%2Fblog%2F2017%2F07%2Fdeadlock-found-when-trying-to-get-lock.html</url>
      <content type="text"><![CDATA[mysql锁机制分为表级锁和行级锁： 共享锁又称为读锁，简称S锁，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。 排他锁又称为写锁，简称X锁，顾名思义，排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。 对于共享锁大家可能很好理解，就是多个事务只能读数据不能改数据，对于排他锁大家的理解可能就有些差别，我当初就犯了一个错误，以为排他锁锁住一行数据后，其他事务就不能读取和修改该行数据，其实不是这样的。排他锁指的是一个事务在一行数据加上排他锁后，其他事务不能再在其上加其他的锁。mysql InnoDB引擎默认的修改数据语句，update,delete,insert都会自动给涉及到的数据加上排他锁，select语句默认不会加任何锁类型，如果加排他锁可以使用select …for update语句，加共享锁可以使用select … lock in share mode语句。所以加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过for update和lock in share mode锁的方式查询数据，但可以直接通过select …from…查询数据，因为普通查询没有任何锁机制。 案发现场API网关在30ms内收到6次相同请求，错误日志： 12345678910111213141516171819Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.754 [http-apr-8080-exec-1379] INFO h.a.a.f.AppPlatformRateLimiterFilter - parameter=_appCrypt_=VDzT76Hdrp9QAO4lSbQuJeIaKnQ8VZnqljK+YmN2W1tyBSv1JqIhTrDHrBlWM9K8yg3kcLOUmENr1OUc+6xWSL13Z2jaBhCJDrMYWad/H971ilDd4eQMrakZP84dCbXC&amp;_t_=HBStockWarningIos_3.6.4&amp;ticket=7.BdzpPOeP2_7JV6IYArPBIOC36NO2PoCMhVPHiISIEM_tAo7-unTlp_baBhZ79TZskD-HBIBmSnk-7y_tv24wD2IiSgTHlj7x5DTHEV7CacwVdw9jmTCuVdePd4mUaM11k5XGRSsPzqzQmomKMu7aGm8R48Nq-ECE7WpSNtQmExU&amp;Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.756 [http-apr-8080-exec-1379] INFO sky.app.api.filter.RateLimiter - userId:3245964, 在 5s 内第1次 执行操作 http://api.*.com/followStockService.follow, 通过流速控制器, 阀值(5s最高40次)Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.756 [http-apr-8080-exec-1319] INFO sky.app.api.filter.RateLimiter - userId:3245964, 在 5s 内第2次 执行操作 http://api.*.com/followStockService.follow, 通过流速控制器, 阀值(5s最高40次)Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.757 [http-apr-8080-exec-1319] DEBUG h.p.commons.web.HbecApiHandleAdapter - param-sha1 : null, appCrypt&lt;1&gt; : VDzT76Hdrp9QAO4lSbQuJeIaKnQ8VZnqljK+YmN2W1tyBSv1JqIhTrDHrBlWM9K8yg3kcLOUmENr1OUc+6xWSL13Z2jaBhCJDrMYWad/H971ilDd4eQMrakZP84dCbXC, dataKey=l7g19q1$g#*o9v-1Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.755 [http-apr-8080-exec-1414] INFO h.a.a.f.AppPlatformRateLimiterFilter - http request=http://api.*.com/followStockService.followJul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.755 [http-apr-8080-exec-1414] INFO h.a.a.f.AppPlatformRateLimiterFilter - Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.757 [http-apr-8080-exec-1414] INFO sky.app.api.filter.RateLimiter - userId:3245964, 在 5s 内第3次 执行操作 http://api.*.com/followStockService.follow, 通过流速控制器, 阀值(5s最高40次)Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.756 [http-apr-8080-exec-1457] INFO h.a.a.f.AppPlatformRateLimiterFilter - http request=http://api.*.com/followStockService.followJul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.756 [http-apr-8080-exec-1457] INFO h.a.a.f.AppPlatformRateLimiterFilter - Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.757 [http-apr-8080-exec-1457] INFO sky.app.api.filter.RateLimiter - userId:3245964, 在 5s 内第4次 执行操作 http://api.*.com/followStockService.follow, 通过流速控制器, 阀值(5s最高40次)Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.757 [http-apr-8080-exec-1334] INFO h.a.a.f.AppPlatformRateLimiterFilter - http request=http://api.*.com/followStockService.followJul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.757 [http-apr-8080-exec-1334] INFO h.a.a.f.AppPlatformRateLimiterFilter - parameter=_appCrypt_=VDzT76Hdrp9QAO4lSbQuJeIaKnQ8VZnqljK+YmN2W1tyBSv1JqIhTrDHrBlWM9K8yg3kcLOUmENr1OUc+6xWSL13Z2jaBhCJDrMYWad/H971ilDd4eQMrakZP84dCbXC&amp;_t_=HBStockWarningIos_3.6.4&amp;ticket=7.BdzpPOeP2_7JV6IYArPBIOC36NO2PoCMhVPHiISIEM_tAo7-unTlp_baBhZ79TZskD-HBIBmSnk-7y_tv24wD2IiSgTHlj7x5DTHEV7CacwVdw9jmTCuVdePd4mUaM11k5XGRSsPzqzQmomKMu7aGm8R48Nq-ECE7WpSNtQmExU&amp;Jul 23 17:12:50 iZ23qpg65e4Z api_qianqian1 2017-07-23 17:12:50.759 [http-apr-8080-exec-1334] INFO sky.app.api.filter.RateLimiter - userId:3245964, 在 5s 内第5次 执行操作 http://api.*.com/followStockService.follow, 通过流速控制器, 阀值(5s最高40次) 业务日志 追踪到业务节点后，发现mysql出现死锁问题：Deadlock found when trying to get lock; try restarting transaction 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103Jul 23 17:12:50 iZ2360o6lpyZ warn1 17-07-23 17:12:50.779 ERROR[DubboServerHandler-10.253.17.105:20880-thread-193 DbService.execute:1247] &#123;&#125;Jul 23 17:12:50 iZ2360o6lpyZ warn1 sky.platform.commons.exceptions.HbecDbServiceException: service=db,message=sky.platform.commons.exceptions.HbecDbServiceException: service=db,message=Jul 23 17:12:50 iZ2360o6lpyZ warn1 ### Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 ### The error may involve WarnFollowMapper.follow-InlineJul 23 17:12:50 iZ2360o6lpyZ warn1 ### The error occurred while setting parametersJul 23 17:12:50 iZ2360o6lpyZ warn1 ### SQL: insert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (?, ?, ?, ?,?, ?, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = ?) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= ?)Jul 23 17:12:50 iZ2360o6lpyZ warn1 ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.platform.runtime.DbServiceInterceptor$1.execute(DbServiceInterceptor.java:39) ~[hbec-platform-commons-0.0.32-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.platform.runtime.DbService.execute(DbService.java:1242) ~[hbec-platform-commons-0.0.32-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.platform.runtime.DbServiceInterceptor.intercept(DbServiceInterceptor.java:33) [hbec-platform-commons-0.0.32-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.app.stock.follow.service.impl.WarnFollowServiceImpl$$EnhancerByCGLIB$$41e28e09.follow(&lt;generated&gt;) [spring-core-4.0.2.RELEASE.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.app.stock.follow.controller.impl.FollowStockControllerImpl.follow(FollowStockControllerImpl.java:304) [hbec-app-stock-follow-1.0.2-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.common.bytecode.Wrapper94.invokeMethod(Wrapper94.java) [na:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:46) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:72) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:53) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:64) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:42) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:75) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:78) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.app.eagleeye.dubbo.EagleeyeFilter.invoke(EagleeyeFilter.java:155) [hbec-platform-runtime-app-0.0.32-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:60) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:112) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:38) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:38) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:91) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:108) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:84) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:170) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:52) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:82) [dubbo-2.5.3.jar:2.5.3]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at java.lang.Thread.run(Thread.java:745) [na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 Caused by: java.lang.RuntimeException: sky.platform.commons.exceptions.HbecDbServiceException: service=db,message=Jul 23 17:12:50 iZ2360o6lpyZ warn1 ### Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 ### The error may involve WarnFollowMapper.follow-InlineJul 23 17:12:50 iZ2360o6lpyZ warn1 ### The error occurred while setting parametersJul 23 17:12:50 iZ2360o6lpyZ warn1 ### SQL: insert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (?, ?, ?, ?,?, ?, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = ?) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= ?)Jul 23 17:12:50 iZ2360o6lpyZ warn1 ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.app.stock.follow.repository.impl.WarnFollowRepository.follow(WarnFollowRepository.java:238) ~[hbec-app-stock-follow-1.0.2-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.app.stock.follow.service.impl.WarnFollowServiceImpl.follow(WarnFollowServiceImpl.java:87) ~[hbec-app-stock-follow-1.0.2-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.app.stock.follow.service.impl.WarnFollowServiceImpl$$EnhancerByCGLIB$$41e28e09.CGLIB$follow$0(&lt;generated&gt;) [spring-core-4.0.2.RELEASE.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.app.stock.follow.service.impl.WarnFollowServiceImpl$$EnhancerByCGLIB$$41e28e09$$FastClassByCGLIB$$cf1f7d1b.invoke(&lt;generated&gt;) ~[spring-core-4.0.2.RELEASE.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) ~[spring-core-4.0.2.RELEASE.jar:4.0.2.RELEASE]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.platform.runtime.DbServiceInterceptor$1.execute(DbServiceInterceptor.java:37) ~[hbec-platform-commons-0.0.32-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 ... 34 common frames omittedJul 23 17:12:50 iZ2360o6lpyZ warn1 Caused by: sky.platform.commons.exceptions.HbecDbServiceException: service=db,message=Jul 23 17:12:50 iZ2360o6lpyZ warn1 ### Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 ### The error may involve WarnFollowMapper.follow-InlineJul 23 17:12:50 iZ2360o6lpyZ warn1 ### The error occurred while setting parametersJul 23 17:12:50 iZ2360o6lpyZ warn1 ### SQL: insert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (?, ?, ?, ?,?, ?, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = ?) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= ?)Jul 23 17:12:50 iZ2360o6lpyZ warn1 ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.platform.runtime.DbService.myInsert(DbService.java:2345) ~[hbec-platform-commons-0.0.32-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.app.stock.follow.repository.impl.WarnFollowRepository.follow(WarnFollowRepository.java:236) ~[hbec-app-stock-follow-1.0.2-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 ... 39 common frames omittedJul 23 17:12:50 iZ2360o6lpyZ warn1 Caused by: org.apache.ibatis.exceptions.PersistenceException: Jul 23 17:12:50 iZ2360o6lpyZ warn1 ### Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 ### The error may involve WarnFollowMapper.follow-InlineJul 23 17:12:50 iZ2360o6lpyZ warn1 ### The error occurred while setting parametersJul 23 17:12:50 iZ2360o6lpyZ warn1 ### SQL: insert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (?, ?, ?, ?,?, ?, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = ?) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= ?)Jul 23 17:12:50 iZ2360o6lpyZ warn1 ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:26) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:154) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:141) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sky.platform.runtime.DbService.myInsert(DbService.java:2331) ~[hbec-platform-commons-0.0.32-SNAPSHOT.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 ... 40 common frames omittedJul 23 17:12:50 iZ2360o6lpyZ warn1 Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transactionJul 23 17:12:50 iZ2360o6lpyZ warn1 at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.Util.handleNewInstance(Util.java:411) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.Util.getInstance(Util.java:386) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1066) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4237) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4169) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2617) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2778) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2825) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2156) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1379) ~[mysql-connector-java-5.1.28.jar:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sun.reflect.GeneratedMethodAccessor199.invoke(Unknown Source) ~[na:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_55]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.logging.jdbc.PreparedStatementLogger.invoke(PreparedStatementLogger.java:62) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at com.sun.proxy.$Proxy28.execute(Unknown Source) ~[na:na]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:44) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:69) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:48) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:105) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:71) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:152) ~[mybatis-3.2.8.jar:3.2.8]Jul 23 17:12:50 iZ2360o6lpyZ warn1 ... 42 common frames omittedJul 23 17:12:50 iZ2360o6lpyZ warn1 17-07-23 17:12:50.780 DEBUG[DubboServerHandler-10.253.17.105:20880-thread-192 follow.debug:139]MYBATIS &lt;== Updates: 2 查看数据库引擎状态 1show engine innodb status 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950------------------------LATEST DETECTED DEADLOCK------------------------2017-07-23 17:13:58 2afc664c2700*** (1) TRANSACTION:TRANSACTION 730441984, ACTIVE 0.003 sec insertingmysql tables in use 3, locked 3LOCK WAIT 8 lock struct(s), heap size 2936, 37 row lock(s), undo log entries 1LOCK BLOCKING MySQL thread id: 12246957 block 12256080MySQL thread id 12256080, OS thread handle 0x2afc48c40700, query id 3543571324 10.253.17.105 test_app Sending datainsert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (3245964, 4, '601318', 'SH','中国平安', null, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = 3245964) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= 3245964)*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 1198 page no 842 n bits 696 index `unique_index` of table `wndb`.`test_follow` trx id 730441984 lock_mode X waitingRecord lock, heap no 624 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 8031878c; asc 1 ;; 1: len 1; hex 84; asc ;; 2: len 6; hex 363031333138; asc 601318;; 3: len 4; hex 800399cb; asc ;;*** (2) TRANSACTION:TRANSACTION 730441985, ACTIVE 0.001 sec insertingmysql tables in use 3, locked 38 lock struct(s), heap size 2936, 37 row lock(s), undo log entries 1MySQL thread id 12246957, OS thread handle 0x2afc664c2700, query id 3543571329 10.253.17.105 test_app Sending datainsert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (3245964, 4, '601318', 'SH','中国平安', null, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = 3245964) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= 3245964)*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 1198 page no 842 n bits 696 index `unique_index` of table `wndb`.`test_follow` trx id 730441985 lock mode S locks rec but not gapRecord lock, heap no 624 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 8031878c; asc 1 ;; 1: len 1; hex 84; asc ;; 2: len 6; hex 363031333138; asc 601318;; 3: len 4; hex 800399cb; asc ;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 1198 page no 842 n bits 696 index `unique_index` of table `wndb`.`test_follow` trx id 730441985 lock_mode X waitingRecord lock, heap no 624 PHYSICAL RECORD: n_fields 4; compact format; info bits 0 0: len 4; hex 8031878c; asc 1 ;; 1: len 1; hex 84; asc ;; 2: len 6; hex 363031333138; asc 601318;; 3: len 4; hex 800399cb; asc ;;*** WE ROLL BACK TRANSACTION (2) 从中可以看到两个事务在等待X锁1234567891011WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 1198 page no 842 n bits 696 index `unique_index` of table `wndb`.`test_follow` trx id 730441984 lock_mode X waitingRecord lock(2) HOLDS THE LOCK(S):RECORD LOCKS space id 1198 page no 842 n bits 696 index `unique_index` of table `wndb`.`test_follow` trx id 730441985 lock mode S locks rec but not gapRecord lock, heap no 624 PHYSICAL RECORD(2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 1198 page no 842 n bits 696 index `unique_index` of table `wndb`.`test_follow` trx id 730441985 lock_mode X waitingRecord lock, heap no 624 PHYSICAL RECORD 重现1.准备工作 同时开启三个command prompt，远程连接mysql服务器：mysql -uroc -proc -h10.0.30.59 wndb 关闭自动提交：set autocommit=0 2.模拟请求Session A123begin;insert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (3245964, 4, '600628', 'SH','新世界', null, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = 3245964) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= 3245964); Session B123begin;insert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (3245964, 4, '600628', 'SH','新世界', null, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = 3245964) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= 3245964); Session C123begin;insert into test_follow (user_id, security_type, stock_code, exchange, stock_name, sub_fund_type, sort) values (3245964, 4, '600628', 'SH','新世界', null, (select max(IFNULL(t1.sort,0)) + 1 from test_FOLLOW t1 where t1.user_id = 3245964) ) on duplicate key update sort= (select max(IFNULL(t2.sort,0)) + 1 from test_follow t2 where t2.user_id= 3245964); commit Session A，session B与session C竞争X锁，直接报错: 解决首先这是个添加操作，APP端不应该对同一用户、同一只股票执行多次并发添加操作，APP端需要解决单设备、多并发问题。后台针对同一用户、同一股票的添加操作，需要使用分布式锁控制并发。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[micro-services]]></title>
      <url>%2Fblog%2F2017%2F07%2Fmicro-services.html</url>
      <content type="text"><![CDATA[微服务是一种架构风格，一个大型复杂软件应用由一个或多个微服务组成。系统中的各个微服务可被独立部署，各个微服务之间是松耦合的。每个微服务仅关注于完成一件任务并很好地完成该任务。在所有情况下，每个任务代表着一个小的业务能力。 MicroServices、Docker、SOA、Agile、Cloud、DevOps等等这类名词的最大特点就是： 一解释就懂，一问就不知，一讨论就打架。 微服务是当前互联网业界的一个技术热点，可提到这个词，大家都有共同的疑问： 一个微服务架构有哪些技术关注点(technical concerns)？ 需要哪些基础框架或组件来支持微服务架构？ 这些框架或组件该如何选型？ 本篇博客整理自 实施微服务，我们需要哪些基础框架？ 解析微服务架构(一)：什么是微服务 ##服务注册、发现、负载均衡和健康检查 和单块(Monolithic)架构不同，微服务架构是由一系列职责单一的细粒度服务构成的分布式网状结构，服务之间通过轻量机制进行通信，这时候必然引入一个服务注册发现问题，也就是说服务提供方要注册通告服务地址，服务的调用方要能发现目标服务，同时服务提供方一般以集群方式提供服务，也就引入了负载均衡和健康检查问题。根据负载均衡LB所在位置的不同，目前主要的服务注册、发现和负载均衡方案有三种： ###第一种是集中式LB方案如下图Fig 1，在服务消费者和服务提供者之间有一个独立的LB，LB通常是专门的硬件设备如F5，或者基于软件如LVS，HAproxy等实现。LB上有所有服务的地址映射表，通常由运维配置注册，当服务消费方调用某个目标服务时，它向LB发起请求，由LB以某种策略（比如Round-Robin）做负载均衡后将请求转发到目标服务。LB一般具备健康检查能力，能自动摘除不健康的服务实例。服务消费方如何发现LB呢？通常的做法是通过DNS，运维人员为服务配置一个DNS域名，这个域名指向LB。 Fig 1, 集中式LB方案 集中式LB方案实现简单，在LB上也容易做集中式的访问控制，这一方案目前还是业界主流。集中式LB的主要问题是单点问题，所有服务调用流量都经过LB，当服务数量和调用量大的时候，LB容易成为瓶颈，且一旦LB发生故障对整个系统的影响是灾难性的。另外，LB在服务消费方和服务提供方之间增加了一跳(hop)，有一定性能开销。 ###第二种是进程内LB方案针对集中式LB的不足，进程内LB方案将LB的功能以库的形式集成到服务消费方进程里头，该方案也被称为软负载(Soft Load Balancing)或者客户端负载方案，下图Fig 2展示了这种方案的工作原理。这一方案需要一个服务注册表(Service Registry)配合支持服务自注册和自发现，服务提供方启动时，首先将服务地址注册到服务注册表（同时定期报心跳到服务注册表以表明服务的存活状态，相当于健康检查），服务消费方要访问某个服务时，它通过内置的LB组件向服务注册表查询（同时缓存并定期刷新）目标服务地址列表，然后以某种负载均衡策略选择一个目标服务地址，最后向目标服务发起请求。这一方案对服务注册表的可用性(Availability)要求很高，一般采用能满足高可用分布式一致的组件（例如Zookeeper, Consul, Etcd等）来实现。 Fig 2, 进程内LB方案 进程内LB方案是一种分布式方案，LB和服务发现能力被分散到每一个服务消费者的进程内部，同时服务消费方和服务提供方之间是直接调用，没有额外开销，性能比较好。但是，该方案以客户库(Client Library)的方式集成到服务调用方进程里头，如果企业内有多种不同的语言栈，就要配合开发多种不同的客户端，有一定的研发和维护成本。另外，一旦客户端跟随服务调用方发布到生产环境中，后续如果要对客户库进行升级，势必要求服务调用方修改代码并重新发布，所以该方案的升级推广有不小的阻力。 进程内LB的案例是Netflix的开源服务框架，对应的组件分别是：Eureka服务注册表，Karyon服务端框架支持服务自注册和健康检查，Ribbon客户端框架支持服务自发现和软路由。另外，阿里开源的服务框架Dubbo也是采用类似机制。 ###第三种是主机独立LB进程方案该方案是针对第二种方案的不足而提出的一种折中方案，原理和第二种方案基本类似，不同之处是，他将LB和服务发现功能从进程内移出来，变成主机上的一个独立进程，主机上的一个或者多个服务要访问目标服务时，他们都通过同一主机上的独立LB进程做服务发现和负载均衡，见下图Fig 3。 Fig 3 主机独立LB进程方案 该方案也是一种分布式方案，没有单点问题，一个LB进程挂了只影响该主机上的服务调用方，服务调用方和LB之间是进程间调用，性能好，同时，该方案还简化了服务调用方，不需要为不同语言开发客户库，LB的升级不需要服务调用方改代码。该方案的不足是部署较复杂，环节多，出错调试排查问题不方便。 该方案的典型案例是Airbnb的SmartStack服务发现框架，对应组件分别是：Zookeeper作为服务注册表，Nerve独立进程负责服务注册和健康检查，Synapse/HAproxy独立进程负责服务发现和负载均衡。Google最新推出的基于容器的PaaS平台Kubernetes，其内部服务发现采用类似的机制。 ##服务前端路由 微服务除了内部相互之间调用和通信之外，最终要以某种方式暴露出去，才能让外界系统（例如客户的浏览器、移动设备等等）访问到，这就涉及服务的前端路由，对应的组件是服务网关(Service Gateway)，见图Fig 4，网关是连接企业内部和外部系统的一道门，有如下关键作用： 服务反向路由，网关要负责将外部请求反向路由到内部具体的微服务，这样虽然企业内部是复杂的分布式微服务结构，但是外部系统从网关上看到的就像是一个统一的完整服务，网关屏蔽了后台服务的复杂性，同时也屏蔽了后台服务的升级和变化。 安全认证和防爬虫，所有外部请求必须经过网关，网关可以集中对访问进行安全控制，比如用户认证和授权，同时还可以分析访问模式实现防爬虫功能，网关是连接企业内外系统的安全之门。 限流和容错，在流量高峰期，网关可以限制流量，保护后台系统不被大流量冲垮，在内部系统出现故障时，网关可以集中做容错，保持外部良好的用户体验。 监控，网关可以集中监控访问量，调用延迟，错误计数和访问模式，为后端的性能优化或者扩容提供数据支持。 日志，网关可以收集所有的访问日志，进入后台系统做进一步分析。 Fig 4, 服务网关 除以上基本能力外，网关还可以实现线上引流，线上压测，线上调试(Surgical debugging)，金丝雀测试(Canary Testing)，数据中心双活(Active-Active HA)等高级功能。 网关通常工作在7层，有一定的计算逻辑，一般以集群方式部署，前置LB进行负载均衡。 开源的网关组件有Netflix的Zuul，特点是动态可热部署的过滤器(filter)机制，其它如HAproxy，Nginx等都可以扩展作为网关使用。 在介绍过服务注册表和网关等组件之后，我们可以通过一个简化的微服务架构图(Fig 5)来更加直观地展示整个微服务体系内的服务注册发现和路由机制，该图假定采用进程内LB服务发现和负载均衡机制。在下图Fig 5的微服务架构中，服务简化为两层，后端通用服务（也称中间层服务Middle Tier Service）和前端服务（也称边缘服务Edge Service，前端服务的作用是对后端服务做必要的聚合和裁剪后暴露给外部不同的设备，如PC，Pad或者Phone）。后端服务启动时会将地址信息注册到服务注册表，前端服务通过查询服务注册表就可以发现然后调用后端服务；前端服务启动时也会将地址信息注册到服务注册表，这样网关通过查询服务注册表就可以将请求路由到目标前端服务，这样整个微服务体系的服务自注册自发现和软路由就通过服务注册表和网关串联起来了。如果以面向对象设计模式的视角来看，网关类似Proxy代理或者Façade门面模式，而服务注册表和服务自注册自发现类似IoC依赖注入模式，微服务可以理解为基于网关代理和注册表IoC构建的分布式系统。 Fig 5, 简化的微服务架构图 ##服务容错 当企业微服务化以后，服务之间会有错综复杂的依赖关系，例如，一个前端请求一般会依赖于多个后端服务，技术上称为1 -&gt; N扇出(见图Fig 6)。在实际生产环境中，服务往往不是百分百可靠，服务可能会出错或者产生延迟，如果一个应用不能对其依赖的故障进行容错和隔离，那么该应用本身就处在被拖垮的风险中。在一个高流量的网站中，某个单一后端一旦发生延迟，可能在数秒内导致所有应用资源(线程，队列等)被耗尽，造成所谓的雪崩效应(Cascading Failure，见图Fig 7)，严重时可致整个网站瘫痪。 Fig 6, 服务依赖 Fig 7, 高峰期单个服务延迟致雪崩效应 经过多年的探索和实践，业界在分布式服务容错一块探索出了一套有效的容错模式和最佳实践，主要包括： 电路熔断器模式(Circuit Breaker Patten), 该模式的原理类似于家里的电路熔断器，如果家里的电路发生短路，熔断器能够主动熔断电路，以避免灾难性损失。在分布式系统中应用电路熔断器模式后，当目标服务慢或者大量超时，调用方能够主动熔断，以防止服务被进一步拖垮；如果情况又好转了，电路又能自动恢复，这就是所谓的弹性容错，系统有自恢复能力。下图Fig 8是一个典型的具备弹性恢复能力的电路保护器状态图，正常状态下，电路处于关闭状态(Closed)，如果调用持续出错或者超时，电路被打开进入熔断状态(Open)，后续一段时间内的所有调用都会被拒绝(Fail Fast)，一段时间以后，保护器会尝试进入半熔断状态(Half-Open)，允许少量请求进来尝试，如果调用仍然失败，则回到熔断状态，如果调用成功，则回到电路闭合状态。Fig 8, 弹性电路保护状态图 舱壁隔离模式(Bulkhead Isolation Pattern)，顾名思义，该模式像舱壁一样对资源或失败单元进行隔离，如果一个船舱破了进水，只损失一个船舱，其它船舱可以不受影响 。线程隔离(Thread Isolation)就是舱壁隔离模式的一个例子，假定一个应用程序A调用了Svc1/Svc2/Svc3三个服务，且部署A的容器一共有120个工作线程，采用线程隔离机制，可以给对Svc1/Svc2/Svc3的调用各分配40个线程，当Svc2慢了，给Svc2分配的40个线程因慢而阻塞并最终耗尽，线程隔离可以保证给Svc1/Svc3分配的80个线程可以不受影响，如果没有这种隔离机制，当Svc2慢的时候，120个工作线程会很快全部被对Svc2的调用吃光，整个应用程序会全部慢下来。 限流(Rate Limiting/Load Shedder)，服务总有容量限制，没有限流机制的服务很容易在突发流量(秒杀，双十一)时被冲垮。限流通常指对服务限定并发访问量，比如单位时间只允许100个并发调用，对超过这个限制的请求要拒绝并回退。 回退(fallback)，在熔断或者限流发生的时候，应用程序的后续处理逻辑是什么？回退是系统的弹性恢复能力，常见的处理策略有，直接抛出异常，也称快速失败(Fail Fast)，也可以返回空值或缺省值，还可以返回备份数据，如果主服务熔断了，可以从备份服务获取数据。 Netflix将上述容错模式和最佳实践集成到一个称为Hystrix的开源组件中，凡是需要容错的依赖点(服务，缓存，数据库访问等)，开发人员只需要将调用封装在Hystrix Command里头，则相关调用就自动置于Hystrix的弹性容错保护之下。Hystrix组件已经在Netflix经过多年运维验证，是Netflix微服务平台稳定性和弹性的基石，正逐渐被社区接受为标准容错组件。 服务框架 微服务化以后，为了让业务开发人员专注于业务逻辑实现，避免冗余和重复劳动，规范研发提升效率，必然要将一些公共关注点推到框架层面。服务框架(Fig 9)主要封装公共关注点逻辑，包括： Fig 9, 服务框架 服务注册、发现、负载均衡和健康检查，假定采用进程内LB方案，那么服务自注册一般统一做在服务器端框架中，健康检查逻辑由具体业务服务定制，框架层提供调用健康检查逻辑的机制，服务发现和负载均衡则集成在服务客户端框架中。 监控日志，框架一方面要记录重要的框架层日志、metrics和调用链数据，还要将日志、metrics等接口暴露出来，让业务层能根据需要记录业务日志数据。在运行环境中，所有日志数据一般集中落地到企业后台日志系统，做进一步分析和处理。 REST/RPC和序列化，框架层要支持将业务逻辑以HTTP/REST或者RPC方式暴露出来，HTTP/REST是当前主流API暴露方式，在性能要求高的场合则可采用Binary/RPC方式。针对当前多样化的设备类型(浏览器、普通PC、无线设备等)，框架层要支持可定制的序列化机制，例如，对浏览器，框架支持输出Ajax友好的JSON消息格式，而对无线设备上的Native App，框架支持输出性能高的Binary消息格式。 配置，除了支持普通配置文件方式的配置，框架层还可集成动态运行时配置，能够在运行时针对不同环境动态调整服务的参数和配置。 限流和容错，框架集成限流容错组件，能够在运行时自动限流和容错，保护服务，如果进一步和动态配置相结合，还可以实现动态限流和熔断。 管理接口，框架集成管理接口，一方面可以在线查看框架和服务内部状态，同时还可以动态调整内部状态，对调试、监控和管理能提供快速反馈。Spring Boot微框架的Actuator模块就是一个强大的管理接口。 统一错误处理，对于框架层和服务的内部异常，如果框架层能够统一处理并记录日志，对服务监控和快速问题定位有很大帮助。 安全，安全和访问控制逻辑可以在框架层统一进行封装，可做成插件形式，具体业务服务根据需要加载相关安全插件。 文档自动生成，文档的书写和同步一直是一个痛点，框架层如果能支持文档的自动生成和同步，会给使用API的开发和测试人员带来极大便利。Swagger是一种流行Restful API的文档方案。当前业界比较成熟的微服务框架有Netflix的Karyon/Ribbon，Spring的Spring Boot/Cloud，阿里的Dubbo等。 ##运行期配置管理 服务一般有很多依赖配置，例如访问数据库有连接字符串配置，连接池大小和连接超时配置，这些配置在不同环境(开发/测试/生产)一般不同，比如生产环境需要配连接池，而开发测试环境可能不配，另外有些参数配置在运行期可能还要动态调整，例如，运行时根据流量状况动态调整限流和熔断阀值。目前比较常见的做法是搭建一个运行时配置中心支持微服务的动态配置，简化架构如下图(Fig 10):Fig 10, 服务配置中心 动态配置存放在集中的配置服务器上，用户通过管理界面配置和调整服务配置，具体服务通过定期拉(Scheduled Pull)的方式或者服务器推(Server-side Push)的方式更新动态配置，拉方式比较可靠，但会有延迟同时有无效网络开销(假设配置不常更新)，服务器推方式能及时更新配置，但是实现较复杂，一般在服务和配置服务器之间要建立长连接。配置中心还要解决配置的版本控制和审计问题，对于大规模服务化环境，配置中心还要考虑分布式和高可用问题。 配置中心比较成熟的开源方案有百度的Disconf，360的QConf，Spring的Cloud Config和阿里的Diamond等。 Netflix的微服务框架Netflix是一家成功实践微服务架构的互联网公司，几年前，Netflix就把它的几乎整个微服务框架栈开源贡献给了社区，这些框架和组件包括： Eureka: 服务注册发现框架 Zuul: 服务网关 Karyon: 服务端框架 Ribbon: 客户端框架 Hystrix: 服务容错组件 Archaius: 服务配置组件 Servo: Metrics组件 Blitz4j: 日志组件 下图Fig 11展示了基于这些组件构建的一个微服务框架体系，来自recipes-rss。 Fig 11, 基于Netflix开源组件的微服务框架 Netflix的开源框架组件已经在Netflix的大规模分布式微服务环境中经过多年的生产实战验证，正逐步被社区接受为构造微服务框架的标准组件。Pivotal去年推出的Spring Cloud开源产品，主要是基于对Netflix开源组件的进一步封装，方便Spring开发人员构建微服务基础框架。对于一些打算构建微服务框架体系的公司来说，充分利用或参考借鉴Netflix的开源微服务组件(或Spring Cloud)，在此基础上进行必要的企业定制，无疑是通向微服务架构的捷径。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[腹肌锻炼]]></title>
      <url>%2Fblog%2F2017%2F06%2Fabs-exercises.html</url>
      <content type="text"><![CDATA[健身是一个循序渐进的过程，不要想一天就成为你心中的那个偶像，需要持久坚持和努力。腹肌训练更是如此，想要减脂塑形、梦想拥有完美身材的男女，不妨一起来试练下面一组动作，提示各位要按照顺序完成训练量。 动作一、60个开合跳，连续进行； 动作二、40个仰卧交替收膝，动作要到位； 动作三、10~15个仰卧起坐； 动作四、看到Z没有，20个凳(Z)上反屈伸； 动作五、按照下方示范动作，左右各20个侧步蹲； 动作六、同动作三，俯卧撑10~15个； 动作七、有没有经常见到这个动作呢？仰卧举腿20个； 动作八、30个高抬腿走起 ； 动作九、深蹲跳 10个就够了； 动作十、平板支撑60秒！哦，一分钟 ； 附带视频一个：click me]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[maven-war-plugin]]></title>
      <url>%2Fblog%2F2017%2F04%2Fmaven-war-plugin.html</url>
      <content type="text"><![CDATA[Apache Maven WAR PluginThe WAR Plugin is responsible for collecting all artifact dependencies, classes and resources of the web application and packaging them into a web application archive. “打包“这个词听起来比较土，比较正式的说法应该是”构建项目软件包“，具体说就是将项目中的各种文件，比如源代码、编译生成的字节码、配置文件、文档，按照规范的格式生成归档，最常见的当然就是JAR包和WAR包了，复杂点的例子是Maven官方下载页面的分发包，它有自定义的格式，方便用户直接解压后就在命令行使用。作为一款”打包工具“，Maven自然有义务帮助用户创建各种各样的包，规范的JAR包和WAR包自然不再话下，略微复杂的自定义打包格式也必须支持，本文就介绍一些常用的打包案例以及相关的实现方式，除了前面提到的一些包以外，你还能看到如何生成源码包、Javadoc包、以及从命令行可直接运行的CLI包。 任何一个Maven项目都需要定义POM元素packaging（如果不写则默认值为jar）。顾名思义，该元素决定了项目的打包方式。实际的情形中，如果你不声明该元素，Maven会帮你生成一个JAR包；如果你定义该元素的值为war，那你会得到一个WAR包；如果定义其值为POM（比如是一个父模块），那什么包都不会生成。除此之外，Maven默认还支持一些其他的流行打包格式，例如ejb3和ear。你不需要了解具体的打包细节，你所需要做的就是告诉Maven，”我是个什么类型的项目“，这就是约定优于配置的力量。 对应于同样的package生命周期阶段，Maven为jar项目调用了maven-jar-plugin，为war项目调用了maven-war-plugin，换言之，packaging直接影响Maven的构建生命周期。了解这一点非常重要，特别是当你需要自定义打包行为的时候，你就必须知道去配置哪个插件。 war plugin的常用配置参数archiveClasses配置项该配置的值为true|false，默认是false。表示是否将class进行打包。正常情况下war类型的工程，java代码编译后的类文件会放到WEB-INF/classes目录下面，散装。 当该参数配置为true时，会将所有的class打包为一个jar，jar的名字与war的名字一致（除了后缀）。然后把这个jar放到WEB-INF/lib目录下，此时WEB-INF/classes目录下是空的。 attachClasses配置项该配置的值为true|false，默认是false。表示在发布war包的时候是否同时发布一个jar包（只有classes，不包含页面相关文件）。正常情况下war类型的工程，当我们执行install或者deploy的时候build出一个war包，安装到本地或者发布到远程。当该参数配置为true时，除了war包外还会多出一个jar包，不过该jar包的classifier默认为classes。 overlays配置节点overlays配置的作用是，将指定war包中的内容与当前项目进行合并。合并策略：如果存在同名冲突，则使用当前项目中的文件。 overlay的具体配置项（include|exclude）可以指定包含或者排除特定模式的文件。 配置示例多war合并archiveClasses和attachClasses参数可以同时配置为true。此时打包文件中含有lib，不含classes。发布时会同时发布classifier为classes的jar包。 如果当前工程A需要从B工程的war包中合入页面文件，同时代码中也要使用B的类文件。工程B包含配置如下：12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;attachClasses&gt;true&lt;/attachClasses&gt; &lt;/configuration&gt; &lt;/plugin&gt; 工程A包含配置如下： 1234567891011121314151617181920212223242526272829303132&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;groupB&lt;/groupId&gt; &lt;artifactId&gt;B&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;classifier&gt;classes&lt;/classifier&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;groupB&lt;/groupId&gt; &lt;artifactId&gt;B&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;type&gt;war&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;overlays&gt; &lt;overlay&gt; &lt;groupId&gt;groupB&lt;/groupId&gt; &lt;artifactId&gt;B&lt;/artifactId&gt; &lt;/overlay&gt; &lt;/overlays&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 可注意如果同名的文件夹会进行合并，不合并空文件夹。 把class文件打包成jar，怎么排除resources目录?正常情况下war类型的工程，java代码编译后的类文件会放到WEB-INF/classes目录下面，散装。 当archiveClasses参数配置为true时，会将所有的class打包为一个jar，jar的名字与war的名字一致。然后把这个jar放到WEB-INF/lib目录下，此时WEB-INF/classes目录下是空的，但如果想在war包的WEB-INF/classes中保留logback.xml配置文件，该怎么做？ 1234567891011121314&lt;plugin&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;configuration&gt; &lt;archiveClasses&gt;true&lt;/archiveClasses&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/classes&lt;/targetPath&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt;&lt;/plugin&gt; 对项目进行动态打包，不同的环境使用不同的配置文件打包demo 112345678910111213141516171819project/`-- src |-- main | |-- java | |-- resources | | |-- local | | | |-- logback.xml | | | |-- spring-dataSource.xml | | | `-- variable.propertes | | |-- product | | | |-- logback.xml | | | |-- spring-dataSource.xml | | | `-- variable.propertes | | `-- qa | | |-- logback.xml | | |-- spring-dataSource.xml | | `-- variable.propertes | |-- webapp `-- test 12maven package –P local 开发环境maven package –P product 生产环境 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;local&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;local&lt;/package.environment&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;properties&gt; &lt;package.environment&gt;product&lt;/package.environment&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt;&lt;build&gt; &lt;resources&gt; &lt;!-- class文件打包成jar包，排除相关配置文件和jrebel配置文件 --&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;local/*&lt;/exclude&gt; &lt;exclude&gt;product/*&lt;/exclude&gt; &lt;exclude&gt;rebel.xml&lt;/exclude&gt; &lt;/excludes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;!-- 区别dev环境与生产环境logback.xml配置 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archiveClasses&gt;true&lt;/archiveClasses&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/$&#123;package.environment&#125;&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;targetPath&gt;WEB-INF/classes&lt;/targetPath&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default-jar&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; demo 21234567891011121314151617181920project/`-- src |-- main | |-- java | |-- env | | |-- dev | | | |-- log4j.properties | | | |-- spring-dataSource.xml | | | `-- variable.propertes | | |-- prod | | | |-- log4j.properties | | | |-- spring-dataSource.xml | | | `-- variable.propertes | | `-- qa | | |-- log4j.properties | | |-- spring-dataSource.xml | | `-- variable.propertes | |-- resources | `-- webapp `-- test 12mvn clean package -P devmvn clean package -P qa 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;demo Maven Webapp&lt;/name&gt; &lt;groupId&gt;webapp&lt;/groupId&gt; &lt;artifactId&gt;webapp&lt;/artifactId&gt; &lt;scm&gt; &lt;connection&gt;scm:svn:http://127.0.0.1/dummy&lt;/connection&gt; &lt;developerConnection&gt;scm:svn:https://127.0.0.1/dummy&lt;/developerConnection&gt; &lt;tag&gt;HEAD&lt;/tag&gt; &lt;url&gt;http://127.0.0.1/dummy&lt;/url&gt; &lt;/scm&gt; &lt;properties&gt; &lt;spring-version&gt;3.1.0.RELEASE&lt;/spring-version&gt; &lt;/properties&gt; &lt;build&gt; &lt;finalName&gt;$&#123;final.name&#125;&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;configuration&gt; &lt;overlays&gt; &lt;overlay&gt; &lt;groupId&gt;TransactionResource&lt;/groupId&gt; &lt;artifactId&gt;TransactionResource&lt;/artifactId&gt; &lt;excludes&gt; &lt;exclude&gt;WEB-INF/web.xml&lt;/exclude&gt; &lt;/excludes&gt; &lt;/overlay&gt; &lt;/overlays&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;runtime.env&#125;&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/classes&lt;/targetPath&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; …… &lt;/dependencies&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;runtime.env&gt;src/main/env/dev&lt;/runtime.env&gt; &lt;final.name&gt;webapp&lt;/final.name&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.eightqiu&lt;/groupId&gt; &lt;artifactId&gt;CodeCmns&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;qa&lt;/id&gt; &lt;properties&gt; &lt;runtime.env&gt;src/main/env/qa&lt;/runtime.env&gt; &lt;final.name&gt;webapp_$&#123;buildNumber&#125;&lt;/final.name&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;buildnumber-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;validate&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;create&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;format&gt;&#123;0,date,yyyyMMdd&#125;&lt;/format&gt; &lt;items&gt; &lt;item&gt;timestamp&lt;/item&gt; &lt;/items&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;reporting&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.1&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.eightqiu&lt;/groupId&gt; &lt;artifactId&gt;CodeCmns&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;runtime.env&gt;src/main/env/prod&lt;/runtime.env&gt; &lt;final.name&gt;webapp&lt;/final.name&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.eightqiu&lt;/groupId&gt; &lt;artifactId&gt;CodeCmns&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[maven-paranamer-plugin]]></title>
      <url>%2Fblog%2F2017%2F04%2Fmaven-paranamer-plugin.html</url>
      <content type="text"><![CDATA[What is it?It is a library that allows the parameter names of non-private methods and constructors to be accessed at runtime. Normally this information is dropped by the compiler. In effect, methods like doSometing(mypkg.Person toMe) currently look like doSomething(mypackage.Person ???) to people using Java’s reflection to inspect methods. 项目主页：https://github.com/paul-hammant/paranamer 如何在运行时获取java方法参数名称? 由于jdk的反射方式，未提供获取参数名的方法 Java的字节码文件默认不存储参数名称。在使用javac编译时，如果开启-g:{vars}选项，可以增加Local variable debugging information。对java方法，参数实际是按照局部变量来存储的，所以可以获取参数名称；但对于java接口中的方法声明，这种方法就无法获取参数名称。 Paranamer专门用来解决获取参数名的问题。其原理是在编译阶段，修改.class文件，在类或接口的字节码文件中增加一个字符串常量，这个常量保存了所有的方法声明信息，包括方法名、参数类型、参数名称。这样在运行时，class loader加载类文件以后，使用Paranamer的api去读取这个字符串，就可以获取参数名称。加上java反射，实际上可以把源代码重现出来。 这个工具可以用来实现代码生成器。其缺点在于，它需要修改源项目的build步骤。据其项目主页说明，Java 8已经加入存储参数名称的功能。 12345678910// MySomethingOrOther.java**Method method = Foo.class.getMethod(...);Paranamer paranamer = new CachingParanamer();String[] parameterNames = paranamer.lookupParameterNames(method) // throws ParameterNamesNotFoundException if not found// or:parameterNames = paranamer.lookupParameterNames(method, false) // will return null if not found 踩过的坑需求：通过java的反射获取method，使用paranamer获取method的参数名称。诡异之处：使用Paranamer paranamer = new CachingParanamer()l.ookupParameterNames(method);无法正常获取方法的变量名称。 一个简单的java类，请注意使用了import .* 的方式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package hbec.commons.services.stock.controller;import hbec.commons.domain.stock.condition.dto.*;import hbec.commons.domain.stock.vo.*;import hbec.exception.portal.HbecPortalStockBizException;import hbec.platform.commons.annotations.HbecService;import hbec.platform.commons.exceptions.HbecDbServiceException;import javax.validation.constraints.NotNull;import java.util.List;/** * @author roc Jul 4, 2016 * */public interface IConditionTradeController &#123; ConditionSaveResult save(Integer userId, @NotNull ConditionTradeDto conditionTradeDto) ; ConditionSaveResult saveTurnPoint(Integer userId, @NotNull ConditionTradeTurnPointDto conditionTradeDto) ; ConditionSaveResult saveBatching(Integer userId, @NotNull ConditionTradeBatchingDto conditionTradeDto) ; ConditionSaveResult saveGrid(Integer userId, @NotNull GridTradeDto conditionTradeDto) ; ConditionSaveResult saveProfit(Integer userId, ProfitConditionTradeDto profitConditionTradeDto) ; Integer delete(Integer userId, @NotNull Integer warnId) ; Integer pause(Integer userId, @NotNull Integer warnId) ; Integer resume(Integer userId, @NotNull Integer warnId) ; PageVo&lt;ConditionTradeMarketVO&gt; findMonitorPageWithMarket(Integer userId, String code, ConditionPageVo&lt;ConditionTradeMarketVO&gt; pager) ; ConditionTradeDetailVo detail(@NotNull Integer userId, @NotNull Integer warnId) ; PageVo&lt;ConditionTradeHistoryVo&gt; queryHistory(@NotNull Integer userId, String stockCode, PageVo&lt;ConditionTradeHistoryVo&gt; pager) ; ConditionTradeDetailVo detailWithMarket(Integer userId, Integer warnId) ; List&lt;EntrustVO&gt; queryEntrustRecord(Integer userId, Integer warnId) ; List&lt;ConditionInfoVO&gt; queryEntrustResult(Integer userId, String stockCode, String historyIds) ; PageCursorVo&lt;ConditionInfoVO&gt; queryEntrustedResult(Integer userId, String stockCode, Integer warnId, Integer cursor, Integer pageSize) ; CountTradeHistoryVo countEntrustedResult(Integer userId, String stockCode, Integer warnId) ; int markAsRead(Integer userId, String stockCode, Integer warnId) ;&#125; 使用paranamer-maven-plugin编译之后如下： 1public static final String __PARANAMER_DATA = "countConditionNum java.lang.Integer userId \ncountEntrustedResult java.lang.Integer,java.lang.String,java.lang.Integer userId,stockCode,warnId \ndelete java.lang.Integer,java.lang.Integer userId,warnId \ndetail java.lang.Integer,java.lang.Integer userId,warnId \ndetailWithMarket java.lang.Integer,java.lang.Integer userId,warnId \nentrustManual java.lang.Integer,java.lang.Integer,EntrustDto userId,warnId,entrustDto \nfindCurrentEntrust java.lang.Integer,java.lang.String,PageVo userId,stockCode,pager \nfindMonitorPageWithMarket java.lang.Integer,java.lang.String,ConditionPageVo userId,code,pager \nfindPage java.lang.Integer,java.lang.String,ConditionPageVo userId,strategyState,pager \nfindTriggeredPage java.lang.Integer,java.lang.Integer,PageVo userId,handled,pager \nmarkAsRead java.lang.Integer,java.lang.String,java.lang.Integer userId,stockCode,warnId \npause java.lang.Integer,java.lang.Integer userId,warnId \nqueryEntrustRecord java.lang.Integer,java.lang.Integer userId,warnId \nqueryEntrustResult java.lang.Integer,java.lang.String,java.lang.String userId,stockCode,historyIds \nqueryEntrustedResult java.lang.Integer,java.lang.String,java.lang.Integer,java.lang.Integer,java.lang.Integer userId,stockCode,warnId,cursor,pageSize \nqueryHistory java.lang.Integer,java.lang.String,PageVo userId,stockCode,pager \nresume java.lang.Integer,java.lang.Integer userId,warnId \nsave java.lang.Integer,ConditionTradeDto userId,conditionTradeDto \nsaveBatching java.lang.Integer,ConditionTradeBatchingDto userId,conditionTradeDto \nsaveGrid java.lang.Integer,GridTradeDto userId,conditionTradeDto \nsaveNewShares java.lang.Integer,NewSharesDto userId,newSharesDto \nsaveProfit java.lang.Integer,ProfitConditionTradeDto userId,profitConditionTradeDto \nsaveTurnPoint java.lang.Integer,ConditionTradeTurnPointDto userId,conditionTradeDto \nsaveVipBatching java.lang.Integer,ConditionTradeBatchingDto userId,conditionTradeDto \n"; 仔细观察可以发现生成的__PARANAMER_DATA常量中，并未包含对象类型变量的具体package路径，此时使用new CachingParanamer()l.ookupParameterNames(method)无法正常获取方法的变量名称。 去掉import .* 的方式之后，再次编译，常量中包含了对象类型变量具体的package路径，此时可成功获取方法的变量名称。 1public static final String __PARANAMER_DATA = "countConditionNum java.lang.Integer userId \ncountEntrustedResult java.lang.Integer,java.lang.String,java.lang.Integer userId,stockCode,warnId \ndelete java.lang.Integer,java.lang.Integer userId,warnId \ndetail java.lang.Integer,java.lang.Integer userId,warnId \ndetailWithMarket java.lang.Integer,java.lang.Integer userId,warnId \nentrustManual java.lang.Integer,java.lang.Integer,hbec.commons.domain.stock.dto.EntrustDto userId,warnId,entrustDto \nfindCurrentEntrust java.lang.Integer,java.lang.String,hbec.commons.domain.stock.vo.PageVo userId,stockCode,pager \nfindMonitorPageWithMarket java.lang.Integer,java.lang.String,hbec.commons.domain.stock.vo.ConditionPageVo userId,code,pager \nfindPage java.lang.Integer,java.lang.String,hbec.commons.domain.stock.vo.ConditionPageVo userId,strategyState,pager \nfindTriggeredPage java.lang.Integer,java.lang.Integer,hbec.commons.domain.stock.vo.PageVo userId,handled,pager \nmarkAsRead java.lang.Integer,java.lang.String,java.lang.Integer userId,stockCode,warnId \npause java.lang.Integer,java.lang.Integer userId,warnId \nqueryEntrustRecord java.lang.Integer,java.lang.Integer userId,warnId \nqueryEntrustResult java.lang.Integer,java.lang.String,java.lang.String userId,stockCode,historyIds \nqueryEntrustedResult java.lang.Integer,java.lang.String,java.lang.Integer,java.lang.Integer,java.lang.Integer userId,stockCode,warnId,cursor,pageSize \nqueryHistory java.lang.Integer,java.lang.String,hbec.commons.domain.stock.vo.PageVo userId,stockCode,pager \nresume java.lang.Integer,java.lang.Integer userId,warnId \nsave java.lang.Integer,hbec.commons.domain.stock.dto.ConditionTradeDto userId,conditionTradeDto \nsaveBatching java.lang.Integer,hbec.commons.domain.stock.dto.ConditionTradeBatchingDto userId,conditionTradeDto \nsaveGrid java.lang.Integer,hbec.commons.domain.stock.dto.GridTradeDto userId,conditionTradeDto \nsaveNewShares java.lang.Integer,hbec.commons.domain.stock.dto.NewSharesDto userId,newSharesDto \nsaveProfit java.lang.Integer,hbec.commons.domain.stock.condition.dto.ProfitConditionTradeDto userId,profitConditionTradeDto \nsaveTurnPoint java.lang.Integer,hbec.commons.domain.stock.dto.ConditionTradeTurnPointDto userId,conditionTradeDto \nsaveVipBatching java.lang.Integer,hbec.commons.domain.stock.dto.ConditionTradeBatchingDto userId,conditionTradeDto \n";]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Shell脚本调试技术]]></title>
      <url>%2Fblog%2F2017%2F03%2FShell%E8%84%9A%E6%9C%AC%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF.html</url>
      <content type="text"><![CDATA[前言shell编程在unix/linux世界中使用得非常广泛，熟练掌握shell编程也是成为一名优秀的unix/linux开发者和系统管理员的必经之路。脚本调试的主要工作就是发现引发脚本错误的原因以及在脚本源代码中定位发生错误的行，常用的手段包括分析输出的错误信息，通过在脚本中加入调试语句，输出调试信息来辅助诊断错误，利用调试工具等。但与其它高级语言相比，shell解释器缺乏相应的调试机制和调试工具的支持，其输出的错误信息又往往很不明确，初学者在调试脚本时，除了知道用echo语句输出一些信息外，别无它法，而仅仅依赖于大量的加入echo语句来诊断错误，确实令人不胜其繁，故常见初学者抱怨shell脚本太难调试了。本文将系统地介绍一些重要的shell脚本调试技术，希望能对shell的初学者有所裨益。 本篇博客整理自 Shell脚本调试技术 Shell脚本调试技术 本文的目标读者是unix/linux环境下的开发人员，测试人员和系统管理员，要求读者具有基本的shell编程知识。本文所使用范例在Bash3.1+Redhat Enterprise Server 4.0下测试通过，但所述调试技巧应也同样适用于其它shell。 在shell脚本中输出调试信息通过在程序中加入调试语句把一些关键地方或出错的地方的相关信息显示出来是最常见的调试手段。Shell程序员通常使用echo(ksh程序员常使用print)语句输出信息，但仅仅依赖echo语句的输出跟踪信息很麻烦，调试阶段在脚本中加入的大量的echo语句在产品交付时还得再费力一一删除。针对这个问题，本节主要介绍一些如何方便有效的输出调试信息的方法。 使用trap命令trap命令用于捕获指定的信号并执行预定义的命令。其基本的语法是: 1trap 'command' signal 其中signal是要捕获的信号，command是捕获到指定的信号之后，所要执行的命令。可以用kill –l命令看到系统中全部可用的信号名，捕获信号后所执行的命令可以是任何一条或多条合法的shell语句，也可以是一个函数名。 shell脚本在执行时，会产生三个所谓的“伪信号”，(之所以称之为“伪信号”是因为这三个信号是由shell产生的，而其它的信号是由操作系统产生的)，通过使用trap命令捕获这三个“伪信号”并输出相关信息对调试非常有帮助。 表 1. shell伪信号 信号名 何时产生 EXIT 从一个函数中退出或整个脚本执行完毕 ERR 当一条命令返回非零状态时(代表命令执行不成功) DEBUG 脚本中每一条命令执行之前 通过捕获EXIT信号,我们可以在shell脚本中止执行或从函数中退出时，输出某些想要跟踪的变量的值，并由此来判断脚本的执行状态以及出错原因,其使用方法是： 1trap 'command' EXIT 或 trap 'command' 0 通过捕获ERR信号,我们可以方便的追踪执行不成功的命令或函数，并输出相关的调试信息，以下是一个捕获ERR信号的示例程序，其中的$LINENO是一个shell的内置变量，代表shell脚本的当前行号。 123456789101112$ cat -n exp1.shERRTRAP()&#123; echo "[LINE:$1] Error: Command or function exited with status $?"&#125;foo()&#123;return 1;&#125;trap 'ERRTRAP $LINENO' ERRabcfoo 其输出结果如下： 1234$ sh exp1.shexp1.sh: line 10: abc: command not found[LINE:10] Error: Command or function exited with status 127[LINE:11] Error: Command or function exited with status 1 在调试过程中，为了跟踪某些变量的值，我们常常需要在shell脚本的许多地方插入相同的echo语句来打印相关变量的值，这种做法显得烦琐而笨拙。而通过捕获DEBUG信号，我们只需要一条trap语句就可以完成对相关变量的全程跟踪。 以下是一个通过捕获DEBUG信号来跟踪变量的示例程序: 123456789101112$ cat –n exp2.sh#!/bin/bashtrap 'echo “before execute line:$LINENO, a=$a,b=$b,c=$c”' DEBUGa=1if [ "$a" -eq 1 ]then b=2else b=1fic=3echo "end" 其输出结果如下： 1234567$ sh exp2.shbefore execute line:3, a=,b=,c=before execute line:4, a=1,b=,c=before execute line:6, a=1,b=,c=before execute line:10, a=1,b=2,c=before execute line:11, a=1,b=2,c=3end 从运行结果中可以清晰的看到每执行一条命令之后，相关变量的值的变化。同时，从运行结果中打印出来的行号来分析，可以看到整个脚本的执行轨迹，能够判断出哪些条件分支执行了，哪些条件分支没有执行。 使用tee命令在shell脚本中管道以及输入输出重定向使用得非常多，在管道的作用下，一些命令的执行结果直接成为了下一条命令的输入。如果我们发现由管道连接起来的一批命令的执行结果并非如预期的那样，就需要逐步检查各条命令的执行结果来判断问题出在哪儿，但因为使用了管道，这些中间结果并不会显示在屏幕上，给调试带来了困难，此时我们就可以借助于tee命令了。 tee命令会从标准输入读取数据，将其内容输出到标准输出设备,同时又可将内容保存成文件。例如有如下的脚本片段，其作用是获取本机的ip地址： 1234ipaddr=`/sbin/ifconfig | grep 'inet addr:' | grep -v '127.0.0.1'| cut -d : -f3 | awk '&#123;print $1&#125;'`echo $ipaddr #注意=号后面的整句是用反引号(数字1键的左边那个键)括起来的。 运行这个脚本，实际输出的却不是本机的ip地址，而是广播地址,这时我们可以借助tee命令，输出某些中间结果，将上述脚本片段修改为： 1234ipaddr=`/sbin/ifconfig | grep 'inet addr:' | grep -v '127.0.0.1'| tee temp.txt | cut -d : -f3 | awk '&#123;print $1&#125;'`echo $ipaddr 之后，将这段脚本再执行一遍，然后查看temp.txt文件的内容： 12$ cat temp.txtinet addr:192.168.0.1 Bcast:192.168.0.255 Mask:255.255.255.0 我们可以发现中间结果的第二列(列之间以:号分隔)才包含了IP地址，而在上面的脚本中使用cut命令截取了第三列，故我们只需将脚本中的cut -d : -f3改为cut -d : -f2即可得到正确的结果。 具体到上述的script例子，我们也许并不需要tee命令的帮助，比如我们可以分段执行由管道连接起来的各条命令并查看各命令的输出结果来诊断错误，但在一些复杂的shell脚本中，这些由管道连接起来的命令可能又依赖于脚本中定义的一些其它变量，这时我们想要在提示符下来分段运行各条命令就会非常麻烦了，简单地在管道之间插入一条tee命令来查看中间结果会更方便一些。 使用”调试钩子”在C语言程序中，我们经常使用DEBUG宏来控制是否要输出调试信息，在shell脚本中我们同样可以使用这样的机制，如下列代码所示： 123if [ “$DEBUG” = “true” ]; thenecho “debugging” #此处可以输出调试信息fi 这样的代码块通常称之为“调试钩子”或“调试块”。在调试钩子内部可以输出任何您想输出的调试信息，使用调试钩子的好处是它是可以通过DEBUG变量来控制的，在脚本的开发调试阶段，可以先执行export DEBUG=true命令打开调试钩子，使其输出调试信息，而在把脚本交付使用时，也无需再费事把脚本中的调试语句一一删除。 如果在每一处需要输出调试信息的地方均使用if语句来判断DEBUG变量的值，还是显得比较繁琐，通过定义一个DEBUG函数可以使植入调试钩子的过程更简洁方便，如下面代码所示: 123456789101112131415161718$ cat –n exp3.sh DEBUG() &#123; if [ "$DEBUG" = "true" ]; then $@ fi &#125; a=1 DEBUG echo "a=$a" if [ "$a" -eq 1 ] then b=2 else b=1 fi DEBUG echo "b=$b" c=3 DEBUG echo "c=$c" 在上面所示的DEBUG函数中，会执行任何传给它的命令，并且这个执行过程是可以通过DEBUG变量的值来控制的，我们可以把所有跟调试有关的命令都作为DEBUG函数的参数来调用，非常的方便。回页首 使用shell的执行选项上一节所述的调试手段是通过修改shell脚本的源代码，令其输出相关的调试信息来定位错误的，那有没有不修改源代码来调试shell脚本的方法呢？答案就是使用shell的执行选项，本节将介绍一些常用选项的用法： -n 只读取shell脚本，但不实际执行 -x 进入跟踪方式，显示所执行的每一条命令 -c “string” 从strings中读取命令 “-n”可用于测试shell脚本是否存在语法错误，但不会实际执行命令。在shell脚本编写完成之后，实际执行之前，首先使用“-n”选项来测试脚本是否存在语法错误是一个很好的习惯。因为某些shell脚本在执行时会对系统环境产生影响，比如生成或移动文件等，如果在实际执行才发现语法错误，您不得不手工做一些系统环境的恢复工作才能继续测试这个脚本。 “-c”选项使shell解释器从一个字符串中而不是从一个文件中读取并执行shell命令。当需要临时测试一小段脚本的执行结果时，可以使用这个选项，如下所示：1sh -c 'a=1;b=2;let c=$a+$b;echo "c=$c"' “-x”选项可用来跟踪脚本的执行，是调试shell脚本的强有力工具。“-x”选项使shell在执行脚本的过程中把它实际执行的每一个命令行显示出来，并且在行首显示一个”+”号。 “+”号后面显示的是经过了变量替换之后的命令行的内容，有助于分析实际执行的是什么命令。 “-x”选项使用起来简单方便，可以轻松对付大多数的shell调试任务,应把其当作首选的调试手段。 如果把本文前面所述的trap ‘command’ DEBUG机制与“-x”选项结合起来，我们 就可以既输出实际执行的每一条命令，又逐行跟踪相关变量的值，对调试相当有帮助。 仍以前面所述的exp2.sh为例，现在加上“-x”选项来执行它： 123456789101112131415161718$ sh –x exp2.sh+ trap 'echo "before execute line:$LINENO, a=$a,b=$b,c=$c"' DEBUG++ echo 'before execute line:3, a=,b=,c='before execute line:3, a=,b=,c=+ a=1++ echo 'before execute line:4, a=1,b=,c='before execute line:4, a=1,b=,c=+ '[' 1 -eq 1 ']'++ echo 'before execute line:6, a=1,b=,c='before execute line:6, a=1,b=,c=+ b=2++ echo 'before execute line:10, a=1,b=2,c='before execute line:10, a=1,b=2,c=+ c=3++ echo 'before execute line:11, a=1,b=2,c=3'before execute line:11, a=1,b=2,c=3+ echo endend 在上面的结果中，前面有“+”号的行是shell脚本实际执行的命令，前面有“++”号的行是执行trap机制中指定的命令，其它的行则是输出信息。 shell的执行选项除了可以在启动shell时指定外，亦可在脚本中用set命令来指定。 “set -参数”表示启用某选项，”set +参数”表示关闭某选项。有时候我们并不需要在启动时用”-x”选项来跟踪所有的命令行，这时我们可以在脚本中使用set命令，如以下脚本片段所示： 123set -x #启动"-x"选项要跟踪的程序段set +x #关闭"-x"选项 set命令同样可以使用上一节中介绍的调试钩子—DEBUG函数来调用，这样可以避免脚本交付使用时删除这些调试语句的麻烦，如以下脚本片段所示： 1234DEBUG set -x #启动"-x"选项要跟踪的程序段DEBUG set +x #关闭"-x"选项回页首 对”-x”选项的增强“-x”执行选项是目前最常用的跟踪和调试shell脚本的手段，但其输出的调试信息仅限于进行变量替换之后的每一条实际执行的命令以及行首的一个”+”号提示符，居然连行号这样的重要信息都没有，对于复杂的shell脚本的调试来说，还是非常的不方便。幸运的是，我们可以巧妙地利用shell内置的一些环境变量来增强”-x”选项的输出信息，下面先介绍几个shell内置的环境变量： $LINENO代表shell脚本的当前行号，类似于C语言中的内置宏LINE $FUNCNAME函数的名字，类似于C语言中的内置宏func,但宏func只能代表当前所在的函数名，而$FUNCNAME的功能更强大，它是一个数组变量，其中包含了整个调用链上所有的函数的名字，故变量${FUNCNAME[0]}代表shell脚本当前正在执行的函数的名字，而变量${FUNCNAME[1]}则代表调用函数${FUNCNAME[0]}的函数的名字，余者可以依此类推。 $PS4主提示符变量$PS1和第二级提示符变量$PS2比较常见，但很少有人注意到第四级提示符变量$PS4的作用。我们知道使用“-x”执行选项将会显示shell脚本中每一条实际执行过的命令，而$PS4的值将被显示在“-x”选项输出的每一条命令的前面。在Bash Shell中，缺省的$PS4的值是”+”号。(现在知道为什么使用”-x”选项时，输出的命令前面有一个”+”号了吧？)。 利用$PS4这一特性，通过使用一些内置变量来重定义$PS4的值，我们就可以增强”-x”选项的输出信息。例如先执行export PS4=’+{$LINENO:${FUNCNAME[0]}} ‘, 然后再使用“-x”选项来执行脚本，就能在每一条实际执行的命令前面显示其行号以及所属的函数名。 以下是一个存在bug的shell脚本的示例，本文将用此脚本来示范如何用“-n”以及增强的“-x”执行选项来调试shell脚本。这个脚本中定义了一个函数isRoot(),用于判断当前用户是不是root用户，如果不是，则中止脚本的执行 12345678910111213141516171819$ cat –n exp4.sh #!/bin/bash isRoot() &#123; if [ "$UID" -ne 0 ] return 1 else return 0 fi&#125;isRootif ["$?" -ne 0 ]then echo "Must be root to run this script" exit 1else echo "welcome root user" #do somethingfi 首先执行sh –n exp4.sh来进行语法检查，输出如下： 123$ sh –n exp4.shexp4.sh: line 6: syntax error near unexpected token `else'exp4.sh: line 6: ` else' 发现了一个语法错误，通过仔细检查第6行前后的命令，我们发现是第4行的if语句缺少then关键字引起的(写惯了C程序的人很容易犯这个错误)。我们可以把第4行修改为if [ “$UID” -ne 0 ]; then来修正这个错误。再次运行sh –n exp4.sh来进行语法检查，没有再报告错误。接下来就可以实际执行这个脚本了，执行结果如下： 123$ sh exp4.shexp2.sh: line 11: [1: command not foundwelcome root user 尽管脚本没有语法错误了，在执行时却又报告了错误。错误信息还非常奇怪“[1: command not found”。现在我们可以试试定制$PS4的值，并使用“-x”选项来跟踪： 123456789$ export PS4='+&#123;$LINENO:$&#123;FUNCNAME[0]&#125;&#125; '$ sh –x exp4.sh+&#123;10:&#125; isRoot+&#123;4:isRoot&#125; '[' 503 -ne 0 ']'+&#123;5:isRoot&#125; return 1+&#123;11:&#125; '[1' -ne 0 ']'exp4.sh: line 11: [1: command not found+&#123;16:&#125; echo 'welcome root user'welcome root user 从输出结果中，我们可以看到脚本实际被执行的语句，该语句的行号以及所属的函数名也被打印出来，从中可以清楚的分析出脚本的执行轨迹以及所调用的函数的内部执行情况。由于执行时是第11行报错，这是一个if语句，我们对比分析一下同为if语句的第4行的跟踪结果： 12+&#123;4:isRoot&#125; '[' 503 -ne 0 ']'+&#123;11:&#125; '[1' -ne 0 ']' 可知由于第11行的[号后面缺少了一个空格，导致[号与紧挨它的变量$?的值1被shell解释器看作了一个整体，并试着把这个整体视为一个命令来执行，故有“[1: command not found”这样的错误提示。只需在[号后面插入一个空格就一切正常了。 shell中还有其它一些对调试有帮助的内置变量，比如在Bash Shell中还有BASH_SOURCE, BASH_SUBSHELL等一批对调试有帮助的内置变量，您可以通过man sh或man bash来查看，然后根据您的调试目的,使用这些内置变量来定制$PS4，从而达到增强“-x”选项的输出信息的目的。 总结现在让我们来总结一下调试shell脚本的过程： 首先使用“-n”选项检查语法错误，然后使用“-x”选项跟踪脚本的执行，使用“-x”选项之前，别忘了先定制PS4变量的值来增强“-x”选项的输出信息，至少应该令其输出行号信息(先执行export PS4=’+[$LINENO]’，更一劳永逸的办法是将这条语句加到您用户主目录的.bash_profile文件中去)，这将使你的调试之旅更轻松。也可以利用trap,调试钩子等手段输出关键调试信息，快速缩小排查错误的范围，并在脚本中使用“set -x”及“set +x”对某些代码块进行重点跟踪。这样多种手段齐下，相信您已经可以比较轻松地抓出您的shell脚本中的臭虫了。如果您的脚本足够复杂，还需要更强的调试能力，可以使用shell调试器bashdb，这是一个类似于GDB的调试工具，可以完成对shell脚本的断点设置，单步执行，变量观察等许多功能，使用bashdb对阅读和理解复杂的shell脚本也会大有裨益。关于bashdb的安装和使用，不属于本文范围，您可参阅http://bashdb.sourceforge.net/上的文档并下载试用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[shell 函数返回字符串的方法]]></title>
      <url>%2Fblog%2F2017%2F03%2Fshell-%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%96%B9%E6%B3%95.html</url>
      <content type="text"><![CDATA[shell的函数只能返回整数值，如果想让函数返回字符串，一般有两种方法：将返回值赋值给一个字符串变量、输出返回值，在函数调用处为变量赋值。 Shell函数Shell 函数的定义格式如下： 1234function_name () &#123; list of commands [ return value ]&#125; 如果你愿意，也可以在函数名前加上关键字 function：1234function function_name () &#123; list of commands [ return value ]&#125; 函数返回值，可以显式增加return语句；如果不加，会将最后一条命令运行结果作为返回值。 Shell 函数返回值只能是整数，一般用来表示函数执行成功与否，0表示成功，其他值表示失败。如果 return 其他数据，比如一个字符串，往往会得到错误提示：“numeric argument required”。 如果一定要让函数返回字符串，那么可以先定义一个变量，用来接收函数的计算结果，脚本在需要的时候访问这个变量来获得函数返回值。 将返回值赋值给一个字符串变量123get_project_version()&#123; VERSION=`grep version $1/pom.xml | head -n 1 | sed -E 's:&lt;/?version&gt;::g' | sed -E 's/^\t*//' | sed -E 's/^ *//' | sed -E 's/\r$//'`&#125; 输出返回值，在函数调用处为变量赋值12345get_project_version()&#123; echo `grep version $1/pom.xml | head -n 1 | sed -E 's:&lt;/?version&gt;::g' | sed -E 's/^\t*//' | sed -E 's/^ *//' | sed -E 's/\r$//'`&#125;version=`get_project_version $PROJECT_PATH` 特殊变量列表 变量 含义 $0 是脚本本身的名字； $# 是传给脚本的参数个数； $@ 是传给脚本的所有参数的列表，即被扩展为”$1” “$2” “$3”等； $* 是以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个，即被扩展成”$1c$2c$3”，其中c是IFS的第一个字符； $$ 是脚本运行的当前进程ID号； $? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误； $n 获取参数的值，$1表示第一个参数，当n&gt;=10时，需要使用${n}来获取参数。 如果你希望直接从终端调用函数，可以将函数定义在主目录下的 .profile 文件，这样每次登录后，在命令提示符后面输入函数名字就可以立即调用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[shell 文件包含]]></title>
      <url>%2Fblog%2F2017%2F03%2Fshell-%E6%96%87%E4%BB%B6%E5%8C%85%E5%90%AB.html</url>
      <content type="text"><![CDATA[像其他语言一样，Shell 也可以包含外部脚本，将外部脚本的内容合并到当前脚本。 121. . ./subscript.sh (常用) 2. source ./subscript.sh 两种方式的效果相同，简单起见，一般使用点号(.)，但是注意点号(.)和文件名中间有一空格。两个脚本不在同一目录时，要用绝对路径。 PS:被包含脚本不需要有执行权限，调用脚本必须有可执行权限。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[shell 获取正在执行脚本的绝对路径]]></title>
      <url>%2Fblog%2F2017%2F03%2Fshell-%E8%8E%B7%E5%8F%96%E6%AD%A3%E5%9C%A8%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC%E7%9A%84%E7%BB%9D%E5%AF%B9%E8%B7%AF%E5%BE%84.html</url>
      <content type="text"><![CDATA[今天在写脚本的时候，想获取下当前执行脚本的绝对路径，试了试pwd，发现并不是正确的路径。找资料后发现 pwd 命令的作用是“print name of current/working directory-当前的工作目录”。 试了试$0，发现也不对，$0是Bash环境下的特殊变量，其真实含义是： Expands to the name of the shell or shell script. This is set at shell initialization. If bash is invoked with a file of commands, $0 is set to the name of that file. If bash is started with the -c option, then $0 is set to the first argument after the string to be executed, if one is present. Otherwise, it is set to the file name used to invoke bash, as given by argument zero. $0的结果与调用方式有关： 使用一个文件调用bash，那$0的值，是那个文件的名字(不能确定绝对路径) 使用-c选项启动bash的话，真正执行的命令会从一个字符串中读取，字符串后面如果还有别的参数的话，使用从$0开始的特殊变量引用(跟路径无关) 除此以外，$0会被设置成调用bash的那个文件的名字(不能确定是绝对路径) 正确的姿势： basepath=$(cd dirname $0; pwd) dirname $0，取得当前执行的脚本文件的父目录 cd dirname $0，进入这个目录(切换当前工作目录) pwd，显示当前工作目录(cd执行后的)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[svn status]]></title>
      <url>%2Fblog%2F2017%2F03%2Fsvn-status.html</url>
      <content type="text"><![CDATA[名称svn status (stat, st) — 打印工作副本文件和目录的状态。 概要svn status [PATH…] 描述Print the status of working copy files and directories. With no arguments, it prints only locally modified items (no repository access). With –show-updates (-u), it adds working revision and server out-of-date information. With –verbose (-v), it prints full revision information on every item. With –quiet (-q), it prints only summary information about locally modified items. The first seven columns in the output are each one character wide, and each column gives you information about a different aspect of each working copy item. 第一列指出一个项目的是添加, 删除还是其它的修改： ‘ ‘没有修改。 ‘A’预定要添加的项目。 ‘D’预定要删除的项目。 ‘M’项目已经修改了。 ‘R’Item has been replaced in your working copy. This means the file was scheduled for deletion, and then a new file with the same name was scheduled for addition in its place. ‘C’项目的内容(相对于属性)与更新得到的数据冲突了。 ‘X’项目与外部定义相关。 ‘I’项目被忽略(例如使用svn:ignore属性)。 ‘?’项目不在版本控制之下。 ‘!’Item is missing (e.g., you moved or deleted it without using svn). This also indicates that a directory is incomplete (a checkout or update was interrupted). ‘~’Item is versioned as one kind of object (file, directory, link), but has been replaced by a different kind of object. The second column tells the status of a file’s or directory’s properties: ‘ ‘没有修改。 ‘M’这个项目的属性已经修改。 ‘C’这个项目的属性与从版本库得到的更新有冲突。 The third column is populated only if the working copy directory is locked (see 第 6 节 “有时你只需要清理”): ‘ ‘项目没有锁定。 ‘L’项目已经锁定。 The fourth column is populated only if the item is scheduled for addition-with-history: ‘ ‘没有历史预定要提交。 ‘+’历史预定要伴随提交。 The fifth column is populated only if the item is switched relative to its parent (see 第 5 节 “使用分支”): ‘ ‘项目是它的父目录的孩子。 ‘S’项目已经转换。 The sixth column is populated with lock information: ‘ ‘When –show-updates (-u) is used, the file is not locked. If –show-updates (-u) is not used, this merely means that the file is not locked in this working copy. K文件锁定在工作副本。 OFile is locked either by another user or in another working copy. This appears only when –show-updates (-u) is used. TFile was locked in this working copy, but the lock has been “stolen” and is invalid. The file is currently locked in the repository. This appears only when –show-updates (-u) is used. BFile was locked in this working copy, but the lock has been “broken” and is invalid. The file is no longer locked. This appears only when –show-updates (-u) is used. The seventh column is populated only if the item is the victim of a tree conflict: ‘ ‘项目不是树冲突的受害者。 ‘C’项目是树冲突的受害者 第八列始终为空。 The out-of-date information appears in the ninth column (only if you pass the –show-updates (-u) option): ‘ ‘这个项目在工作副本是最新的。 ‘*‘在服务器这个项目有了新的修订版本。 The remaining fields are variable width and delimited by spaces. The working revision is the next field if the –show-updates (-u) or –verbose (-v) option is passed. If the –verbose (-v) option is passed, the last committed revision and last committed author are displayed next. 工作副本路径永远是最后一个字段，所以它可以包括空格。 选项 –changelist ARG–depth ARG–ignore-externals–incremental–no-ignore–quiet (-q)–show-updates (-u)–verbose (-v)–xml例子 这是查看你在工作副本所做的修改的最简单的方法。 $ svn status wc M wc/bar.cA + wc/qax.cIf you want to find out what files in your working copy are out of date, pass the –show-updates (-u) option (this will not make any changes to your working copy). Here you can see that wc/foo.c has changed in the repository since we last updated our working copy: $ svn status -u wc M 965 wc/bar.c * 965 wc/foo.c A + 965 wc/qax.cStatus against revision: 981[注意] 注意–show-updates (-u) only places an asterisk next to items that are out of date (i.e., items that will be updated from the repository if you later use svn update). –show-updates (-u) does not cause the status listing to reflect the repository’s version of the item (although you can see the revision number in the repository by passing the –verbose (-v) option). The most information you can get out of the status subcommand is as follows: $ svn status -u -v wc M 965 938 sally wc/bar.c * 965 922 harry wc/foo.c A + 965 687 harry wc/qax.c 965 687 harry wc/zig.cStatus against revision: 981Lastly, you can get svn status output in XML format with the –xml option: $ svn status –xml wc123456789101112131415161718192021222324252627&lt;?xml version="1.0"?&gt;&lt;status&gt;&lt;target path="wc"&gt;&lt;entry path="qax.c"&gt;&lt;wc-status props="none" item="added" revision="0"&gt;&lt;/wc-status&gt;&lt;/entry&gt;&lt;entry path="bar.c"&gt;&lt;wc-status props="normal" item="modified" revision="965"&gt;&lt;commit revision="965"&gt;&lt;author&gt;sally&lt;/author&gt;&lt;date&gt;2008-05-28T06:35:53.048870Z&lt;/date&gt;&lt;/commit&gt;&lt;/wc-status&gt;&lt;/entry&gt;&lt;/target&gt;&lt;/status&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[股票估值]]></title>
      <url>%2Fblog%2F2017%2F03%2F%E8%82%A1%E7%A5%A8%E4%BC%B0%E5%80%BC.html</url>
      <content type="text"><![CDATA[格雷厄姆认为：“稳健投资者的基本原理是不会随着年代的更替而改变的，但是这些原理的应用，则必须随着金融机制和金融环境所发生的重大变化而作出相应的调整。” 实际上巴菲特的“以合理的价格买优秀的公司”也正是格老与时俱进思想的体现。 股票估值是一个相对复杂的过程，影响的因素很多，没有全球统一的标准。影响股票估值的主要因素依次是每股收益、行业市盈率、流通股本、每股净资产、每股净资产增长率等指标。 股票估值分为绝对估值、相对估值和联合估值。 绝对估值绝对估值(absolute valuation)是通过对上市公司历史及当前的基本面的分析和对未来反映公司经营状况的财务数据的预测获得上市公司股票的内在价值。 绝对估值的方法一是现金流贴现定价模型，二是B-S期权定价模型(主要应用于期权定价、权证定价等)。现金流贴现定价模型目前使用最多的是DDM和DCF，而DCF估值模型中，最广泛应用的就是FCFE股权自由现金流模型。 绝对估值的作用股票的价格总是围绕着股票的内在价值上下波动，发现价格被低估的股票，在股票的价格远远低于内在价值的时候买入股票，而在股票的价格回归到内在价值甚至高于内在价值的时候卖出以获利。对上市公司进行研究，经常听到估值这个词，说的其实是如何来判断一家公司的价值同时与它的当前股价进行对比，得出股价是否偏离价值的判断，进而指导投资。 DCF是一套很严谨的估值方法，是一种绝对定价方法，想得出准确的DCF值，需要对公司未来发展情况有清晰的了解。得出DCF 值的过程就是判断公司未来发展的过程。所以DCF 估值的过程也很重要。就准确判断企业的未来发展来说，判断成熟稳定的公司相对容易一些，处于扩张期的企业未来发展的不确定性较大，准确判断较为困难。再加上DCF 值本身对参数的变动很敏感，使DCF 值的可变性很大。但在得出DCF 值的过程中，会反映研究员对企业未来发展的判断，并在此基础上假设。有了DCF 的估值过程和结果，以后如果假设有变动，即可通过修改参数得到新的估值。 相对估值相对估值是使用市盈率、市净率、市售率、市现率等价格指标与其它多只股票（对比系）进行对比，如果低于对比系的相应的指标值的平均值，股票价格被低估，股价将很有希望上涨，使得指标回归对比系的平均值。相对估值包括PE、PB、PEG、EV/EBITDA等估值法。通常的做法是对比，一个是和该公司历史数据进行对比，二是和国内同行业企业的数据进行对比，确定它的位置，三是和国际上的(特别是香港和美国)同行业重点企业数据进行对比。市盈率PE（股价/每股收益）： PE是简洁有效的估值方法，其核心在于e 的确定。PE=p/e，即价格与每股收益的比值。从直观上看，如果公司未来若干年每股收益为恒定值，那么PE 值代表了公司保持恒定盈利水平的存在年限。这有点像实业投资中回收期的概念，只是忽略了资金的时间价值。而实际上保持恒定的e 几乎是不可能的，e 的变动往往取决于宏观经济和企业的生存周期所决定的波动周期。所以在运用PE 值的时候，e 的确定显得尤为重要，由此也衍生出具有不同含义的PE 值。E 有两个方面，一个是历史的e，另一个是预测的e。对于历史的e 来说，可以用不同e 的时点值，可以用移动平均值，也可以用动态年度值，这取决于想要表达的内容。对于预测的e 来说，预测的准确性尤为重要，在实际市场中，e 的变动趋势对股票投资往往具有决定性的影响。市净率PB（股价/每股净资）和净资产收益率ROE,PB &amp;ROE适合于周期的极值判断。对于股票投资来说，准确预测e 是非常重要的，e 的变动趋势往往决定了股价是上行还是下行。但股价上升或下降到多少是合理的呢？ PB&amp;ROE 可以给出一个判断极值的方法。比如，对于一个有良好历史ROE 的公司，在业务前景尚可的情况下，PB 值低于1就有可能是被低估的。如果公司的盈利前景较稳定，没有表现出明显的增长性特征，公司的PB 值显著高于行业（公司历史）的最高PB 值，股价触顶的可能性就比较大。这里提到的周期有三个概念：市场的波动周期、股价的变动周期和周期性行业的变动周期。 相关概念PEPE是指市盈率，也称为“利润收益率”，是某种股票普通股每股市价与每股盈利的比率，即：PE(市盈率)=每股市价/每股收益。市盈率把股价和利润联系起来，反映了企业的近期表现。如果股价上升，利润没有变化，甚至下降，则市盈率将会上升。 PB平均市净率=股价/账面价值。其中，账面价值=总资产-无形资产-负债-优先股权益。可以看出，所谓账面价值是公司解散清算的价值。如果公司要清算，那么先要还债，无形资产则将不复存在，而优先股的优先权之一就是清算的时候先分钱，但是本股市没有优先股。这样，用每股净资产来代替账面价值，则PB就是大家理解的市净率，即：PB(市净率)=股价/每股净资产。 ROEROE即净资产收益率，又称股东权益报酬率。作为判断上市公司盈利能力的一项重要指标，一直受到证券市场参与各方的极大关注。分析师将ROE解释为将公司盈余再投资以产生更多收益的能力。它也是衡量公司内部财务、行销及经营绩效的指标。ROE的计算方法是：净资产收益率＝报告期净利润／报告期末净资产。 DCF绝对估值法DCF：DCF是一套很严谨的估值方法，是一种绝对定价方法，想得出准确的DCF值，需要对公司未来发展情况有清晰的了解。得出DCF值的过程就是判断公司未来发展的过程，所以DCF估值的过程也很重要。就准确判断企业的未来发展来说，判断成熟稳定的公司相对容易一些，处于扩张期的企业未来发展的不确定性较大，准确判断较为困难。再加上DCF值本身对参数的变动很敏感，使DCF值的可变性很大。但在得出DCF值的过程中，会反映研究员对企业未来发展的判断，并在此基础上假设。有了DCF的估值过程和结果，以后如果假设有变动，即可通过修改参数得到新的估值。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[人生最浪费生命的事情]]></title>
      <url>%2Fblog%2F2017%2F03%2F%E4%BA%BA%E7%94%9F%E6%9C%80%E6%B5%AA%E8%B4%B9%E7%94%9F%E5%91%BD%E7%9A%84%E4%BA%8B%E6%83%85.html</url>
      <content type="text"><![CDATA[人这一生，浪费了太多的时间在毫无意义的事情上，担忧、抱怨、埋怨、比较…… 担忧庸人自扰是为难自己，让自己每天神经紧绷、忧心忡忡，只会使自己身心俱疲。生活里总会有变数，总会有风雨，任谁都无法提前预知一切。所以，让自己焦虑烦扰，不如让自己释怀轻松地过每一天，顺其自然、淡定坦然地面对一切，不要让担忧禁锢你的身体、束缚你的内心。 抱怨充满抱怨的人生会与快乐渐行渐远。对环境不满、对别人不满、对命运不满、对现实不满，最后对自己的选择和决定不满……抱怨会削弱你奋斗的力量，会阻碍你前行的脚步，会让你陷入负面情绪无法自拔。试着让自己勇敢坦然地面对一切风雨，接受自己做出的每一个决定，即使这个过程充满艰辛，也不要轻言放弃，更不要裹足不前、自怨自艾。 埋怨遇事，先责备别人；不顺，先埋怨条件，这是一种消极被动的人生态度，是一种缺乏担当的表现。埋怨根本于事无补，只会让你看不清自己的问题、意识不到自己的错误。聪明的人会懂得先反省自己，从自己的身上找答案。只有用这种积极的态度去面对生活中遇到的问题，才能够让你汲取教训、增长经验，让你在今后的生活中越走越顺利。 比较 生活中，自己觉得快乐不快乐、满足不满足、幸福不幸福，才是正理。不要陷入跟别人不断的比较之中，不要因为别人扰乱了自己的步伐。每个人都有自己的机遇和福分，也会遭遇自己的坎坷和波折，不要拿别人的成就荣耀与自己比，不要盲目追随、模仿别人的生活方式而忘记了自己的初衷和追求。多倾听自己的内心，多思考自己的需要，走自己的路，过自己的人生。 这是你吗？花费了太多的时间在你不该做的事情上。总是在抱怨。没有充实你的思想。满脑子都是消极想法。觉得没有激情。对未来没有计划。花了太多时间和对你成长没有任何贡献的人在一起。沉迷于手机。把钱花在了毫无意义的事上。睡眠不足。没有照顾好自己的身体。不愿意离开舒适区。 把时间和感受留给自己、留给内心。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[国债逆回购]]></title>
      <url>%2Fblog%2F2017%2F03%2F%E5%9B%BD%E5%80%BA%E9%80%86%E5%9B%9E%E8%B4%AD.html</url>
      <content type="text"><![CDATA[Thinking will not overcome fear but action will.空想终日惶恐，行动方可无惧。 概念国债逆回购，就是将资金通过国债回购市场拆出，其实就是一种短期贷款，即你把钱借给别人，获得固定利息;而别人用国债作抵押，到期还本付息。国债逆回购业务是能为投资者提高闲置资金增值能力的金融品种，它具有安全性高、流通性强、收益理想等特点，等同于国债。 债券回购交易的实质是？逆回购就是客户放弃一定时间内的资金使用权，在约定时间内按成交时确定的利率获取利息收入的一种投资品种。 债券回购是指交易双方进行的以债券为权利质押的一种短期资金融通业务。资金融入方（正回购方）在将债券质押给资金融出方（逆回购方）以融入资金的同时，双方约定在将来某一日期由正回购方按约定回购利率计算的金额向逆回购方买回相等数量的同品种债券的交易行为。债券回购的最长期限为1年，利率由双方协商确定。 这当中卖方的目的在于获得高于银行存款利息收入，而买方的目的在于获得资金的使用权。一笔回购交易涉及二次交易契约行为，即开始时的初始交易及回购期满时的回购交易。买卖双方的具体操作程序如下：债券回购交易申报中，融资方（债券持有者）按“买入”予以申报，融券方（资金持有者）按“卖出”予以申报。到期反向成交时，无须再行申报，由交易所电脑系统自动产生一条反向成交记录，登记结算机构据此进行资金和债券的清算与交割。 国债逆回购本质上就是一个机构借钱给另一个机构（银行，保险等）。原本国家规定是机构间的拆借，不允许个人参与，不知道什么时候开始个人也可以参加了。什么时候机构需要临时借钱？目前来看一般是每季度末1－2天，银行需要借钱美化信贷指标；大蓝筹发行前一日。 是否有风险？与股票交易不同，债券回购在成交之后不再承担价格波动的风险，收益率的高低在成交时确定。因此基本无价格波动风险。 适合哪些人买？ 有理财需求的人 钱放银行拿死利息的人 炒股的人 做生意的流动资金 家中的闲置资金 申报规则上海回购交易的申报数量必须为100手（10万资金）的整数倍，单笔数量不超过1万手（1000万资金）；回购价格为每百元资金到期的年收益率，最小变动单位为0.005元。 深圳回购交易的申报数量必须为1手的整数倍（1000元），回购价格为每百元资金到期的年收益率，最小变动单位为0.001元。 回购买入的最佳时间是？ 一般2点半之后临近收盘下单量往往会大增，从而导致价格走低。 一般星期四、月末、季度末、年末，市场资金面紧张价格通常很高。 重要节假日前两天，1日回购品种价格通常较高。 周五3日品种一般比1日品种总收益高。 如果其间有节假日，长期品种一般比短期品种总收益高。 单日内一般9：30-10：00、14：00-14：30收益率最高。 从以往的规律和盘面表现看，每日下午2时30分之前利率较高; 每周四相比平日利率要高;节假日前利率尤其高。 投资品种投资者要进行回购只能做沪市2040**、深1318***的新国债回购，共18个品种。 上交所回购品种 品种 代码 简称 到账时间 可用时间 手续费比例 每10万元交易手续费(元) 1天国债回购 204001 GC001 T + 1 T + 2 成交金额的0.001% 1 2天国债回购 204002 GC002 T + 2 T + 3 成交金额的0.002% 2 3天国债回购 204003 GC003 T + 3 T + 4 成交金额的0.003% 3 4天国债回购 204004 GC004 T + 4 T + 5 成交金额的0.004% 4 7天国债回购 204007 GC007 T + 7 T + 8 成交金额的0.005% 5 14天国债回购 204014 GC014 T + 14 T + 15 成交金额的0.010% 10 28天国债回购 204028 GC028 T + 28 T + 29 成交金额的0.020% 20 91天国债回购 204091 GC091 T + 91 T + 92 成交金额的0.030% 30 182天国债回购 204182 GC182 T + 182 T + 183 成交金额的0.030% 30 深交所回购品种 品种 代码 简称 到账时间 可用时间 手续费比例 每10万元交易手续费(元) 1天国债回购 131810 R-00l T + 1 T + 2 成交金额的0.001% 1 2天国债回购 1318ll R-002 T + 2 T + 3 成交金额的0.002% 2 3天国债回购 131800 R-003 T + 3 T + 4 成交金额的0.003% 3 4天国债回购 131809 R-004 T + 4 T + 5 成交金额的0.004% 4 7天国债回购 131801 R-007 T + 7 T + 8 成交金额的0.005% 5 14天国债回购 131802 R-014 T + 14 T + 15 成交金额的0.010% 10 28天国债回购 131803 R-028 T + 28 T + 29 成交金额的0.020% 20 91天国债回购 131805 R-091 T + 91 T + 92 成交金额的0.030% 30 182天国债回购 131806 R-182 T + 182 T + 183 成交金额的0.030% 30]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IntelliJ IDEA 插件推荐]]></title>
      <url>%2Fblog%2F2017%2F03%2FIntelliJ-IDEA-plugins.html</url>
      <content type="text"><![CDATA[人不要等明天，因为没有人知道自己有没有明天。 推荐插件本篇博客整理自IntelliJ IDEA 简体中文专题教程和日常开发归档： IntelliJ IDEA 简体中文专题教程 插件名称 插件介绍 官网地址 IDE Features Trainer IntelliJ IDEA 官方出的学习辅助插件 https://plugins.jetbrains.com/plugin/8554?pr=idea Key promoter 快捷键提示 https://plugins.jetbrains.com/plugin/4455?pr=idea Grep Console 自定义设置控制台输出颜色 https://plugins.jetbrains.com/idea/plugin/7125-grep-console String Manipulation 驼峰式命名和下划线命名交替变化 https://plugins.jetbrains.com/plugin/2162?pr=idea CheckStyle-IDEA 代码规范检查 https://plugins.jetbrains.com/plugin/1065?pr=idea FindBugs-IDEA 潜在 Bug 检查 https://plugins.jetbrains.com/plugin/3847?pr=idea MetricsReloaded 代码复杂度检查 https://plugins.jetbrains.com/plugin/93?pr=idea Statistic 代码统计 https://plugins.jetbrains.com/plugin/4509?pr=idea JRebel Plugin 热部署 https://plugins.jetbrains.com/plugin/?id=4441 CodeGlance 在编辑代码最右侧，显示一块代码小地图 https://plugins.jetbrains.com/plugin/7275?pr=idea GsonFormat 把 JSON 字符串直接实例化成类 https://plugins.jetbrains.com/plugin/7654?pr=idea MultiMarkdown 书写 Markdown 文章 https://plugins.jetbrains.com/plugin/7896?pr=idea Eclipse Code Formatter 使用 Eclipse 的代码格式化风格，在一个团队中如果公司有规定格式化风格，这个可以使用。 https://plugins.jetbrains.com/plugin/6546?pr=idea Jindent-Source Code Formatter 自定义类、方法、doc、变量注释模板 http://plugins.jetbrains.com/plugin/2170?pr=idea ECTranslation 翻译插件 https://github.com/Skykai521/ECTranslation/releases UpperLowerCapitalize 大小写插件 https://plugins.jetbrains.com/plugin/183-upperlowercapitalize Maven Helper A must have plugin for working with Maven. https://plugins.jetbrains.com/plugin/7179-maven-helper]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IntelliJ IDEA For Mac 快捷键]]></title>
      <url>%2Fblog%2F2017%2F03%2FIntelliJ-IDEA-key-map-for-Mac-OS.html</url>
      <content type="text"><![CDATA[刘心武说：与其讨好别人，不如武装自己；与其逃避现实，不如笑对人生；与其听风听雨，不如昂首出击！ 建议将 Mac 系统中与 IntelliJ IDEA 冲突的快捷键取消或更改，不建议改 IntelliJ IDEA 的默认快捷键。 本篇博客整理自IntelliJ IDEA 简体中文专题教程和日常开发归档： IntelliJ IDEA 简体中文专题教程 Windows / Linux：https://www.jetbrains.com/idea/docs/IntelliJIDEA_ReferenceCard.pdf Mac OS X：https://www.jetbrains.com/idea/docs/IntelliJIDEA_ReferenceCard_Mac.pdf 在 IntelliJ IDEA 中有两个 Mac 版本的快捷键，一个叫做：Mac OS X，一个叫做：Mac OS X 10.5+。目前都是用：Mac OS X 10.5+ 有两套的原因：https://intellij-support.jetbrains.com/hc/en-us/community/posts/206159109-Updated-Mac-OS-X-keymap-Feedback-needed Mac键盘符号和修饰键说明 ⌘ Command ⇧ Shift ⌥ Option ⌃ Control ↩︎ Return/Enter ⌫ Delete ⌦ 向前删除键（Fn+Delete） ↑ 上箭头 ↓ 下箭头 ← 左箭头 → 右箭头 ⇞ Page Up（Fn+↑） ⇟ Page Down（Fn+↓） Home Fn + ← End Fn + → ⇥ 右制表符（Tab键） ⇤ 左制表符（Shift+Tab） ⎋ Escape (Esc) 一、Editing（编辑） Control + Space 基本的代码补全（补全任何类、方法、变量） Control + Shift + Space 智能代码补全（过滤器方法列表和变量的预期类型） Command + Shift + Enter 自动结束代码，行末自动添加分号 Command + P 显示方法的参数信息 Control + J 快速查看文档 Shift + F1 查看外部文档（在某些代码上会触发打开浏览器显示相关文档） Command + 鼠标放在代码上 显示代码简要信息 Command + F1 在错误或警告处显示具体描述信息 Command + N, Control + Enter, Control + N 生成代码（getter、setter、构造函数、hashCode/equals,toString） Control + O 覆盖方法（重写父类方法） Control + I 实现方法（实现接口中的方法） Command + Option + T 包围代码（使用if..else, try..catch, for, synchronized等包围选中的代码） Command + / 注释/取消注释与行注释 Command + Option + / 注释/取消注释与块注释 Option + 方向键上 连续选中代码块 Option + 方向键下 减少当前选中的代码块 Control + Shift + Q 显示上下文信息 Option + Enter 显示意向动作和快速修复代码 Command + Option + L 格式化代码 Control + Option + O 优化import Control + Option + I 自动缩进线 Tab / Shift + Tab 缩进代码 / 反缩进代码 Command + X 剪切当前行或选定的块到剪贴板 Command + C 复制当前行或选定的块到剪贴板 Command + V 从剪贴板粘贴 Command + Shift + V 从最近的缓冲区粘贴 Command + D 复制当前行或选定的块 Command + Delete 删除当前行或选定的块的行 Control + Shift + J 智能的将代码拼接成一行 Command + Enter 智能的拆分拼接的行 Shift + Enter 开始新的一行 Command + Shift + U 大小写切换 Command + Shift + ] / Command + Shift + [ 选择直到代码块结束/开始 Option + Fn + Delete 删除到单词的末尾 Option + Delete 删除到单词的开头 Command + 加号 / Command + 减号 展开 / 折叠代码块 Command + Shift + 加号 展开所以代码块 Command + Shift + 减号 折叠所有代码块 Command + W 关闭活动的编辑器选项卡 二、Search/Replace（查询/替换） Double Shift 查询任何东西 Command + F 文件内查找 Command + G 查找模式下，向下查找 Command + Shift + G 查找模式下，向上查找 Command + R 文件内替换 Command + Shift + F 全局查找（根据路径） Command + Shift + R 全局替换（根据路径） Command + Shift + S 查询结构（Ultimate Edition 版专用，需要在Keymap中设置） Command + Shift + M 替换结构（Ultimate Edition 版专用，需要在Keymap中设置） 三、Usage Search（使用查询） Option + F7 / Command + F7 在文件中查找用法 / 在类中查找用法 Command + Shift + F7 在文件中突出显示的用法 Command + Option + F7 显示用法 四、Compile and Run（编译和运行） Command + F9 编译Project Command + Shift + F9 编译选择的文件、包或模块 Control + Option + R 弹出 Run 的可选择菜单 Control + Option + D 弹出 Debug 的可选择菜单 Control + R 运行 Control + D 调试 Control + Shift + R, Control + Shift + D 从编辑器运行上下文环境配置 五、Debugging（调试） F8 进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F7 进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 Shift + F7 智能步入，断点所在行上有多个方法调用，会弹出进入哪个方法 Shift + F8 跳出 Option + F9 运行到光标处，如果光标前有其他断点会进入到该断点 Option + F8 计算表达式（可以更改变量值使其生效） Command + Option + R 恢复程序运行，如果该断点下面代码还有断点则停在下一个断点上 Command + F8 切换断点（若光标当前行有断点则取消断点，没有则加上断点） Command + Shift + F8 查看断点信息 六、Navigation（导航） Command + O 查找类文件 Command + Shift + O 查找所有类型文件、打开文件、打开目录，打开目录需要在输入的内容前面或后面加一个反斜杠/ Command + Option + O 前往指定的变量 / 方法 Control + 方向键左 / Control + 方向键右 左右切换打开的编辑tab页 F12 返回到前一个工具窗口 Esc 从工具窗口进入代码文件窗口 Shift + Esc 隐藏当前或最后一个活动的窗口，且光标进入代码文件窗口 Command + Shift + F4 关闭活动run/messages/find/… tab Command + L 在当前文件跳转到某一行的指定处 Command + E 显示最近打开的文件记录列表 Option + 方向键左 / Option + 方向键右 光标跳转到当前单词 / 中文句的左 / 右侧开头位置 Command + Option + 方向键左 / Command + Option + 方向键右 退回 / 前进到上一个操作的地方 Command + Shift + Delete 跳转到最后一个编辑的地方 Option + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择(如在代码编辑窗口可以选择显示该文件的Finder) Command + B / Command + 鼠标点击 进入光标所在的方法/变量的接口或是定义处 Command + Option + B 跳转到实现处，在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 Option + Space, Command + Y 快速打开光标所在方法、类的定义 Control + Shift + B 跳转到类型声明处 Command + U 前往当前光标所在方法的父类的方法 / 接口定义 Control + 方向键下 / Control + 方向键上 当前光标跳转到当前文件的前一个/后一个方法名位置 Command + ] / Command + [ 移动光标到当前所在代码的花括号开始/结束位置 Command + F12 弹出当前文件结构层，可以在弹出的层上直接输入进行筛选（可用于搜索类中的方法） Control + H 显示当前类的层次结构 Command + Shift + H 显示方法层次结构 Control + Option + H 显示调用层次结构 F2 / Shift + F2 跳转到下一个/上一个突出错误或警告的位置 F4 / Command + 方向键下 编辑/查看代码源 Option + Home 显示到当前文件的导航条 F3选中文件/文件夹/代码行，添加/取消书签 Option + F3 选中文件/文件夹/代码行，使用助记符添加/取消书签 Control + 0...Control + 9 定位到对应数值的书签位置 Command + F3 显示所有书签 七、Refactoring（重构） F5 复制文件到指定目录 F6 移动文件到指定目录 Command + Delete 在文件上为安全删除文件，弹出确认框 Shift + F6 重命名文件 Command + F6 更改签名 Command + Option + N 一致性 Command + Option + M 将选中的代码提取为方法 Command + Option + V 提取变量 Command + Option + F 提取字段 Command + Option + C 提取常量 Command + Option + P 提取参数 八、VCS/Local History（版本控制/本地历史记录） Command + K 提交代码到版本控制器 Command + T 从版本控制器更新代码 Option + Shift + C 查看最近的变更记录 Control + C 快速弹出版本控制器操作面板 九、Live Templates（动态代码模板） Command + Option + J 弹出模板选择窗口，将选定的代码使用动态模板包住 Command + J 插入自定义动态代码模板 十、General（通用） Command + 1...Command + 9 打开相应编号的工具窗口 Command + S 保存所有 Command + Option + Y 同步、刷新 Control + Command + F 切换全屏模式 Command + Shift + F12 切换最大化编辑器 Option + Shift + F 添加到收藏夹 Option + Shift + I 检查当前文件与当前的配置文件 Control + ` 快速切换当前的scheme（切换主题、代码样式等） Command + , 打开IDEA系统设置 Command + ; 打开项目结构对话框 Shift + Command + A 查找动作（可设置相关选项） Control + Shift + Tab 编辑窗口标签和工具窗口之间切换（如果在切换的过程加按上delete，则是关闭对应选中的窗口） 十一、Other（一些官方文档上没有体现的快捷键） Command + Shift +8 竖编辑模式]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[IntelliJ IDEA 快键键]]></title>
      <url>%2Fblog%2F2017%2F03%2FIntelliJ-IDEA-key-map.html</url>
      <content type="text"><![CDATA[直到有一天，当我发现我们都已经渐渐地老去的时候，我才感悟到人世间最珍贵的东西莫过于朋友之间的友谊!朋友，谢谢人生路上曾有你。 题外话 非常感谢我的朋友曹同学(PS:他的博客还在搬家阶段……)，一个极客程序猿，让我真正开始使用IntelliJ IDEA。 IntelliJ IDEA 本身的设计思维是提倡键盘优先于鼠标的，所以各种快捷键组合层出不穷，对于快捷键设置也有各种支持，对于其他 IDE 的快捷键组合也有预设模板进行支持。使用时，请干掉那些不相关软件的快捷键。 本篇博客整理自IntelliJ IDEA 简体中文专题教程和日常开发归档： IntelliJ IDEA 简体中文专题教程 Windows / Linux：https://www.jetbrains.com/idea/docs/IntelliJIDEA_ReferenceCard.pdf Mac OS X：https://www.jetbrains.com/idea/docs/IntelliJIDEA_ReferenceCard_Mac.pdf Ctrl 快捷键 介绍 Ctrl + F 在当前文件进行文本查找 （必备） Ctrl + R 在当前文件进行文本替换 （必备） Ctrl + Z 撤销 （必备） Ctrl + Y 删除光标所在行 或 删除选中的行 （必备） Ctrl + X 剪切光标所在行 或 剪切选择内容 Ctrl + C 复制光标所在行 或 复制选择内容 Ctrl + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 （必备） Ctrl + W 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 （必备） Ctrl + E 显示最近打开的文件记录列表 （必备） Ctrl + N 根据输入的 类名 查找类文件 （必备） Ctrl + G 在当前文件跳转到指定行处 Ctrl + J 插入自定义动态代码模板 （必备） Ctrl + P 方法参数提示显示 （必备） Ctrl + Q 光标所在的变量 / 类名 / 方法名等上面（也可以在提示补充的时候按），显示文档内容 Ctrl + U 前往当前光标所在的方法的父类的方法 / 接口定义 （必备） Ctrl + B 进入光标所在的方法/变量的接口或是定义处，等效于 Ctrl + 左键单击 （必备） Ctrl + K 版本控制提交项目，需要此项目有加入到版本控制才可用 Ctrl + T 版本控制更新项目，需要此项目有加入到版本控制才可用 Ctrl + H 显示当前类的层次结构 Ctrl + O 选择可重写的方法 Ctrl + I 选择可继承的方法 Ctrl + + 展开代码 Ctrl + - 折叠代码 Ctrl + / 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 （必备） Ctrl + [ 移动光标到当前所在代码的花括号开始位置 Ctrl + ] 移动光标到当前所在代码的花括号结束位置 Ctrl + F1 在光标所在的错误代码处显示错误信息 （必备） Ctrl + F3 调转到所选中的词的下一个引用位置 （必备） Ctrl + F4 关闭当前编辑文件 Ctrl + F8 在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点 Ctrl + F9 执行 Make Project 操作 Ctrl + F11 选中文件 / 文件夹，使用助记符设定 / 取消书签 （必备） Ctrl + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选 Ctrl + Tab 编辑窗口切换，如果在切换的过程又加按上delete，则是关闭对应选中的窗口 Ctrl + End 跳到文件尾 Ctrl + Home 跳到文件头 Ctrl + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl + 逗号 （必备） Ctrl + Delete 删除光标后面的单词或是中文句 （必备） Ctrl + BackSpace 删除光标前面的单词或是中文句 （必备） Ctrl + 1,2,3…9 定位到对应数值的书签位置 （必备） Ctrl + 左键单击 在打开的文件标题上，弹出该文件路径 （必备） Ctrl + 光标定位 按 Ctrl 不要松开，会显示光标所在的类信息摘要 Ctrl + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 （必备） Ctrl + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 （必备） Ctrl + 前方向键 等效于鼠标滚轮向前效果 （必备） Ctrl + 后方向键 等效于鼠标滚轮向后效果 （必备） Alt 快捷键 介绍 Alt + ` 显示版本控制常用操作菜单弹出层 （必备） Alt + Q 弹出一个提示，显示当前类的声明 / 上下文信息 Alt + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 （必备） Alt + F2 对于前面页面，显示各类浏览器打开目标选择弹出层 Alt + F3 选中文本，逐个往下查找相同文本，并高亮显示 Alt + F7 查找光标所在的方法 / 变量 / 类被调用的地方 Alt + F8 在 Debug 的状态下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果 Alt + Home 定位 / 显示到当前文件的 Navigation Bar Alt + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同 （必备） Alt + Insert 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 （必备） Alt + 左方向键 切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 （必备） Alt + 右方向键 按切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 （必备） Alt + 前方向键 当前光标跳转到当前文件的前一个方法名位置 （必备） Alt + 后方向键 当前光标跳转到当前文件的后一个方法名位置 （必备） Alt + 1,2,3…9 显示对应数值的选项卡，其中 1 是 Project 用得最多 （必备） Shift 快捷键 介绍 Shift + F1 如果有外部文档可以连接外部文档 Shift + F2 跳转到上一个高亮错误 或 警告位置 Shift + F3 在查找模式下，查找匹配上一个 Shift + F4 对当前打开的文件，使用新Windows窗口打开，旧窗口保留 Shift + F6 对文件 / 文件夹 重命名 Shift + F7 在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法 Shift + F8 在 Debug 模式下，跳出，表现出来的效果跟 F9 一样 Shift + F9 等效于点击工具栏的 Debug 按钮 Shift + F10 等效于点击工具栏的 Run 按钮 Shift + F11 弹出书签显示层 （必备） Shift + Tab 取消缩进 （必备） Shift + ESC 隐藏当前 或 最后一个激活的工具窗口 Shift + End 选中光标到当前行尾位置 Shift + Home 选中光标到当前行头位置 Shift + Enter 开始新一行。光标所在行下空出一行，光标定位到新行位置 （必备） Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 （必备） Shift + 滚轮前后滚动 当前文件的横向滚动轴滚动 （必备） Ctrl + Alt 快捷键 介绍 Ctrl + Alt + L 格式化代码，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + O 优化导入的类，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + I 光标所在行 或 选中部分进行自动代码缩进，有点类似格式化 Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 （必备） Ctrl + Alt + J 弹出模板选择窗口，将选定的代码加入动态模板中 Ctrl + Alt + H 调用层次 Ctrl + Alt + B 在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 Ctrl + Alt + V 快速引进变量 Ctrl + Alt + Y 同步、刷新 Ctrl + Alt + S 打开 IntelliJ IDEA 系统设置 （必备） Ctrl + Alt + F7 显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来 Ctrl + Alt + F11 切换全屏模式 Ctrl + Alt + Enter 光标所在行上空出一行，光标定位到新行 （必备） Ctrl + Alt + Home 弹出跟当前文件有关联的文件弹出层 Ctrl + Alt + Space 类名自动完成 Ctrl + Alt + 左方向键 退回到上一个操作的地方 （必备） Ctrl + Alt + 右方向键 前进到上一个操作的地方 （必备） Ctrl + Alt + 前方向键 在查找模式下，跳到上个查找的文件 Ctrl + Alt + 后方向键 在查找模式下，跳到下个查找的文件 Ctrl + Shift 快捷键 介绍 Ctrl + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 （必备） Ctrl + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 （必备） Ctrl + Shift + J 自动将下一行合并到当前行末尾 （必备） Ctrl + Shift + Z 取消撤销 （必备） Ctrl + Shift + W 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 （必备） Ctrl + Shift + N 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 （必备） Ctrl + Shift + U 对选中的代码进行大 / 小写轮流转换 （必备） Ctrl + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 （必备） Ctrl + Shift + C 复制当前文件磁盘路径到剪贴板 （必备） Ctrl + Shift + V 弹出缓存的最近拷贝的内容管理器弹出层 Ctrl + Shift + E 显示最近修改的文件列表的弹出层 Ctrl + Shift + H 显示方法层次结构 Ctrl + Shift + B 跳转到类型声明处 （必备） Ctrl + Shift + I 快速查看光标所在的方法 或 类的定义 Ctrl + Shift + A 查找动作 / 设置 Ctrl + Shift + / 代码块注释 （必备） Ctrl + Shift + [ 选中从光标所在位置到它的顶部中括号位置 （必备） Ctrl + Shift + ] 选中从光标所在位置到它的底部中括号位置 （必备） Ctrl + Shift + + 展开所有代码 （必备） Ctrl + Shift + - 折叠所有代码 （必备） Ctrl + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失 （必备） Ctrl + Shift + F8 在 Debug 模式下，指定断点进入条件 Ctrl + Shift + F9 编译选中的文件 / 包 / Module Ctrl + Shift + F12 编辑器最大化 （必备） Ctrl + Shift + Space 智能代码提示 Ctrl + Shift + Enter 自动结束代码，行末自动添加分号 （必备） Ctrl + Shift + Backspace 退回到上次修改的地方 （必备） Ctrl + Shift + 1,2,3…9 快速添加指定数值的书签 （必备） Ctrl + Shift + 左键单击 把光标放在某个类变量上，按此快捷键可以直接定位到该类中 （必备） Ctrl + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句 （必备） Ctrl + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句 （必备） Ctrl + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 （必备） Ctrl + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 （必备） Alt + Shift 快捷键 介绍 Alt + Shift + N 选择 / 添加 task （必备） Alt + Shift + F 显示添加到收藏夹弹出层 / 添加到收藏夹 Alt + Shift + C 查看最近操作项目的变化情况列表 Alt + Shift + I 查看项目当前文件 Alt + Shift + F7 在 Debug 模式下，下一步，进入当前方法体内，如果方法体还有方法，则会进入该内嵌的方法中，依此循环进入 Alt + Shift + F9 弹出 Debug 的可选择菜单 Alt + Shift + F10 弹出 Run 的可选择菜单 Alt + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 （必备） Alt + Shift + 前方向键 移动光标所在行向上移动 （必备） Alt + Shift + 后方向键 移动光标所在行向下移动 （必备） Ctrl + Shift + Alt 快捷键 介绍 Ctrl + Shift + Alt + V 无格式黏贴 （必备） Ctrl + Shift + Alt + N 前往指定的变量 / 方法 Ctrl + Shift + Alt + S 打开当前项目设置 （必备） Ctrl + Shift + Alt + C 复制参考信息 其他 快捷键 介绍 F2 跳转到下一个高亮错误 或 警告位置 （必备） F3 在查找模式下，定位到下一个匹配处 F4 编辑源 （必备） F7 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 F8 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F9 在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上 F11 添加书签 （必备） F12 回到前一个工具窗口 （必备） Tab 缩进 （必备） ESC 从工具窗口进入代码文件窗口 （必备） 连按两次Shift 弹出 Search Everywhere 弹出层 UpperLowerCapitalize 大小写插件快捷键 快捷键 介绍 Alt+P to uppercase Alt+L to lowercase Alt+C 首字母大写]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[markdown-syntax]]></title>
      <url>%2Fblog%2F2017%2F03%2Fmarkdown-syntax.html</url>
      <content type="text"><![CDATA[NOTE: This is Simplelified Chinese Edition Document of Markdown Syntax. If you are seeking for English Edition Document. Please refer to Markdown: Syntax. 声明： 这份文档派生(fork)于繁体中文版，在此基础上进行了繁体转简体工作，并进行了适当的润色。此文档用 Markdown 语法编写，你可以到这里查看它的源文件。「繁体中文版的原始文件可以查看这里 。」–By @riku / 本项目托管于 GitCafe 注： 本项目同时也托管于 Github 上，请通过 fork＋pull request 方式来帮忙改进本项目。 Markdown 语法说明 (简体中文版) / (点击查看快速入门) 概述 宗旨 兼容 HTML 特殊字符自动转换 区块元素 段落和换行 标题 区块引用 列表 代码区块 分隔线 区段元素 链接 强调 代码 图片 其它 反斜杠 自动链接 感谢 概述 宗旨 Markdown 的目标是实现「易读易写」。 可读性，无论如何，都是最重要的。一份使用 Markdown 格式撰写的文件应该可以直接以纯文本发布，并且看起来不会像是由许多标签或是格式指令所构成。Markdown 语法受到一些既有 text-to-HTML 格式的影响，包括 Setext、atx、Textile、reStructuredText、Grutatext 和 EtText，而最大灵感来源其实是纯文本电子邮件的格式。 总之， Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像*强调*。Markdown 的列表看起来，嗯，就是列表。Markdown 的区块引用看起来就真的像是引用一段文字，就像你曾在电子邮件中见过的那样。 兼容 HTML Markdown 语法的目标是：成为一种适用于网络的书写语言。 Markdown 不是想要取代 HTML，甚至也没有要和它相近，它的语法种类很少，只对应 HTML 标记的一小部分。Markdown 的构想不是要使得 HTML 文档更容易书写。在我看来， HTML 已经很容易写了。Markdown 的理念是，能让文档更容易读、写和随意改。HTML 是一种发布的格式，Markdown 是一种书写的格式。就这样，Markdown 的格式语法只涵盖纯文本可以涵盖的范围。 不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。不需要额外标注这是 HTML 或是 Markdown；只要直接加标签就可以了。 要制约的只有一些 HTML 区块元素――比如 &lt;div&gt;、&lt;table&gt;、&lt;pre&gt;、&lt;p&gt; 等标签，必须在前后加上空行与其它内容区隔开，还要求它们的开始标签与结尾标签不能用制表符或空格来缩进。Markdown 的生成器有足够智能，不会在 HTML 区块标签外加上不必要的 &lt;p&gt; 标签。 例子如下，在 Markdown 文件里加上一段 HTML 表格： 这是一个普通段落。 &lt;table&gt; &lt;tr&gt; &lt;td&gt;Foo&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; 这是另一个普通段落。 请注意，在 HTML 区块标签间的 Markdown 格式语法将不会被处理。比如，你在 HTML 区块内使用 Markdown 样式的*强调*会没有效果。 HTML 的区段（行内）标签如 &lt;span&gt;、&lt;cite&gt;、&lt;del&gt; 可以在 Markdown 的段落、列表或是标题里随意使用。依照个人习惯，甚至可以不用 Markdown 格式，而直接采用 HTML 标签来格式化。举例说明：如果比较喜欢 HTML 的 &lt;a&gt; 或 &lt;img&gt; 标签，可以直接使用这些标签，而不用 Markdown 提供的链接或是图像标签语法。 和处在 HTML 区块标签间不同，Markdown 语法在 HTML 区段标签间是有效的。 特殊字符自动转换 在 HTML 文件中，有两个字符需要特殊处理： &lt; 和 &amp; 。 &lt; 符号用于起始标签，&amp; 符号则用于标记 HTML 实体，如果你只是想要显示这些字符的原型，你必须要使用实体的形式，像是 &amp;lt; 和 &amp;amp;。 &amp; 字符尤其让网络文档编写者受折磨，如果你要打「AT&amp;T」 ，你必须要写成「AT&amp;amp;T」。而网址中的 &amp; 字符也要转换。比如你要链接到： http://images.google.com/images?num=30&amp;q=larry+bird 你必须要把网址转换写为： http://images.google.com/images?num=30&amp;amp;q=larry+bird 才能放到链接标签的 href 属性里。不用说也知道这很容易忽略，这也可能是 HTML 标准检验所检查到的错误中，数量最多的。 Markdown 让你可以自然地书写字符，需要转换的由它来处理好了。如果你使用的 &amp; 字符是 HTML 字符实体的一部分，它会保留原状，否则它会被转换成 &amp;amp;。 所以你如果要在文档中插入一个版权符号 ©，你可以这样写： &amp;copy; Markdown 会保留它不动。而若你写： AT&amp;T Markdown 就会将它转为： AT&amp;amp;T 类似的状况也会发生在 &lt; 符号上，因为 Markdown 允许 兼容 HTML ，如果你是把 &lt; 符号作为 HTML 标签的定界符使用，那 Markdown 也不会对它做任何转换，但是如果你写： 4 &lt; 5 Markdown 将会把它转换为： 4 &amp;lt; 5 不过需要注意的是，code 范围内，不论是行内还是区块， &lt; 和 &amp; 两个符号都一定会被转换成 HTML 实体，这项特性让你可以很容易地用 Markdown 写 HTML code （和 HTML 相对而言， HTML 语法中，你要把所有的 &lt; 和 &amp; 都转换为 HTML 实体，才能在 HTML 文件里面写出 HTML code。） 区块元素 段落和换行 一个 Markdown 段落是由一个或多个连续的文本行组成，它的前后要有一个以上的空行（空行的定义是显示上看起来像是空的，便会被视为空行。比方说，若某一行只包含空格和制表符，则该行也会被视为空行）。普通段落不该用空格或制表符来缩进。 「由一个或多个连续的文本行组成」这句话其实暗示了 Markdown 允许段落内的强迫换行（插入换行符），这个特性和其他大部分的 text-to-HTML 格式不一样（包括 Movable Type 的「Convert Line Breaks」选项），其它的格式会把每个换行符都转成 &lt;br /&gt; 标签。 如果你确实想要依赖 Markdown 来插入 &lt;br /&gt; 标签的话，在插入处先按入两个以上的空格然后回车。 的确，需要多费点事（多加空格）来产生 &lt;br /&gt; ，但是简单地「每个换行都转换为 &lt;br /&gt;」的方法在 Markdown 中并不适合， Markdown 中 email 式的 区块引用 和多段落的 列表 在使用换行来排版的时候，不但更好用，还更方便阅读。 标题 Markdown 支持两种标题的语法，类 Setext 和类 atx 形式。 类 Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），例如： This is an H1 ============= This is an H2 ------------- 任何数量的 = 和 - 都可以有效果。 类 Atx 形式则是在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶，例如： # 这是 H1 ## 这是 H2 ###### 这是 H6 你可以选择性地「闭合」类 atx 样式的标题，这纯粹只是美观用的，若是觉得这样看起来比较舒适，你就可以在行尾加上 #，而行尾的 # 数量也不用和开头一样（行首的井字符数量决定标题的阶数）： # 这是 H1 # ## 这是 H2 ## ### 这是 H3 ###### 区块引用 Blockquotes Markdown 标记区块引用是使用类似 email 中用 &gt; 的引用方式。如果你还熟悉在 email 信件中的引言部分，你就知道怎么在 Markdown 文件中建立一个区块引用，那会看起来像是你自己先断好行，然后在每行的最前面加上 &gt; ： &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, &gt; consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. &gt; Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. &gt; &gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse &gt; id sem consectetuer libero luctus adipiscing. Markdown 也允许你偷懒只在整个段落的第一行最前面加上 &gt; ： &gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. &gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt; ： &gt; This is the first level of quoting. &gt; &gt; &gt; This is nested blockquote. &gt; &gt; Back to the first level. 引用的区块内也可以使用其他的 Markdown 语法，包括标题、列表、代码区块等： &gt; ## 这是一个标题。 &gt; &gt; 1. 这是第一行列表项。 &gt; 2. 这是第二行列表项。 &gt; &gt; 给出一些例子代码： &gt; &gt; return shell_exec(&quot;echo $input | $markdown_script&quot;); 任何像样的文本编辑器都能轻松地建立 email 型的引用。例如在 BBEdit 中，你可以选取文字后然后从选单中选择增加引用阶层。 列表 Markdown 支持有序列表和无序列表。 无序列表使用星号、加号或是减号作为列表标记： * Red * Green * Blue 等同于： + Red + Green + Blue 也等同于： - Red - Green - Blue 有序列表则使用数字接着一个英文句点： 1. Bird 2. McHale 3. Parish 很重要的一点是，你在列表标记上使用的数字并不会影响输出的 HTML 结果，上面的列表所产生的 HTML 标记为： &lt;ol&gt; &lt;li&gt;Bird&lt;/li&gt; &lt;li&gt;McHale&lt;/li&gt; &lt;li&gt;Parish&lt;/li&gt; &lt;/ol&gt; 如果你的列表标记写成： 1. Bird 1. McHale 1. Parish 或甚至是： 3. Bird 1. McHale 8. Parish 你都会得到完全相同的 HTML 输出。重点在于，你可以让 Markdown 文件的列表数字和输出的结果相同，或是你懒一点，你可以完全不用在意数字的正确性。 如果你使用懒惰的写法，建议第一个项目最好还是从 1. 开始，因为 Markdown 未来可能会支持有序列表的 start 属性。 列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。 要让列表看起来更漂亮，你可以把内容用固定的缩进整理好： * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 但是如果你懒，那也行： * Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. * Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse id sem consectetuer libero luctus adipiscing. 如果列表项目间用空行分开，在输出 HTML 时 Markdown 就会将项目内容用 &lt;p&gt;标签包起来，举例来说： * Bird * Magic 会被转换为： &lt;ul&gt; &lt;li&gt;Bird&lt;/li&gt; &lt;li&gt;Magic&lt;/li&gt; &lt;/ul&gt; 但是这个： * Bird * Magic 会被转换为： &lt;ul&gt; &lt;li&gt;&lt;p&gt;Bird&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Magic&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; 列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符： 1. This is a list item with two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. Donec sit amet nisl. Aliquam semper ipsum sit amet velit. 2. Suspendisse id sem consectetuer libero luctus adipiscing. 如果你每行都有缩进，看起来会看好很多，当然，再次地，如果你很懒惰，Markdown 也允许： * This is a list item with two paragraphs. This is the second paragraph in the list item. You&apos;re only required to indent the first line. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. * Another item in the same list. 如果要在列表项目内放进引用，那 &gt; 就需要缩进： * A list item with a blockquote: &gt; This is a blockquote &gt; inside a list item. 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： * 一列表项包含一个列表区块： &lt;代码写在这&gt; 当然，项目列表很可能会不小心产生，像是下面这样的写法： 1986. What a great season. 换句话说，也就是在行首出现数字-句点-空白，要避免这样的状况，你可以在句点前面加上反斜杠。 1986\. What a great season. 代码区块 和程序相关的写作或是标签语言原始码通常会有已经排版好的代码区块，通常这些区块我们并不希望它以一般段落文件的方式去排版，而是照原来的样子显示，Markdown 会用 &lt;pre&gt; 和 &lt;code&gt; 标签来把代码区块包起来。 要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以，例如，下面的输入： 这是一个普通段落： 这是一个代码区块。 Markdown 会转换成： &lt;p&gt;这是一个普通段落：&lt;/p&gt; &lt;pre&gt;&lt;code&gt;这是一个代码区块。 &lt;/code&gt;&lt;/pre&gt; 这个每行一阶的缩进（4 个空格或是 1 个制表符），都会被移除，例如： Here is an example of AppleScript: tell application &quot;Foo&quot; beep end tell 会被转换为： &lt;p&gt;Here is an example of AppleScript:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;tell application &quot;Foo&quot; beep end tell &lt;/code&gt;&lt;/pre&gt; 一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。 在代码区块里面， &amp; 、 &lt; 和 &gt; 会自动转成 HTML 实体，这样的方式让你非常容易使用 Markdown 插入范例用的 HTML 原始码，只需要复制贴上，再加上缩进就可以了，剩下的 Markdown 都会帮你处理，例如： &lt;div class=&quot;footer&quot;&gt; &amp;copy; 2004 Foo Corporation &lt;/div&gt; 会被转换为： &lt;pre&gt;&lt;code&gt;&amp;lt;div class=&quot;footer&quot;&amp;gt; &amp;amp;copy; 2004 Foo Corporation &amp;lt;/div&amp;gt; &lt;/code&gt;&lt;/pre&gt; 代码区块中，一般的 Markdown 语法不会被转换，像是星号便只是星号，这表示你可以很容易地以 Markdown 语法撰写 Markdown 语法相关的文件。 分隔线 你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线： * * * *** ***** - - - --------------------------------------- 区段元素 链接 Markdown 支持两种形式的链接语法： 行内式和参考式两种形式。 不管是哪一种，链接文字都是用 [方括号] 来标记。 要建立一个行内式的链接，只要在方块括号后面紧接着圆括号并插入网址链接即可，如果你还想要加上链接的 title 文字，只要在网址后面，用双引号把 title 文字包起来即可，例如： This is [an example](http://example.com/ &quot;Title&quot;) inline link. [This link](http://example.net/) has no title attribute. 会产生： &lt;p&gt;This is &lt;a href=&quot;http://example.com/&quot; title=&quot;Title&quot;&gt; an example&lt;/a&gt; inline link.&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;http://example.net/&quot;&gt;This link&lt;/a&gt; has no title attribute.&lt;/p&gt; 如果你是要链接到同样主机的资源，你可以使用相对路径： See my [About](/about/) page for details. 参考式的链接是在链接文字的括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记： This is [an example][id] reference-style link. 你也可以选择性地在两个方括号中间加上一个空格： This is [an example] [id] reference-style link. 接着，在文件的任意处，你可以把这个标记的链接内容定义出来： [id]: http://example.com/ &quot;Optional Title Here&quot; 链接内容定义的形式为： 方括号（前面可以选择性地加上至多三个空格来缩进），里面输入链接文字 接着一个冒号 接着一个以上的空格或制表符 接着链接的网址 选择性地接着 title 内容，可以用单引号、双引号或是括弧包着 下面这三种链接的定义都是相同： [foo]: http://example.com/ &quot;Optional Title Here&quot; [foo]: http://example.com/ &apos;Optional Title Here&apos; [foo]: http://example.com/ (Optional Title Here) 请注意：有一个已知的问题是 Markdown.pl 1.0.1 会忽略单引号包起来的链接 title。 链接网址也可以用方括号包起来： [id]: &lt;http://example.com/&gt; &quot;Optional Title Here&quot; 你也可以把 title 属性放到下一行，也可以加一些缩进，若网址太长的话，这样会比较好看： [id]: http://example.com/longish/path/to/resource/here &quot;Optional Title Here&quot; 网址定义只有在产生链接的时候用到，并不会直接出现在文件之中。 链接辨别标签可以有字母、数字、空白和标点符号，但是并不区分大小写，因此下面两个链接是一样的： [link text][a] [link text][A] 隐式链接标记功能让你可以省略指定链接标记，这种情形下，链接标记会视为等同于链接文字，要用隐式链接标记只要在链接文字后面加上一个空的方括号，如果你要让 “Google” 链接到 google.com，你可以简化成： [Google][] 然后定义链接内容： [Google]: http://google.com/ 由于链接文字可能包含空白，所以这种简化型的标记内也许包含多个单词： Visit [Daring Fireball][] for more information. 然后接着定义链接： [Daring Fireball]: http://daringfireball.net/ 链接的定义可以放在文件中的任何一个地方，我比较偏好直接放在链接出现段落的后面，你也可以把它放在文件最后面，就像是注解一样。 下面是一个参考式链接的范例： I get 10 times more traffic from [Google] [1] than from [Yahoo] [2] or [MSN] [3]. [1]: http://google.com/ &quot;Google&quot; [2]: http://search.yahoo.com/ &quot;Yahoo Search&quot; [3]: http://search.msn.com/ &quot;MSN Search&quot; 如果改成用链接名称的方式写： I get 10 times more traffic from [Google][] than from [Yahoo][] or [MSN][]. [google]: http://google.com/ &quot;Google&quot; [yahoo]: http://search.yahoo.com/ &quot;Yahoo Search&quot; [msn]: http://search.msn.com/ &quot;MSN Search&quot; 上面两种写法都会产生下面的 HTML。 &lt;p&gt;I get 10 times more traffic from &lt;a href=&quot;http://google.com/&quot; title=&quot;Google&quot;&gt;Google&lt;/a&gt; than from &lt;a href=&quot;http://search.yahoo.com/&quot; title=&quot;Yahoo Search&quot;&gt;Yahoo&lt;/a&gt; or &lt;a href=&quot;http://search.msn.com/&quot; title=&quot;MSN Search&quot;&gt;MSN&lt;/a&gt;.&lt;/p&gt; 下面是用行内式写的同样一段内容的 Markdown 文件，提供作为比较之用： I get 10 times more traffic from [Google](http://google.com/ &quot;Google&quot;) than from [Yahoo](http://search.yahoo.com/ &quot;Yahoo Search&quot;) or [MSN](http://search.msn.com/ &quot;MSN Search&quot;). 参考式的链接其实重点不在于它比较好写，而是它比较好读，比较一下上面的范例，使用参考式的文章本身只有 81 个字符，但是用行内形式的却会增加到 176 个字元，如果是用纯 HTML 格式来写，会有 234 个字元，在 HTML 格式中，标签比文本还要多。 使用 Markdown 的参考式链接，可以让文件更像是浏览器最后产生的结果，让你可以把一些标记相关的元数据移到段落文字之外，你就可以增加链接而不让文章的阅读感觉被打断。 强调 Markdown 使用星号（*）和底线（_）作为标记强调字词的符号，被 * 或 _ 包围的字词会被转成用 &lt;em&gt; 标签包围，用两个 * 或 _ 包起来的话，则会被转成 &lt;strong&gt;，例如： *single asterisks* _single underscores_ **double asterisks** __double underscores__ 会转成： &lt;em&gt;single asterisks&lt;/em&gt; &lt;em&gt;single underscores&lt;/em&gt; &lt;strong&gt;double asterisks&lt;/strong&gt; &lt;strong&gt;double underscores&lt;/strong&gt; 你可以随便用你喜欢的样式，唯一的限制是，你用什么符号开启标签，就要用什么符号结束。 强调也可以直接插在文字中间： un*frigging*believable 但是如果你的 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。 如果要在文字前后直接插入普通的星号或底线，你可以用反斜线： \*this text is surrounded by literal asterisks\* 代码 如果要标记一小段行内代码，你可以用反引号把它包起来（` ），例如： Use the `printf()` function. 会产生： &lt;p&gt;Use the &lt;code&gt;printf()&lt;/code&gt; function.&lt;/p&gt; 如果要在代码区段内插入反引号，你可以用多个反引号来开启和结束代码区段： ``There is a literal backtick (`) here.`` 这段语法会产生： &lt;p&gt;&lt;code&gt;There is a literal backtick (`) here.&lt;/code&gt;&lt;/p&gt; 代码区段的起始和结束端都可以放入一个空白，起始端后面一个，结束端前面一个，这样你就可以在区段的一开始就插入反引号： A single backtick in a code span: `` ` `` A backtick-delimited string in a code span: `` `foo` `` 会产生： &lt;p&gt;A single backtick in a code span: &lt;code&gt;`&lt;/code&gt;&lt;/p&gt; &lt;p&gt;A backtick-delimited string in a code span: &lt;code&gt;`foo`&lt;/code&gt;&lt;/p&gt; 在代码区段内，&amp; 和方括号都会被自动地转成 HTML 实体，这使得插入 HTML 原始码变得很容易，Markdown 会把下面这段： Please don&apos;t use any `&lt;blink&gt;` tags. 转为： &lt;p&gt;Please don&apos;t use any &lt;code&gt;&amp;lt;blink&amp;gt;&lt;/code&gt; tags.&lt;/p&gt; 你也可以这样写： `&amp;#8212;` is the decimal-encoded equivalent of `&amp;mdash;`. 以产生： &lt;p&gt;&lt;code&gt;&amp;amp;#8212;&lt;/code&gt; is the decimal-encoded equivalent of &lt;code&gt;&amp;amp;mdash;&lt;/code&gt;.&lt;/p&gt; 图片 很明显地，要在纯文字应用中设计一个「自然」的语法来插入图片是有一定难度的。 Markdown 使用一种和链接很相似的语法来标记图片，同样也允许两种样式： 行内式和参考式。 行内式的图片语法看起来像是： ![Alt text](/path/to/img.jpg) ![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 详细叙述如下： 一个惊叹号 ! 接着一个方括号，里面放上图片的替代文字 接着一个普通括号，里面放上图片的网址，最后还可以用引号包住并加上选择性的 ‘title’ 文字。 参考式的图片语法则长得像这样： ![Alt text][id] 「id」是图片参考的名称，图片参考的定义方式则和连结参考一样： [id]: url/to/image &quot;Optional title attribute&quot; 到目前为止， Markdown 还没有办法指定图片的宽高，如果你需要的话，你可以使用普通的 &lt;img&gt; 标签。 其它 自动链接 Markdown 支持以比较简短的自动链接形式来处理网址和电子邮件信箱，只要是用方括号包起来， Markdown 就会自动把它转成链接。一般网址的链接文字就和链接地址一样，例如： &lt;http://example.com/&gt; Markdown 会转为： &lt;a href=&quot;http://example.com/&quot;&gt;http://example.com/&lt;/a&gt; 邮址的自动链接也很类似，只是 Markdown 会先做一个编码转换的过程，把文字字符转成 16 进位码的 HTML 实体，这样的格式可以糊弄一些不好的邮址收集机器人，例如： &lt;address@example.com&gt; Markdown 会转成： &lt;a href=&quot;&amp;#x6D;&amp;#x61;i&amp;#x6C;&amp;#x74;&amp;#x6F;:&amp;#x61;&amp;#x64;&amp;#x64;&amp;#x72;&amp;#x65; &amp;#115;&amp;#115;&amp;#64;&amp;#101;&amp;#120;&amp;#x61;&amp;#109;&amp;#x70;&amp;#x6C;e&amp;#x2E;&amp;#99;&amp;#111; &amp;#109;&quot;&gt;&amp;#x61;&amp;#x64;&amp;#x64;&amp;#x72;&amp;#x65;&amp;#115;&amp;#115;&amp;#64;&amp;#101;&amp;#120;&amp;#x61; &amp;#109;&amp;#x70;&amp;#x6C;e&amp;#x2E;&amp;#99;&amp;#111;&amp;#109;&lt;/a&gt; 在浏览器里面，这段字串（其实是 &lt;a href=&quot;mailto:address@example.com&quot;&gt;address@example.com&lt;/a&gt;）会变成一个可以点击的「address@example.com」链接。 （这种作法虽然可以糊弄不少的机器人，但并不能全部挡下来，不过总比什么都不做好些。不管怎样，公开你的信箱终究会引来广告信件的。） 反斜杠 Markdown 可以利用反斜杠来插入一些在语法中有其它意义的符号，例如：如果你想要用星号加在文字旁边的方式来做出强调效果（但不用 &lt;em&gt; 标签），你可以在星号的前面加上反斜杠： \*literal asterisks\* Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号： \ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 感谢 感谢 leafy7382 协助翻译，hlb、Randylien 帮忙润稿，ethantw 的汉字标准格式・CSS Reset， WM 回报文字错误。 感谢 fenprace，addv。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mac自定义subl命令]]></title>
      <url>%2Fblog%2F2017%2F03%2FMacOS-subl.html</url>
      <content type="text"><![CDATA[mac os用户可以通过命令行的方式打开Sublime Text，具体配置如下： 1sudo ln -s "/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl" /usr/local/bin/subl]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Multiple SSH Keys settings]]></title>
      <url>%2Fblog%2F2017%2F03%2FMultiple-SSH-Keys-settings.html</url>
      <content type="text"><![CDATA[我不该只是等待，我应该去寻找。 大多数 Git 服务器都会选择使用 SSH 公钥来进行授权。系统中的每个用户都必须提供一个公钥用于授权，没有的话就要生成一个。生成公钥的过程在所有操作系统上都差不多。 首先先确认一下是否已经有一个公钥了。SSH 公钥默认储存在账户的主目录下的 ~/.ssh 目录。关键是看有没有用 something 和 something.pub 来命名的一对文件，这个 something 通常就是 id_dsa 或 id_rsa。有 .pub 后缀的文件就是公钥，另一个文件则是密钥。假如没有这些文件，或者干脆连 .ssh 目录都没有，可以用 ssh-keygen 来创建。该程序在 Linux/Mac 系统上由 SSH 包提供，而在 Windows 上则包含在 MSysGit 包里： 12345678910$ ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/Users/schacon/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /Users/schacon/.ssh/id_rsa.Your public key has been saved in /Users/schacon/.ssh/id_rsa.pub.The key fingerprint is:43:c5:5b:5f:b1:f1:50:43:ad:20:a6:92:6a:1f:9a:3a schacon@agadorlaptop.local 它先要求你确认保存公钥的位置（.ssh/id_rsa），然后它会让你重复一个密码两次，如果不想在使用公钥的时候输入密码，可以留空。 现在，所有做过这一步的用户都得把它们的公钥给你或者 Git 服务器的管理员（假设 SSH 服务被设定为使用公钥机制）。他们只需要复制 .pub 文件的内容然后发邮件给管理员。 下面以github、gitlab为例，生成ssh公钥。 create different ssh key according the article Mac Set-Up Git Please refer to github ssh issues for common problems. 配置用户名和邮箱将项目从git仓库检出 git clone git@github.com:test, cd test and modify git config 12345git config user.name "用户名"git config user.email "邮箱"##全局设置用户名git config --global user.name "用户名" 生成ssh key12ssh-keygen -t rsa -C "邮箱" multi ssh key开发过程中，可能会使用不同的git仓库，如github、gitlab或者其他云平台，如果每次都覆盖原来的id_rsa，那么之前的认证就会失效。怎么破？ 在~/.ssh目录下增加config文件，生成ssh key时同时指定文件名即可。 12ssh-keygen -t rsa -f ~/.ssh/id_rsa.touker -C "email" 执行后，~/.ssh目录下会生成id_rsa.touker和id_rsa.touker.pub两个文件 配置config文件123$ cd ~/.ssh/$ touch config$ subl -a config 修改~/.ssh/config Gitlab默认使用git用户 123456789Host github.comHostName github.comUser gitIdentityFile /root/.ssh/id_rsa_githubHost 10.0.30.24HostName 10.0.30.24User gitIdentityFile /root/.ssh/id_rsa_touker 上传公钥id_rsa.pub12## 拷贝到剪切板clip &lt; ~/.ssh/id_rsa.pub github-&gt;settings-&gt;SSH keys gitlab -&gt; My SSH keys 验证是否配置成功1234ssh -T git@github.comHi username! You’ve successfully authenticated, but GitHub does not provide shell access.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Maven pom.xml]]></title>
      <url>%2Fblog%2F2017%2F03%2FMaven-pom.xml.html</url>
      <content type="text"><![CDATA[当你的能力还驾驭不了你的目标时，那就应该沉下心来历练。 pom作为项目对象模型，通过xml表示maven项目，使用pom.xml来实现。主要描述：配置文件，开发者需要遵循的规则，缺陷管理系统，组织和licenses，项目的url，项目的依赖性，以及其他所有的项目相关因素。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd"&gt; &lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。--&gt; &lt;parent&gt; &lt;!--被继承的父项目的构件标识符--&gt; &lt;artifactId/&gt; &lt;!--被继承的父项目的全球唯一标识符--&gt; &lt;groupId/&gt; &lt;!--被继承的父项目的版本--&gt; &lt;version/&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项 目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。--&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。--&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app--&gt; &lt;groupId&gt;asia.banseon&lt;/groupId&gt; &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个 特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。--&gt; &lt;artifactId&gt;banseon-maven2&lt;/artifactId&gt; &lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型--&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号--&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--项目的名称, Maven产生的文档用--&gt; &lt;name&gt;banseon-maven&lt;/name&gt; &lt;!--项目主页的URL, Maven产生的文档用--&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标 签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。--&gt; &lt;description&gt;A maven project to study maven.&lt;/description&gt; &lt;!--描述了这个项目构建环境中的前提条件。--&gt; &lt;prerequisites&gt; &lt;!--构建该项目或使用该插件所需要的Maven的最低版本--&gt; &lt;maven/&gt; &lt;/prerequisites&gt; &lt;!--项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira--&gt; &lt;issueManagement&gt; &lt;!--问题管理系统（例如jira）的名字，--&gt; &lt;system&gt;jira&lt;/system&gt; &lt;!--该项目使用的问题管理系统的URL--&gt; &lt;url&gt;http://jira.baidu.com/banseon&lt;/url&gt; &lt;/issueManagement&gt; &lt;!--项目持续集成信息--&gt; &lt;ciManagement&gt; &lt;!--持续集成系统的名字，例如continuum--&gt; &lt;system/&gt; &lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。--&gt; &lt;url/&gt; &lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告）--&gt; &lt;notifiers&gt; &lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者--&gt; &lt;notifier&gt; &lt;!--传送通知的途径--&gt; &lt;type/&gt; &lt;!--发生错误时是否通知--&gt; &lt;sendOnError/&gt; &lt;!--构建失败时是否通知--&gt; &lt;sendOnFailure/&gt; &lt;!--构建成功时是否通知--&gt; &lt;sendOnSuccess/&gt; &lt;!--发生警告时是否通知--&gt; &lt;sendOnWarning/&gt; &lt;!--不赞成使用。通知发送到哪里--&gt; &lt;address/&gt; &lt;!--扩展配置项--&gt; &lt;configuration/&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; &lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。--&gt; &lt;inceptionYear/&gt; &lt;!--项目相关邮件列表信息--&gt; &lt;mailingLists&gt; &lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。--&gt; &lt;mailingList&gt; &lt;!--邮件的名称--&gt; &lt;name&gt;Demo&lt;/name&gt; &lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;post&gt;banseon@126.com&lt;/post&gt; &lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;subscribe&gt;banseon@126.com&lt;/subscribe&gt; &lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;unsubscribe&gt;banseon@126.com&lt;/unsubscribe&gt; &lt;!--你可以浏览邮件信息的URL--&gt; &lt;archive&gt;http:/hi.baidu.com/banseon/demo/dev/&lt;/archive&gt; &lt;/mailingList&gt; &lt;/mailingLists&gt; &lt;!--项目开发者列表--&gt; &lt;developers&gt; &lt;!--某个项目开发者的信息--&gt; &lt;developer&gt; &lt;!--SCM里项目开发者的唯一标识符--&gt; &lt;id&gt;HELLO WORLD&lt;/id&gt; &lt;!--项目开发者的全名--&gt; &lt;name&gt;banseon&lt;/name&gt; &lt;!--项目开发者的email--&gt; &lt;email&gt;banseon@126.com&lt;/email&gt; &lt;!--项目开发者的主页的URL--&gt; &lt;url/&gt; &lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色--&gt; &lt;roles&gt; &lt;role&gt;Project Manager&lt;/role&gt; &lt;role&gt;Architect&lt;/role&gt; &lt;/roles&gt; &lt;!--项目开发者所属组织--&gt; &lt;organization&gt;demo&lt;/organization&gt; &lt;!--项目开发者所属组织的URL--&gt; &lt;organizationUrl&gt;http://hi.baidu.com/banseon&lt;/organizationUrl&gt; &lt;!--项目开发者属性，如即时消息如何处理等--&gt; &lt;properties&gt; &lt;dept&gt;No&lt;/dept&gt; &lt;/properties&gt; &lt;!--项目开发者所在时区， -11到12范围内的整数。--&gt; &lt;timezone&gt;-5&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!--项目的其他贡献者列表--&gt; &lt;contributors&gt; &lt;!--项目的其他贡献者。参见developers/developer元素--&gt; &lt;contributor&gt; &lt;name/&gt;&lt;email/&gt;&lt;url/&gt;&lt;organization/&gt;&lt;organizationUrl/&gt;&lt;roles/&gt;&lt;timezone/&gt;&lt;properties/&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。--&gt; &lt;licenses&gt; &lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。--&gt; &lt;license&gt; &lt;!--license用于法律上的名称--&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;!--官方的license正文页面的URL--&gt; &lt;url&gt;http://www.baidu.com/banseon/LICENSE-2.0.txt&lt;/url&gt; &lt;!--项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖--&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;!--关于license的补充信息--&gt; &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。--&gt; &lt;scm&gt; &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。--&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读--&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!--当前代码的标签，在开发阶段默认为HEAD--&gt; &lt;tag/&gt; &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。--&gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &lt;/scm&gt; &lt;!--描述项目所属组织的各种属性。Maven产生的文档用--&gt; &lt;organization&gt; &lt;!--组织的全名--&gt; &lt;name&gt;demo&lt;/name&gt; &lt;!--组织主页的URL--&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;/organization&gt; &lt;!--构建项目需要的信息--&gt; &lt;build&gt; &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;sourceDirectory/&gt; &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。--&gt; &lt;scriptSourceDirectory/&gt; &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;testSourceDirectory/&gt; &lt;!--被编译过的应用程序class文件存放的目录。--&gt; &lt;outputDirectory/&gt; &lt;!--被编译过的测试class文件存放的目录。--&gt; &lt;testOutputDirectory/&gt; &lt;!--使用来自该项目的一系列构建扩展--&gt; &lt;extensions&gt; &lt;!--描述使用到的构建扩展。--&gt; &lt;extension&gt; &lt;!--构建扩展的groupId--&gt; &lt;groupId/&gt; &lt;!--构建扩展的artifactId--&gt; &lt;artifactId/&gt; &lt;!--构建扩展的版本--&gt; &lt;version/&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值--&gt; &lt;defaultGoal/&gt; &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。--&gt; &lt;resources&gt; &lt;!--这个元素描述了项目相关或测试相关的所有资源路径--&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。--&gt; &lt;targetPath/&gt; &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。--&gt; &lt;filtering/&gt; &lt;!--描述存放资源的目录，该路径相对POM路径--&gt; &lt;directory/&gt; &lt;!--包含的模式列表，例如**/*.xml.--&gt; &lt;includes/&gt; &lt;!--排除的模式列表，例如**/*.xml--&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。--&gt; &lt;testResources&gt; &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明--&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!--构建产生的所有文件存放的目录--&gt; &lt;directory/&gt; &lt;!--产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。--&gt; &lt;finalName/&gt; &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表--&gt; &lt;filters/&gt; &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置--&gt; &lt;pluginManagement&gt; &lt;!--使用的插件列表 。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述插件所需要的信息。--&gt; &lt;plugin&gt; &lt;!--插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。--&gt; &lt;extensions/&gt; &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。--&gt; &lt;executions&gt; &lt;!--execution元素包含了插件执行需要的信息--&gt; &lt;execution&gt; &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标--&gt; &lt;id/&gt; &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段--&gt; &lt;phase/&gt; &lt;!--配置的执行目标--&gt; &lt;goals/&gt; &lt;!--配置是否被传播到子POM--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!--项目引入插件所需要的额外依赖--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!--使用的插件列表--&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--在列的项目构建profile，如果被激活，会修改构建处理--&gt; &lt;profiles&gt; &lt;!--根据环境参数或命令行参数激活某个构建处理--&gt; &lt;profile&gt; &lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。--&gt; &lt;id/&gt; &lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。--&gt; &lt;activation&gt; &lt;!--profile默认是否激活的标志--&gt; &lt;activeByDefault/&gt; &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。--&gt; &lt;jdk/&gt; &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。--&gt; &lt;os&gt; &lt;!--激活profile的操作系统的名字--&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!--激活profile的操作系统所属家族(如 'windows')--&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!--激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!--激活profile的操作系统版本--&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段--&gt; &lt;property&gt; &lt;!--激活profile的属性的名称--&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!--激活profile的属性的值--&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。--&gt; &lt;file&gt; &lt;!--如果指定的文件存在，则激活profile。--&gt; &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/exists&gt; &lt;!--如果指定的文件不存在，则激活profile。--&gt; &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!--构建项目所需要的信息。参见build元素--&gt; &lt;build&gt; &lt;defaultGoal/&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory/&gt;&lt;finalName/&gt;&lt;filters/&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules/&gt; &lt;!--发现依赖和扩展的远程仓库列表。--&gt; &lt;repositories&gt; &lt;!--参见repositories/repository元素--&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt;&lt;name/&gt;&lt;url/&gt;&lt;layout/&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt;&lt;name/&gt;&lt;url/&gt;&lt;layout/&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素.--&gt; &lt;reports/&gt; &lt;!--该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素--&gt; &lt;reporting&gt; ...... &lt;/reporting&gt; &lt;!--参见dependencyManagement元素--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--参见distributionManagement元素--&gt; &lt;distributionManagement&gt; ...... &lt;/distributionManagement&gt; &lt;!--参见properties元素--&gt; &lt;properties/&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules/&gt; &lt;!--发现依赖和扩展的远程仓库列表。--&gt; &lt;repositories&gt; &lt;!--包含需要连接到远程仓库的信息--&gt; &lt;repository&gt; &lt;!--如何处理远程仓库里发布版本的下载--&gt; &lt;releases&gt; &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled/&gt; &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。--&gt; &lt;updatePolicy/&gt; &lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。--&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库--&gt; &lt;id&gt;banseon-repository-proxy&lt;/id&gt; &lt;!--远程仓库名称--&gt; &lt;name&gt;banseon-repository-proxy&lt;/name&gt; &lt;!--远程仓库URL，按protocol://hostname/path形式--&gt; &lt;url&gt;http://192.168.1.169:9999/repository/&lt;/url&gt; &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。--&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--&gt; &lt;pluginRepository&gt; ...... &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!--依赖的group ID--&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;!--依赖的artifact ID--&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。--&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。--&gt; &lt;type&gt;jar&lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。--&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用--&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。--&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。--&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素.--&gt; &lt;reports&gt;&lt;/reports&gt; &lt;!--该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。--&gt; &lt;reporting&gt; &lt;!--true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。--&gt; &lt;excludeDefaults/&gt; &lt;!--所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。--&gt; &lt;outputDirectory/&gt; &lt;!--使用的报表插件和他们的配置。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述报表插件需要的信息--&gt; &lt;plugin&gt; &lt;!--报表插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--报表插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的报表插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--报表插件的配置--&gt; &lt;configuration/&gt; &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标--&gt; &lt;reportSets&gt; &lt;!--表示报表的一个集合，以及产生该集合的配置--&gt; &lt;reportSet&gt; &lt;!--报表集合的唯一标识符，POM继承时用到--&gt; &lt;id/&gt; &lt;!--产生报表集合时，被使用的报表的配置--&gt; &lt;configuration/&gt; &lt;!--配置是否被继承到子POMs--&gt; &lt;inherited/&gt; &lt;!--这个集合里使用到哪些报表--&gt; &lt;reports/&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。--&gt; &lt;distributionManagement&gt; &lt;!--部署项目产生的构件到远程仓库需要的信息--&gt; &lt;repository&gt; &lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素--&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;banseon maven2&lt;/name&gt; &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素--&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt; &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt; &lt;layout/&gt; &lt;/snapshotRepository&gt; &lt;!--部署项目的网站需要的信息--&gt; &lt;site&gt; &lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置--&gt; &lt;id&gt;banseon-site&lt;/id&gt; &lt;!--部署位置的名称--&gt; &lt;name&gt;business api website&lt;/name&gt; &lt;!--部署位置的URL，按protocol://hostname/path形式--&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。--&gt; &lt;downloadUrl/&gt; &lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。--&gt; &lt;relocation&gt; &lt;!--构件新的group ID--&gt; &lt;groupId/&gt; &lt;!--构件新的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--构件新的版本号--&gt; &lt;version/&gt; &lt;!--显示给用户的，关于移动的额外信息，例如原因。--&gt; &lt;message/&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。--&gt; &lt;status/&gt; &lt;/distributionManagement&gt; &lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。--&gt; &lt;properties/&gt; &lt;/project&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux sed 命令]]></title>
      <url>%2Fblog%2F2017%2F02%2FLinux-sed.html</url>
      <content type="text"><![CDATA[其实对于爱情，越单纯越幸福。 sed是一种流编辑器，它能够完美配合正则表达式使用，功能非同凡响。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件，简化对文件的反复操作，编写转换程序等。 文件截取从2012-02-09到2012-09-10的所有数据行, 日志文件以yyyy-MM-dd的日期格式开头 1sed -n '/^2012-02-09/,/^2012-09-10/p' whole.log &gt; part.log 从文件中导出包含指定内容的行 1sed -n '/.*010000061905.*/p' catalina.out.2016-12-19 &gt; 010000061905.log 从日志中截取指定时间的内容,如提取12:00-13:00的内容 1sed -n '/^16-12-19 12:00*/,/^16-12-19 13:00*/p' catalina.out.2016-12-19 &gt; part.log 提取svn日志找出svn提交历史中的message信息 1svn log -l2 --xml | grep msg | sed -E "s:&lt;/?msg&gt;::g" 日志分析以下API网管的部分日志数据，URL请求需要经过身份验证才可以被API网管转发，每个请求都需要经过流速控制，下面我们分析9:00-11:00的用户的请求类别、数量以及请求频率是否存在异常： 123456789102017-07-17 10:29:59.947 [http-apr-8080-exec-968] INFO PlatformUriHandler - Http request ok : /securityFinanceService.queryFinanceAccountWithProfit(execution times):11302017-07-17 10:29:59.967 [http-apr-8080-exec-953] INFO h.a.a.f.AppPlatformRateLimiterFilter - http request=http://api.*.com/securityFinanceService.queryHoldPositionOverview2017-07-17 10:29:59.967 [http-apr-8080-exec-953] INFO h.a.a.f.AppPlatformRateLimiterFilter - parameter=_appCrypt_=RHtNFWqD74F0TF4WH8YeLA==&amp;ticket=2.daVmH6WojkSmBfJ-ige_cj8mcUolrWsVceIPKnEAcUIy2UvPIGrt8Q-5tIDd8Kt-vD51aSfKhcwMBa4qd4mZc31bDVluaYQvAjPvzSCv-v7QZaH5dOM2QsJN8jrn0ppWJyKpWVQWt8mFWpJ0XoNUYhLd9kB95X2g-bMNI4xGDi0&amp;_t_=HBStockWarningAndroid_3.6.6&amp;2017-07-17 10:29:59.969 [http-apr-8080-exec-953] INFO hbec.app.api.filter.RateLimiter - userId:2988470, 在 5s 内第1次 执行操作 http://api.*.com/securityFinanceService.queryHoldPositionOverview, 通过流速控制器, 阀值(5s最高40次)2017-07-17 10:29:59.969 [http-apr-8080-exec-953] DEBUG h.a.a.f.AppPlatformRateLimiterFilter - pass rate limiter~2017-07-17 10:29:59.969 [http-apr-8080-exec-953] DEBUG h.p.commons.web.HbecApiHandleAdapter - param-sha1 : null, appCrypt&lt;1&gt; : RHtNFWqD74F0TF4WH8YeLA==, dataKey=9mycm#kjd=g4r24r2017-07-17 10:29:59.969 [http-apr-8080-exec-953] DEBUG h.p.commons.web.HbecApiHandleAdapter - plainText&lt;2&gt; reqParam : ,2017-07-17 10:29:59.969 [http-apr-8080-exec-953] DEBUG h.p.commons.web.HbecApiHandleAdapter - rpc paramter = 29884702017-07-17 10:29:59.969 [http-apr-8080-exec-953] DEBUG h.p.commons.web.HbecApiHandleAdapter - rpc parameter = [2988470]2017-07-17 10:30:00.021 [http-apr-8080-exec-906] INFO h.a.a.f.AppPlatformRateLimiterFilter - http request=http://api.*.com/conditionTradeService.countEntrustedResult 1.按时间段裁剪日志分析以上日志不难发现，每行都以固定的时间格式开头：2017-07-17 10:29:59.969 1sed -n '/^2017-07-17 09:00*/,/^2017-07-17 11:00*/p' api2.txt &gt; api2.0900_1000.txt 2.筛选出包含用户Id和请求url的行记录经过流速控制的请求，都会输出指定的日志，因此我们可以从中筛选出用户信息和请求信息。 12017-07-17 10:29:59.969 [http-apr-8080-exec-953] INFO hbec.app.api.filter.RateLimiter - userId:2988470, 在 5s 内第1次 执行操作 http://api.*.com/securityFinanceService.queryHoldPositionOverview, 通过流速控制器, 阀值(5s最高40次) 1sed -n '/.*hbec.app.api.filter.RateLimiter - userId:.*/p' api2.0900_1000.txt &gt; part.txt 筛选后的日志： 1234562017-07-17 09:30:00.064 [http-apr-8080-exec-880] INFO hbec.app.api.filter.RateLimiter - userId:3229792, 在 5s 内第3次 执行操作 http://api.touker.com/conditionTradeService.countEntrustedResult, 通过流速控制器, 阀值(5s最高40次)2017-07-17 09:30:00.091 [http-apr-8080-exec-835] INFO hbec.app.api.filter.RateLimiter - userId:3262223, 在 5s 内第2次 执行操作 http://api.touker.com/securityFinanceService.queryHoldPositionOverview, 通过流速控制器, 阀值(5s最高40次)2017-07-17 09:30:00.119 [http-apr-8080-exec-868] INFO hbec.app.api.filter.RateLimiter - userId:2328415, 在 5s 内第1次 执行操作 http://api.touker.com/securityExchangeController.queryAvailableNumber, 通过流速控制器, 阀值(5s最高40次)2017-07-17 09:30:00.138 [http-apr-8080-exec-877] INFO hbec.app.api.filter.RateLimiter - userId:2996025, 在 5s 内第4次 执行操作 http://api.touker.com/followStockService.query, 通过流速控制器, 阀值(5s最高40次)2017-07-17 09:30:00.182 [http-apr-8080-exec-869] INFO hbec.app.api.filter.RateLimiter - userId:3261451, 在 5s 内第5次 执行操作 http://api.touker.com/abossQuery.queryAbossStatus, 通过流速控制器, 阀值(5s最高40次)2017-07-17 09:30:00.238 [http-apr-8080-exec-778] INFO hbec.app.api.filter.RateLimiter - userId:2976226, 在 5s 内第3次 执行操作 http://api.touker.com/followStockService.query, 通过流速控制器, 阀值(5s最高40次) 3.替换多余信息1234sed -i "s/.*.RateLimiter - userId://g" part.txtsed -i "s/, 通过流速控制器, 阀值(5s最高40次)//g" part.txtsed -i "s/, 在 5s 内第[0-9]*次 执行操作//g" part.txtsed -i "s/, 未通过流速控制器, 阀值(5s最高40次)//g" part.txt 替换后 123456789103263487 stockService.queryIndustryConceptChange3263487 followStockService.query3224197 securityFinanceService.queryHoldPositionOverview3229792 conditionTradeService.findMonitorPageWithMarket183981 followStockService.query3249596 dynamicConfiguration.queryTradeConfiguration3255313 securityFinanceService.queryHoldPositionOverview3249596 securityFinanceService.queryFinanceAccountWithProfit3264204 abossQuery.queryAbossStatus2868006 stockService.queryIndustryConceptChange 4.统计统计每个用户的请求信息123排序 : sort part.txt &gt; sort.part统计 : uniq -c sort.part &gt; count.txt 统计用户数量12345筛选出userId : sed -i "s/ http:\/\/api.touker.com\/.*//g" part.txt排序 : sort part.txt &gt; userId.sort.part统计 : uniq -c userId.sort.part &gt; userId.count.txt 统计统计请求量最大的URL 123456筛选出URL : sed -i "s/.*http:\/\/api.touker.com\///g" part.txt排序 : sort part.txt &gt; url.sort.part统计 : uniq -c url.sort.part &gt; url.count.txt 统计url调用次数 123筛选出URL : sed -i "s/.*http:\/\/api.touker.com\///g" part.txtawk '&#123;sum += $1&#125;;END &#123;print sum&#125;' part.txt 合并多个API日志文件的请求次数 12awk '&#123;s[$2] += $1&#125;END&#123; for(i in s)&#123; print i, s[i] &#125; &#125;' part.txt &gt; final.txt]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[基于Rabbitmq实现延迟队列]]></title>
      <url>%2Fblog%2F2017%2F02%2F%E5%9F%BA%E4%BA%8ERabbitmq%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97.html</url>
      <content type="text"><![CDATA[延迟队列的使用场景 淘宝订单业务：下单后30min之内没有付款，就自动取消订单。 饿了吗订餐通知：下单成功后60s之后给用户发送短信通知。 关闭空闲连接：服务器中有很多客户端的连接，空闲一段时间之后需要关闭之。 缓存：缓存中的对象，超过了空闲时间，从缓存中移出。 任务超时处理：在网络协议滑动窗口请求应答式交互时，处理超时未响应的请求。 失败重试机制：业务操作失败后，间隔一定的时间进行失败重试。 这类业务的特点就是：延迟工作、失败重试。一种比较笨的方式是使用后台线程遍历所有对象，挨个检查。这种方法虽然简单好用，但是对象数量过多时，可能存在性能问题，检查间隔时间不好设置，间隔时间过大，影响精确度，过小则存在效率问题，而且做不到按超时的时间顺序处理。 本地延迟队列 DelayQueueDelayQueue是一个无界的BlockingQueue，用于放置实现了Delayed接口的对象，其中的对象只能在其到期时才能从队列中取走。这种队列是有序的，即队头对象的延迟到期时间最长。Delayed扩展了Comparable接口，比较的基准为延时的时间值，Delayed接口的实现类getDelay的返回值应为固定值（final）。DelayQueue内部是使用PriorityQueue实现的。 12DelayQueue = BlockingQueue + PriorityQueue + Delayed DelayQueue的关键元素BlockingQueue、PriorityQueue、Delayed。可以这么说，DelayQueue是一个使用优先队列（PriorityQueue）实现的BlockingQueue，优先队列的比较基准值是时间。(注意：不能将null元素放置到这种队列) 但是我们知道，利用DelayQueue实现的是一个单机的、JVM内存中的延迟队列，并没有集群的支持，而且无法满足在对业务系统泵机的时、消息消费异常的时候做相应的逻辑处理。 基于分布式消息队列RabbitMQ实现延迟队列RabbitMQ本身没有直接支持延迟队列功能，但是可以通过以下特性模拟出延迟队列的功能： Per-Queue Message TTL RabbitMQ可以对消息和队列设置TTL（过期时间）。RabbitMQ针对队列中的消息过期时间(Time To Live, TTL)有两种方法可以设置。第一种方法是通过队列属性设置，队列中所有消息都有相同的过期时间。第二种方法是对消息进行单独设置，每条消息TTL可以不同。如果上述两种方法同时使用，则消息的过期时间以两者之间TTL较小的那个数值为准。消息在队列的生存时间一旦超过设置的TTL值，就成为dead message,消费者将无法再收到该消息。 Dead Letter Exchanges 死信消息利用DLX，当消息在一个队列中变成死信后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。消息变成死信有以下几种情况： 消息被拒绝（basic.reject or basic.nack）并且requeue=false 消息TTL过期 队列达到最大长度 DLX同一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。当队列中有死信消息时，RabbitMQ就会自动的将死信消息重新发布到设置的Exchange中去，进而被路由到另一个队列，publish可以监听这个队列中消息做相应的处理，这个特性可以弥补RabbitMQ 3.0.0以前支持的immediate参数中的向publish确认的功能。 结合以上两个特性，就可以模拟出延迟消息的功能. 流程图 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209package hbec.app.stock.rabbitmq.utils;import java.io.IOException;import java.util.HashMap;import java.util.concurrent.TimeUnit;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import com.google.common.base.Preconditions;import com.google.common.collect.Maps;import com.rabbitmq.client.AMQP;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Consumer;/** * @Description &lt;strong&gt;基于RabbitMQ实现的分布式延迟重试队列&lt;/strong&gt; * * &lt;ul&gt; * &lt;li&gt;delayExchangeName : 交换器名称&lt;/li&gt; * &lt;li&gt;delayQueueName : 延迟队列名称&lt;/li&gt; * &lt;li&gt;delayRoutingKeyName : 路由器名称&lt;/li&gt; * &lt;li&gt;perDelayQueueMessageTTL : 延迟队列中message的默认ttl&lt;/li&gt; * &lt;/ul&gt; * 通过&#123;@link RabbitMQDelayQueue#put(byte[], long, TimeUnit)&#125;首次进入延迟队列的消息， * 其ttl = min(message ttl, per queue message ttl)， * 消息被Reject/nack之后变成死信消息，其自带message ttl失效， * 以后将按照&#123;@link #perDelayQueueMessageTTL&#125;指定的延迟时间投递给经由&#123;@link RabbitMQDelayQueue#consumerRegister&#125;注册的消费者，直到消息被Ack. * * @author roc roc.fly@qq.com * @date Dec 9, 2016 3:29:39 PM */public class RabbitMQDelayQueue &#123; private static Logger LOGGER = LoggerFactory.getLogger(RabbitMQDelayQueue.class); private static final String POSTFIX_TASK = "_task"; // direct类型 交换器 public static final String EXCHANGE_TYPE_DIRECT = "direct"; private Connection connection; //注册消费者 private ConsumerRegister consumerRegister; //任务队列配置 private String taskExchangeName; private String taskQueueName; private String taskRoutingKeyName; //延迟队列配置 private String delayExchangeName; private String delayQueueName; private String delayRoutingKeyName; //延迟队列中的消息ttl private long perDelayQueueMessageTTL; public RabbitMQDelayQueue(Connection connection, ConsumerRegister consumerRegister, String delayExchangeName, String delayQueueName, String delayRoutingKeyName, long perDelayQueueMessageTTL) throws IOException &#123; this.connection = connection; this.consumerRegister = consumerRegister; this.delayExchangeName = delayExchangeName; this.delayQueueName = delayQueueName; this.delayRoutingKeyName = delayRoutingKeyName; this.perDelayQueueMessageTTL = perDelayQueueMessageTTL; this.taskExchangeName = delayExchangeName + POSTFIX_TASK; this.taskQueueName = delayQueueName + POSTFIX_TASK; this.taskRoutingKeyName = delayRoutingKeyName + POSTFIX_TASK; init(); registerConsumer(); &#125; /** * * @Description 注册消费者 * @author roc roc.fly@qq.com * @date Dec 29, 2016 1:36:25 PM */ public interface ConsumerRegister &#123; public Consumer register(Channel channel) throws IOException; &#125; /** * 注册带有ttl的queue和对应的任务队列 * * @throws IOException * @author roc */ private void init() throws IOException &#123; Channel channel = connection.createChannel(); channel.exchangeDeclare(taskExchangeName, EXCHANGE_TYPE_DIRECT, true); channel.exchangeDeclare(delayExchangeName, EXCHANGE_TYPE_DIRECT, true); // 任务队列 B HashMap&lt;String, Object&gt; argumentsTask = Maps.newHashMap(); argumentsTask.put("x-dead-letter-exchange", delayExchangeName); argumentsTask.put("x-dead-letter-routing-key", delayRoutingKeyName); channel.queueDeclare(taskQueueName, true, false, false, argumentsTask); channel.queueBind(taskQueueName, taskExchangeName, taskRoutingKeyName); // 延迟队列 A HashMap&lt;String, Object&gt; argumentsDelay = Maps.newHashMap(); argumentsDelay.put("x-dead-letter-exchange", taskExchangeName); argumentsDelay.put("x-dead-letter-routing-key", taskRoutingKeyName); argumentsDelay.put("x-message-ttl", perDelayQueueMessageTTL); channel.queueDeclare(delayQueueName, true, false, false, argumentsDelay); channel.queueBind(delayQueueName, delayExchangeName, delayRoutingKeyName); channel.close(); &#125; /** * 注册消费者 * @throws IOException * @author roc */ private void registerConsumer() throws IOException &#123; LOGGER.info("register consumer -&gt;&#123;&#125;", this); Channel channel = connection.createChannel(); Consumer consumer = consumerRegister.register(channel); channel.basicConsume(taskQueueName, false, consumer); LOGGER.info("register consumer -&gt;&#123;&#125; success", this); &#125; /** * 消息入队 * * @param body 消息内容 * @param timeout 超时时间 * @param unit 超时时间单位 * @throws IOException * @author roc */ public void put(byte[] body, long timeout, TimeUnit unit) throws IOException &#123; Preconditions.checkNotNull(body); Preconditions.checkArgument(timeout &gt;= 0); Preconditions.checkNotNull(unit); LOGGER.info("put element to delay queue -&gt;&#123;&#125;", body.hashCode()); Channel channel = null; try &#123; channel = connection.createChannel(); // deliveryMode=2 标识任务的持久性 long millis = unit.toMillis(timeout); AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder().expiration(String.valueOf(millis)).deliveryMode(2).build(); channel.basicPublish(delayExchangeName, delayRoutingKeyName, properties, body); LOGGER.info("put element to delay queue success"); &#125; finally &#123; if (null != channel) channel.close(); &#125; &#125; public static class Builder &#123; private Connection connection; private ConsumerRegister consumerRegister; private String delayExchangeName; private String delayQueueName; private String delayRoutingKeyName; private long perDelayQueueMessageTTL; public Builder setConnection(Connection connection) &#123; this.connection = connection; return this; &#125; public Builder setDelayExchangeName(String delayExchangeName) &#123; this.delayExchangeName = delayExchangeName; return this; &#125; public Builder setDelayQueueName(String delayQueueName) &#123; this.delayQueueName = delayQueueName; return this; &#125; public Builder setDelayRoutingKeyName(String delayRoutingKeyName) &#123; this.delayRoutingKeyName = delayRoutingKeyName; return this; &#125; public Builder setConsumerRegister(ConsumerRegister consumerRegister) &#123; this.consumerRegister = consumerRegister; return this; &#125; public Builder setPerDelayQueueMessageTTL(long timeout, TimeUnit unit) &#123; this.perDelayQueueMessageTTL = unit.toMillis(timeout);; return this; &#125; public RabbitMQDelayQueue build() throws IOException &#123; Preconditions.checkNotNull(connection); Preconditions.checkNotNull(delayExchangeName); Preconditions.checkNotNull(delayQueueName); Preconditions.checkNotNull(delayRoutingKeyName); Preconditions.checkNotNull(consumerRegister); return new RabbitMQDelayQueue(connection, consumerRegister, delayExchangeName, delayQueueName, delayRoutingKeyName, perDelayQueueMessageTTL); &#125; &#125;&#125; 测试代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package hbec.app.stock.rabbitmq.utils;import hbec.app.stock.rabbitmq.utils.RabbitMQDelayQueue.ConsumerRegister;import java.io.IOException;import java.nio.charset.Charset;import java.util.List;import java.util.Map;import java.util.concurrent.TimeUnit;import com.rabbitmq.client.AMQP.BasicProperties;import com.rabbitmq.client.Address;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Consumer;import com.rabbitmq.client.DefaultConsumer;import com.rabbitmq.client.Envelope;/** * 测试demo * */public class RabbitMQDelayQueueTest &#123; public static void main(String[] args) throws IOException &#123; delayQueue(); &#125; public static void delayQueue() throws IOException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setUsername(&quot;guest&quot;); factory.setPassword(&quot;guest&quot;); Address address = new Address(&quot;10.0.30.67&quot;, 56720); Connection connection = factory.newConnection(new Address[] &#123; address &#125;); RabbitMQDelayQueue delayQueue = new RabbitMQDelayQueue.Builder().setConnection(connection).setPerDelayQueueMessageTTL(15, TimeUnit.SECONDS).setDelayExchangeName(&quot;delay_exchange_roc&quot;).setDelayQueueName(&quot;delay_queue_roc&quot;).setDelayRoutingKeyName(&quot;delay_routing_key_roc&quot;).setConsumerRegister(new ConsumerRegister() &#123; @Override public Consumer register(Channel channel) throws IOException &#123; return new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, BasicProperties properties, byte[] body) throws IOException &#123; long deliveryTag = envelope.getDeliveryTag(); String exchange = envelope.getExchange(); String routingKey = envelope.getRoutingKey(); // TODO do something String content = new String(body, Charset.forName(&quot;utf-8&quot;)); System.out.println(&quot;receive message --- &gt; &quot; + content); Map&lt;String, Object&gt; headers = properties.getHeaders(); if (headers != null) &#123; List&lt;Map&lt;String, Object&gt;&gt; xDeath = (List&lt;Map&lt;String, Object&gt;&gt;) headers.get(&quot;x-death&quot;); System.out.println(&quot;xDeath--- &gt; &quot; + xDeath); if (xDeath != null &amp;&amp; !xDeath.isEmpty()) &#123; Map&lt;String, Object&gt; entrys = xDeath.get(0); &#125; &#125; // 消息拒收 // if(do something) 消息重新入队 getChannel().basicReject(deliveryTag, false); // else 消息应答 // getChannel().basicAck(deliveryTag, false); &#125; &#125;; &#125; &#125;).build(); delayQueue.put(&quot;&#123;\&quot;name\&quot; : \&quot;i am roc!!\&quot;&#125;\&quot;&quot;.getBytes(&quot;UTF-8&quot;), 3, TimeUnit.SECONDS); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo mouse follow up special effects]]></title>
      <url>%2Fblog%2F2017%2F02%2Fhexo-mouse-follow-up-special-effects.html</url>
      <content type="text"><![CDATA[一个基于canvas绘制的网页背景效果。 canvas-nest.js is a nest backgroud of website draw on canvas use javascript, do not depend on jQuery. WordPress插件: https://github.com/aTool-org/canvas-nest-for-wpgithub: https://github.com/hustcc/canvas-nest.js 效果如图 使用方法 打开next/layout/_layout.swig 文件， 将下面的代码插入到 和 之间. 1&lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"&gt;&lt;/script&gt; 强烈建议在 &lt;/body&gt;标签上方. 例如下面的代码结构: 1234567891011&lt;html&gt;&lt;head&gt; ...&lt;/head&gt;&lt;body&gt; ... ... ... &lt;script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 请注意不要将代码置于&lt;head&gt; &lt;/head&gt;里面.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2Fblog%2F2017%2F01%2Fhello-world.html</url>
      <content type="text"><![CDATA[2017，blog搬家~]]></content>
    </entry>

    
  
  
</search>
